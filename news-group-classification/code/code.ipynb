{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7aebeef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from glob import glob\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from catboost import Pool, CatBoostClassifier\n",
    "\n",
    "from bert_sklearn import BertClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cf0651d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../data/train.csv\", index_col=\"id\")\n",
    "test = pd.read_csv(\"../data/test.csv\", index_col=\"id\")\n",
    "submission = pd.read_csv(\"../data/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f727d13a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already existed : ../pickle\n",
      "Directory already existed : ../model\n",
      "Directory already existed : ../submission\n"
     ]
    }
   ],
   "source": [
    "def create_dir(dir):\n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)\n",
    "        print(\"Created Directory :\", dir)\n",
    "    else:\n",
    "        print(\"Directory already existed :\", dir)\n",
    "create_dir(\"../pickle\")\n",
    "create_dir(\"../model\")\n",
    "create_dir(\"../submission\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db4dcb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train['text']\n",
    "train_y = train['target']\n",
    "test_x = test['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e48114ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_train = train.shape[0] # 주어진 train data의 row 수\n",
    "rows_test = test.shape[0] # 주어진 test data의 row 수\n",
    "num_classes = len(train_y.unique())\n",
    "num_trial = 100 # 파라미터 튜닝을 몇 번 진행하는지의 수\n",
    "splits_hp = 5 # 파라미터 튜닝을 진행할 때의 kfold 수\n",
    "splits_tr = 15 # 모델 트레이닝을 진행할 때의 kfold 수\n",
    "basic_seed = 42 # default seed\n",
    "num_seed_tr = 5 # 트레이닝 seed 개수\n",
    "sel_seed = 3 # 선택할 seed 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "105cbc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dict = {}\n",
    "pred_test_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15b6b03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ab4d386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building sklearn text classifier...\n",
      "Loading bert-base-cased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 8617, validation data size: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|███████████████████████████████████████████████████████| 1078/1078 [08:35<00:00,  2.09it/s, loss=1.55]\n",
      "Training  : 100%|██████████████████████████████████████████████████████| 1078/1078 [06:42<00:00,  2.68it/s, loss=0.731]\n",
      "Training  : 100%|██████████████████████████████████████████████████████| 1078/1078 [06:42<00:00,  2.68it/s, loss=0.407]\n",
      "Training  : 100%|██████████████████████████████████████████████████████| 1078/1078 [06:43<00:00,  2.67it/s, loss=0.235]\n",
      "Predicting: 100%|████████████████████████████████████████████████████████████████████| 308/308 [00:18<00:00, 17.06it/s]\n",
      "Predicting: 100%|██████████████████████████████████████████████████████████████████| 4617/4617 [02:02<00:00, 37.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1 log_loss : 1.0057300674007976\n",
      "fold 1 accuracy_score : 0.7337662337662337\n",
      "Building sklearn text classifier...\n",
      "Loading bert-base-cased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 8617, validation data size: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|███████████████████████████████████████████████████████| 1078/1078 [06:42<00:00,  2.67it/s, loss=1.55]\n",
      "Training  : 100%|██████████████████████████████████████████████████████| 1078/1078 [06:42<00:00,  2.68it/s, loss=0.734]\n",
      "Training  : 100%|██████████████████████████████████████████████████████| 1078/1078 [06:43<00:00,  2.67it/s, loss=0.407]\n",
      "Training  : 100%|██████████████████████████████████████████████████████| 1078/1078 [06:47<00:00,  2.65it/s, loss=0.236]\n",
      "Predicting: 100%|████████████████████████████████████████████████████████████████████| 308/308 [00:18<00:00, 16.95it/s]\n",
      "Predicting: 100%|██████████████████████████████████████████████████████████████████| 4617/4617 [02:02<00:00, 37.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 2 log_loss : 1.0477646129171647\n",
      "fold 2 accuracy_score : 0.724025974025974\n",
      "Building sklearn text classifier...\n",
      "Loading bert-base-cased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 8617, validation data size: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|███████████████████████████████████████████████████████| 1078/1078 [06:43<00:00,  2.67it/s, loss=1.54]\n",
      "Training  : 100%|██████████████████████████████████████████████████████| 1078/1078 [06:43<00:00,  2.67it/s, loss=0.729]\n",
      "Training  : 100%|██████████████████████████████████████████████████████| 1078/1078 [06:43<00:00,  2.67it/s, loss=0.418]\n",
      "Training  : 100%|██████████████████████████████████████████████████████| 1078/1078 [06:44<00:00,  2.67it/s, loss=0.244]\n",
      "Predicting: 100%|████████████████████████████████████████████████████████████████████| 308/308 [00:18<00:00, 17.03it/s]\n",
      "Predicting: 100%|██████████████████████████████████████████████████████████████████| 4617/4617 [02:02<00:00, 37.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 3 log_loss : 1.0058677466020995\n",
      "fold 3 accuracy_score : 0.724025974025974\n",
      "Building sklearn text classifier...\n",
      "Loading bert-base-cased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 8617, validation data size: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|███████████████████████████████████████████████████████| 1078/1078 [06:43<00:00,  2.67it/s, loss=1.53]\n",
      "Training  : 100%|███████████████████████████████████████████████████████| 1078/1078 [06:44<00:00,  2.67it/s, loss=0.72]\n",
      "Training  : 100%|██████████████████████████████████████████████████████| 1078/1078 [06:43<00:00,  2.67it/s, loss=0.392]\n",
      "Training  : 100%|██████████████████████████████████████████████████████| 1078/1078 [06:43<00:00,  2.67it/s, loss=0.229]\n",
      "Predicting: 100%|████████████████████████████████████████████████████████████████████| 308/308 [00:18<00:00, 16.93it/s]\n",
      "Predicting: 100%|██████████████████████████████████████████████████████████████████| 4617/4617 [02:02<00:00, 37.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 4 log_loss : 1.182348691795586\n",
      "fold 4 accuracy_score : 0.6801948051948052\n",
      "Building sklearn text classifier...\n",
      "Loading bert-base-cased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 8617, validation data size: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|███████████████████████████████████████████████████████| 1078/1078 [06:43<00:00,  2.67it/s, loss=1.54]\n",
      "Training  : 100%|██████████████████████████████████████████████████████| 1078/1078 [06:44<00:00,  2.67it/s, loss=0.727]\n",
      "Training  : 100%|██████████████████████████████████████████████████████| 1078/1078 [06:43<00:00,  2.67it/s, loss=0.405]\n",
      "Training  : 100%|███████████████████████████████████████████████████████| 1078/1078 [06:43<00:00,  2.67it/s, loss=0.24]\n",
      "Predicting: 100%|████████████████████████████████████████████████████████████████████| 308/308 [00:18<00:00, 16.96it/s]\n",
      "Predicting: 100%|██████████████████████████████████████████████████████████████████| 4617/4617 [02:02<00:00, 37.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 5 log_loss : 0.8792634128709832\n",
      "fold 5 accuracy_score : 0.7532467532467533\n",
      "Building sklearn text classifier...\n",
      "Loading bert-base-cased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 8617, validation data size: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|███████████████████████████████████████████████████████| 1078/1078 [06:43<00:00,  2.67it/s, loss=1.54]\n",
      "Training  : 100%|██████████████████████████████████████████████████████| 1078/1078 [06:44<00:00,  2.67it/s, loss=0.717]\n",
      "Training  : 100%|██████████████████████████████████████████████████████| 1078/1078 [06:44<00:00,  2.67it/s, loss=0.398]\n",
      "Training  : 100%|██████████████████████████████████████████████████████| 1078/1078 [06:44<00:00,  2.67it/s, loss=0.228]\n",
      "Predicting: 100%|████████████████████████████████████████████████████████████████████| 308/308 [00:18<00:00, 16.92it/s]\n",
      "Predicting: 100%|██████████████████████████████████████████████████████████████████| 4617/4617 [02:02<00:00, 37.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 6 log_loss : 0.961283171279737\n",
      "fold 6 accuracy_score : 0.7402597402597403\n",
      "Building sklearn text classifier...\n",
      "Loading bert-base-cased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 8617, validation data size: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|███████████████████████████████████████████████████████| 1078/1078 [06:44<00:00,  2.66it/s, loss=1.54]\n",
      "Training  : 100%|██████████████████████████████████████████████████████| 1078/1078 [06:44<00:00,  2.66it/s, loss=0.722]\n",
      "Training  : 100%|██████████████████████████████████████████████████████| 1078/1078 [06:44<00:00,  2.67it/s, loss=0.398]\n",
      "Training  : 100%|██████████████████████████████████████████████████████| 1078/1078 [06:45<00:00,  2.66it/s, loss=0.235]\n",
      "Predicting: 100%|████████████████████████████████████████████████████████████████████| 308/308 [00:18<00:00, 16.53it/s]\n",
      "Predicting: 100%|██████████████████████████████████████████████████████████████████| 4617/4617 [02:02<00:00, 37.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 7 log_loss : 0.9017799040638326\n",
      "fold 7 accuracy_score : 0.7288961038961039\n",
      "Building sklearn text classifier...\n",
      "Loading bert-base-cased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 8617, validation data size: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|███████████████████████████████████████████████████████| 1078/1078 [06:43<00:00,  2.67it/s, loss=1.54]\n",
      "Training  : 100%|██████████████████████████████████████████████████████| 1078/1078 [06:44<00:00,  2.66it/s, loss=0.727]\n",
      "Training  : 100%|██████████████████████████████████████████████████████| 1078/1078 [06:44<00:00,  2.67it/s, loss=0.411]\n",
      "Training  : 100%|███████████████████████████████████████████████████████| 1078/1078 [06:44<00:00,  2.67it/s, loss=0.24]\n",
      "Predicting: 100%|████████████████████████████████████████████████████████████████████| 308/308 [00:18<00:00, 17.02it/s]\n",
      "Predicting: 100%|██████████████████████████████████████████████████████████████████| 4617/4617 [02:03<00:00, 37.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 8 log_loss : 0.9164883734317969\n",
      "fold 8 accuracy_score : 0.7483766233766234\n",
      "Building sklearn text classifier...\n",
      "Loading bert-base-cased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 8618, validation data size: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|███████████████████████████████████████████████████████| 1078/1078 [06:44<00:00,  2.67it/s, loss=1.54]\n",
      "Training  : 100%|██████████████████████████████████████████████████████| 1078/1078 [06:44<00:00,  2.66it/s, loss=0.723]\n",
      "Training  : 100%|██████████████████████████████████████████████████████| 1078/1078 [06:45<00:00,  2.66it/s, loss=0.398]\n",
      "Training  : 100%|██████████████████████████████████████████████████████| 1078/1078 [06:44<00:00,  2.67it/s, loss=0.227]\n",
      "Predicting: 100%|████████████████████████████████████████████████████████████████████| 308/308 [00:18<00:00, 16.93it/s]\n",
      "Predicting: 100%|██████████████████████████████████████████████████████████████████| 4617/4617 [02:02<00:00, 37.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 9 log_loss : 0.9783276064052373\n",
      "fold 9 accuracy_score : 0.7430894308943089\n",
      "Building sklearn text classifier...\n",
      "Loading bert-base-cased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 8618, validation data size: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|███████████████████████████████████████████████████████| 1078/1078 [06:44<00:00,  2.67it/s, loss=1.54]\n",
      "Training  : 100%|██████████████████████████████████████████████████████| 1078/1078 [06:44<00:00,  2.66it/s, loss=0.721]\n",
      "Training  : 100%|██████████████████████████████████████████████████████| 1078/1078 [06:44<00:00,  2.67it/s, loss=0.394]\n",
      "Training  : 100%|██████████████████████████████████████████████████████| 1078/1078 [06:44<00:00,  2.66it/s, loss=0.226]\n",
      "Predicting: 100%|████████████████████████████████████████████████████████████████████| 308/308 [00:18<00:00, 16.84it/s]\n",
      "Predicting: 100%|██████████████████████████████████████████████████████████████████| 4617/4617 [02:02<00:00, 37.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 10 log_loss : 0.9699831385037273\n",
      "fold 10 accuracy_score : 0.7252032520325203\n",
      "Building sklearn text classifier...\n",
      "Loading bert-base-cased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 8618, validation data size: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|███████████████████████████████████████████████████████| 1078/1078 [06:44<00:00,  2.66it/s, loss=1.54]\n",
      "Training  : 100%|██████████████████████████████████████████████████████| 1078/1078 [06:44<00:00,  2.67it/s, loss=0.721]\n",
      "Training  : 100%|██████████████████████████████████████████████████████| 1078/1078 [06:44<00:00,  2.67it/s, loss=0.397]\n",
      "Training  : 100%|██████████████████████████████████████████████████████| 1078/1078 [06:44<00:00,  2.66it/s, loss=0.229]\n",
      "Predicting: 100%|████████████████████████████████████████████████████████████████████| 308/308 [00:18<00:00, 17.02it/s]\n",
      "Predicting: 100%|██████████████████████████████████████████████████████████████████| 4617/4617 [02:02<00:00, 37.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 11 log_loss : 0.965720923263639\n",
      "fold 11 accuracy_score : 0.7154471544715447\n",
      "Building sklearn text classifier...\n",
      "Loading bert-base-cased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 8618, validation data size: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|███████████████████████████████████████████████████████| 1078/1078 [06:44<00:00,  2.67it/s, loss=1.55]\n",
      "Training  : 100%|██████████████████████████████████████████████████████| 1078/1078 [06:44<00:00,  2.67it/s, loss=0.736]\n",
      "Training  : 100%|██████████████████████████████████████████████████████| 1078/1078 [06:44<00:00,  2.66it/s, loss=0.419]\n",
      "Training  : 100%|██████████████████████████████████████████████████████| 1078/1078 [06:44<00:00,  2.66it/s, loss=0.238]\n",
      "Predicting: 100%|████████████████████████████████████████████████████████████████████| 308/308 [00:18<00:00, 16.87it/s]\n",
      "Predicting: 100%|██████████████████████████████████████████████████████████████████| 4617/4617 [02:02<00:00, 37.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 12 log_loss : 0.8927514750458407\n",
      "fold 12 accuracy_score : 0.7414634146341463\n",
      "Building sklearn text classifier...\n",
      "Loading bert-base-cased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 8618, validation data size: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|███████████████████████████████████████████████████████| 1078/1078 [06:41<00:00,  2.68it/s, loss=1.55]\n",
      "Training  : 100%|██████████████████████████████████████████████████████| 1078/1078 [06:41<00:00,  2.68it/s, loss=0.722]\n",
      "Training  : 100%|██████████████████████████████████████████████████████| 1078/1078 [06:42<00:00,  2.68it/s, loss=0.395]\n",
      "Training  : 100%|███████████████████████████████████████████████████████| 1078/1078 [06:41<00:00,  2.68it/s, loss=0.23]\n",
      "Predicting: 100%|████████████████████████████████████████████████████████████████████| 308/308 [00:17<00:00, 17.16it/s]\n",
      "Predicting: 100%|██████████████████████████████████████████████████████████████████| 4617/4617 [02:01<00:00, 37.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 13 log_loss : 1.037271712600715\n",
      "fold 13 accuracy_score : 0.7219512195121951\n",
      "Building sklearn text classifier...\n",
      "Loading bert-base-cased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 8618, validation data size: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|███████████████████████████████████████████████████████| 1078/1078 [06:42<00:00,  2.68it/s, loss=1.54]\n",
      "Training  : 100%|██████████████████████████████████████████████████████| 1078/1078 [06:41<00:00,  2.68it/s, loss=0.728]\n",
      "Training  : 100%|██████████████████████████████████████████████████████| 1078/1078 [06:42<00:00,  2.68it/s, loss=0.398]\n",
      "Training  : 100%|██████████████████████████████████████████████████████| 1078/1078 [06:42<00:00,  2.68it/s, loss=0.229]\n",
      "Predicting: 100%|████████████████████████████████████████████████████████████████████| 308/308 [00:17<00:00, 17.19it/s]\n",
      "Predicting: 100%|██████████████████████████████████████████████████████████████████| 4617/4617 [02:02<00:00, 37.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 14 log_loss : 1.0132728217006193\n",
      "fold 14 accuracy_score : 0.7382113821138211\n",
      "Building sklearn text classifier...\n",
      "Loading bert-base-cased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 8618, validation data size: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|███████████████████████████████████████████████████████| 1078/1078 [06:42<00:00,  2.68it/s, loss=1.54]\n",
      "Training  : 100%|██████████████████████████████████████████████████████| 1078/1078 [06:43<00:00,  2.67it/s, loss=0.735]\n",
      "Training  : 100%|██████████████████████████████████████████████████████| 1078/1078 [06:41<00:00,  2.68it/s, loss=0.395]\n",
      "Training  : 100%|███████████████████████████████████████████████████████| 1078/1078 [06:42<00:00,  2.68it/s, loss=0.23]\n",
      "Predicting: 100%|████████████████████████████████████████████████████████████████████| 308/308 [00:18<00:00, 16.40it/s]\n",
      "Predicting: 100%|██████████████████████████████████████████████████████████████████| 4617/4617 [02:02<00:00, 37.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 15 log_loss : 0.9823714066750221\n",
      "fold 15 accuracy_score : 0.734959349593496\n",
      "seed 0 log_loss : 0.9826859028141225\n",
      "seed 0 accuracy_score : 0.7302068666738871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lucky_seeds = np.random.randint(0, 1000, num_seed_tr)\n",
    "\n",
    "for i, seed in enumerate(lucky_seeds):\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=splits_tr, random_state=seed, shuffle=True)\n",
    "    cv = np.zeros((rows_train, num_classes))\n",
    "    pred_test = np.zeros((rows_test, num_classes))\n",
    "\n",
    "    for n, (train_idx, val_idx) in enumerate(kfold.split(train_x, train_y)):\n",
    "        \n",
    "        x_train, x_val = train_x.iloc[train_idx], train_x.iloc[val_idx]\n",
    "        y_train, y_val = train_y.iloc[train_idx].values.ravel(), train_y.iloc[val_idx].values.ravel()\n",
    "        \n",
    "#         print(f'fold {n+1} start')\n",
    "        \n",
    "        BERTModel = BertClassifier(bert_model=\"bert-base-cased\", random_state=basic_seed,\n",
    "                                   epochs=4, validation_fraction=0, train_batch_size=8, eval_batch_size=2)\n",
    "        BERTModel.fit(x_train, y_train)\n",
    "        \n",
    "        cv[val_idx, :] = BERTModel.predict_proba(x_val)\n",
    "        pred_test += BERTModel.predict_proba(test_x) / splits_tr\n",
    "        \n",
    "        print(f'fold {n+1}', 'log_loss :', log_loss(y_val, cv[val_idx]))\n",
    "        print(f'fold {n+1}', 'accuracy_score :', accuracy_score(y_val, np.argmax(cv[val_idx], axis=1)))\n",
    "        \n",
    "    pred_dict['bert'+str(seed)] = cv\n",
    "    pred_test_dict['bert'+str(seed)] = pred_test\n",
    "    print(f'seed {seed}', 'log_loss :', log_loss(train_y, cv))\n",
    "    print(f'seed {seed}', 'accuracy_score :', accuracy_score(train_y, np.argmax(cv, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c75ea5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bert0': array([[1.00496174e-04, 1.24635262e-04, 2.01725619e-04, ...,\n",
       "         5.10851794e-04, 5.70034936e-05, 1.59385076e-04],\n",
       "        [3.60107457e-04, 1.12816738e-03, 5.04482188e-04, ...,\n",
       "         6.21390645e-04, 1.92494903e-04, 1.22765472e-04],\n",
       "        [1.78482354e-01, 1.39642181e-03, 3.91481211e-04, ...,\n",
       "         2.64126738e-03, 3.76746524e-03, 7.22015619e-01],\n",
       "        ...,\n",
       "        [1.00949011e-03, 2.22144707e-04, 4.13263944e-04, ...,\n",
       "         9.92110312e-01, 8.57076084e-04, 4.63111181e-04],\n",
       "        [1.50617445e-04, 2.20812717e-03, 4.76216432e-03, ...,\n",
       "         2.20376067e-04, 4.76652145e-04, 1.00054033e-03],\n",
       "        [3.43922037e-03, 3.89210327e-04, 2.00755894e-03, ...,\n",
       "         1.68654369e-03, 6.16816461e-01, 6.88752579e-03]])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f890dc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb68efc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8356520",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2f286bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2 = pred_dict['bert0']\n",
    "pred_test2 = pred_test_dict['bert0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b1162ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dict(model):\n",
    "    with open('../pickle/pred_dict_'+model+'.pickle', 'rb') as fw:\n",
    "        pred_dict_new_local = pickle.load(fw)\n",
    "    with open('../pickle/pred_test_dict_'+model+'.pickle', 'rb') as fw:\n",
    "        pred_test_dict_new_local = pickle.load(fw)\n",
    "    return pred_dict_new_local, pred_test_dict_new_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "609b7e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dict_mlp, pred_test_dict_mlp = load_dict('mlp_cv15')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c875cbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.zeros((rows_train, num_classes))\n",
    "for _, value in pred_dict_mlp.items():\n",
    "    pred += value\n",
    "pred /= len(pred_dict_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b3bba20",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = np.zeros((rows_test, num_classes))\n",
    "for _, value in pred_test_dict_mlp.items():\n",
    "    pred_test += value\n",
    "pred_test /= len(pred_test_dict_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bd5d23d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.796274\n"
     ]
    }
   ],
   "source": [
    "print(f'accuracy_score: {accuracy_score(train_y, np.argmax(pred*0.86+pred2*0.14, axis=1)):.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2740bae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = np.argmax(pred_test*0.86+pred_test2*0.14, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a90d92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dict['bert0'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a36531",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f273d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertClassifier(bert_model=\"bert-base-multilingual-uncased\", epochs=3, learning_rate=4e-05, validation_fraction=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf17d9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d3ce3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adeee656",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f0408e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lucky_seeds = np.random.randint(0, 1000, num_seed_tr)\n",
    "\n",
    "for i, seed in enumerate(lucky_seeds):\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=splits_tr, random_state=seed, shuffle=True)\n",
    "    cv = np.zeros((rows_train, num_classes))\n",
    "    pred_test = np.zeros((rows_test, num_classes))\n",
    "\n",
    "    for n, (train_idx, val_idx) in enumerate(kfold.split(train_x, train_y)):\n",
    "        \n",
    "        x_train, x_val = train_x.iloc[train_idx], train_x.iloc[val_idx]\n",
    "        y_train, y_val = train_y.iloc[train_idx].values.ravel(), train_y.iloc[val_idx].values.ravel()\n",
    "        \n",
    "        vectorizer = TfidfVectorizer(ngram_range=(1, 2))\n",
    "        vectorizer.fit(x_train)\n",
    "        x_train = vectorizer.transform(x_train)\n",
    "        x_val = vectorizer.transform(x_val)\n",
    "        x_test = vectorizer.transform(test_x)\n",
    "        \n",
    "        print(f'fold {n+1} start')\n",
    "        \n",
    "        MLPModel = MLPClassifier(max_iter=12, random_state=basic_seed, verbose=False)\n",
    "        MLPModel.fit(x_train, y_train)\n",
    "        \n",
    "        cv[val_idx, :] = MLPModel.predict_proba(x_val)\n",
    "\n",
    "#         cat_best_hyperparams = {\"iterations\": 10000, \"learning_rate\": 0.3}\n",
    "#         catmodel = CatBoostClassifier(**cat_best_hyperparams)\n",
    "#         catmodel.fit(x_train, y_train, eval_set=[(x_val, y_val)], early_stopping_rounds=50, verbose=10)\n",
    "        \n",
    "#         cv[val_idx] = catmodel.predict(x_val)\n",
    "        pred_test += MLPModel.predict_proba(x_test) / splits_tr\n",
    "        \n",
    "        print(f'fold {n+1}', 'log_loss :', log_loss(y_val, cv[val_idx]))\n",
    "        print(f'fold {n+1}', 'accuracy_score :', accuracy_score(y_val, np.argmax(cv[val_idx], axis=1)))\n",
    "        \n",
    "    pred_dict['mlp'+str(seed)] = cv\n",
    "    pred_test_dict['mlp'+str(seed)] = pred_test\n",
    "    print(f'seed {seed}', 'log_loss :', log_loss(train_y, cv))\n",
    "    print(f'seed {seed}', 'accuracy_score :', accuracy_score(train_y, np.argmax(cv, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca1d7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_dict(model, pred_dict, pred_test_dict):\n",
    "    pred_dict_local = {}\n",
    "    for key, value in pred_dict.items():\n",
    "        if model in key:\n",
    "            pred_dict_local[key]=value\n",
    "\n",
    "    pred_test_dict_local = {}\n",
    "    for key, value in pred_test_dict.items():\n",
    "        if model in key:\n",
    "            pred_test_dict_local[key]=value\n",
    "\n",
    "    pred_dict_new_local = dict(sorted(\n",
    "        pred_dict_local.items(), \n",
    "        key=lambda x:accuracy_score((train_y), np.argmax(list(x[1]), axis=1)), reverse=False)[:5])\n",
    "    pred_test_dict_new_local = {}\n",
    "    for key, value in pred_dict_new_local.items():\n",
    "        pred_test_dict_new_local[key]=pred_test_dict_local[key]\n",
    "        \n",
    "    return pred_dict_new_local, pred_test_dict_new_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7172b061",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dict(model, pred_dict, pred_test_dict):\n",
    "    with open('../pickle/pred_dict_'+model+'.pickle', 'wb') as fw:\n",
    "        pickle.dump(pred_dict, fw)\n",
    "    with open('../pickle/pred_test_dict_'+model+'.pickle', 'wb') as fw:\n",
    "        pickle.dump(pred_test_dict, fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8a25b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dict_bert, pred_test_dict_bert = sort_dict('bert', pred_dict, pred_test_dict)\n",
    "save_dict('bert', pred_dict_bert, pred_test_dict_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d66d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dict_mlp, pred_test_dict_mlp = sort_dict('mlp', pred_dict, pred_test_dict)\n",
    "save_dict('mlp', pred_dict_mlp, pred_test_dict_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b7a9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.zeros((rows_train, num_classes))\n",
    "for _, value in pred_dict_mlp.items():\n",
    "    pred += value\n",
    "pred /= len(pred_dict_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd0991b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'accuracy_score: {accuracy_score(train_y, np.argmax(pred, axis=1)):.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca6380f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = np.zeros((rows_test, num_classes))\n",
    "for _, value in pred_test_dict_mlp.items():\n",
    "    pred_test += value\n",
    "pred_test /= len(pred_test_dict_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76eea18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dict(model):\n",
    "    with open('../pickle/pred_dict_'+model+'.pickle', 'rb') as fw:\n",
    "        pred_dict_new_local = pickle.load(fw)\n",
    "    with open('../pickle/pred_test_dict_'+model+'.pickle', 'rb') as fw:\n",
    "        pred_test_dict_new_local = pickle.load(fw)\n",
    "    return pred_dict_new_local, pred_test_dict_new_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af519682",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dict_mlp2, pred_test_dict_mlp2 = load_dict('mlp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3a119e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2 = np.zeros((rows_train, num_classes))\n",
    "for _, value in pred_dict_mlp2.items():\n",
    "    pred2 += value\n",
    "pred2 /= len(pred_dict_mlp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006c97f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test2 = np.zeros((rows_test, num_classes))\n",
    "for _, value in pred_test_dict_mlp2.items():\n",
    "    pred_test2 += value\n",
    "pred_test2 /= len(pred_test_dict_mlp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a195bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'accuracy_score: {accuracy_score(train_y, np.argmax(pred*0.6+pred2*0.4, axis=1)):.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd589551",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = np.argmax(pred_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1abd55c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission[\"target\"] = pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1a7ee0a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15    567\n",
       "6     538\n",
       "3     532\n",
       "16    507\n",
       "1     505\n",
       "5     501\n",
       "7     500\n",
       "13    499\n",
       "2     491\n",
       "9     490\n",
       "10    481\n",
       "17    480\n",
       "14    465\n",
       "12    447\n",
       "4     444\n",
       "8     443\n",
       "11    442\n",
       "0     401\n",
       "18    359\n",
       "19    141\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1670641e",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_name = '20220410'\n",
    "submission_number = '1'\n",
    "submission.to_csv(f'../submission/{submission_name}-{submission_number}.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d166dc91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9228</th>\n",
       "      <td>9228</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9229</th>\n",
       "      <td>9229</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9230</th>\n",
       "      <td>9230</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9231</th>\n",
       "      <td>9231</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9232</th>\n",
       "      <td>9232</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9233 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  target\n",
       "0        0       3\n",
       "1        1      16\n",
       "2        2      11\n",
       "3        3       8\n",
       "4        4      13\n",
       "...    ...     ...\n",
       "9228  9228      16\n",
       "9229  9229       1\n",
       "9230  9230       4\n",
       "9231  9231       0\n",
       "9232  9232      12\n",
       "\n",
       "[9233 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f64d0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
