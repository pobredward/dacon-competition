{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a37225f",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aebeef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from glob import glob\n",
    "from itertools import permutations\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "\n",
    "import optuna\n",
    "from optuna import Trial\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.visualization import plot_contour, plot_optimization_history\n",
    "from optuna.visualization import plot_parallel_coordinate, plot_slice, plot_param_importances\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from catboost import Pool, CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf0651d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../data/train.csv\", index_col=\"id\")\n",
    "test = pd.read_csv(\"../data/test.csv\", index_col=\"id\")\n",
    "submission = pd.read_csv(\"../data/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f727d13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dir(dir):\n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)\n",
    "        print(\"Created Directory :\", dir)\n",
    "    else:\n",
    "        print(\"Directory already existed :\", dir)\n",
    "create_dir(\"../pickle\")\n",
    "create_dir(\"../model\")\n",
    "create_dir(\"../submission\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4dcb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train['text']\n",
    "train_y = train['target']\n",
    "test_x = test['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48114ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_train = train.shape[0] # 주어진 train data의 row 수\n",
    "rows_test = test.shape[0] # 주어진 test data의 row 수\n",
    "num_classes = len(train_y.unique())\n",
    "num_trial = 100 # 파라미터 튜닝을 몇 번 진행하는지의 수\n",
    "splits_hp = 3 # 파라미터 튜닝을 진행할 때의 kfold 수\n",
    "splits_tr = 15 # 모델 트레이닝을 진행할 때의 kfold 수\n",
    "basic_seed = 42 # default seed\n",
    "num_seed_tr = 5 # 트레이닝 seed 개수\n",
    "sel_seed = 4 # 선택할 seed 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105cbc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dict = {}\n",
    "pred_test_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7feea0c",
   "metadata": {},
   "source": [
    "# LGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fc0329",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_objective(trial: Trial) -> float:\n",
    "    score_hp = []\n",
    "    for seed_hp in [0]:\n",
    "        params_lgb = {\n",
    "            \"random_state\": basic_seed,\n",
    "            \"verbosity\": -1,\n",
    "            \"n_estimators\": 10000,\n",
    "            \"objective\": \"multiclass\",\n",
    "            \"metric\": \"multi_logloss\",\n",
    "            \"learning_rate\": trial.suggest_uniform(\"learning_rate\", 4e-2, 1e-1), # default=0.1, range=[0,1]\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 5, 12), # default=-1\n",
    "            \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 1e-2, 1e+0), # default=0\n",
    "            \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 1e-2, 1e+1), # default=0\n",
    "            \"num_leaves\": trial.suggest_int(\"num_leaves\", 31, 4000), # default=31, range=(1,130172]\n",
    "            \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.2, 0.8), # feature_fraction, default=1\n",
    "            \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0), # bagging_fraction, default=1, range=[0,1]\n",
    "            \"subsample_freq\": trial.suggest_int(\"subsample_freq\", 1, 20), # bagging_freq, default=0\n",
    "            \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 20, 30), # min_data_in_leaf, default=20 \n",
    "            \"max_bin\": trial.suggest_int(\"max_bin\", 100, 400),\n",
    "        }\n",
    "\n",
    "        kfold = StratifiedKFold(n_splits=splits_hp, random_state=seed_hp, shuffle=True)\n",
    "        cv = np.zeros((rows_train, num_classes))\n",
    "\n",
    "        for n, (train_idx, val_idx) in enumerate(kfold.split(train_x, train_y)):\n",
    "            \n",
    "            x_train, x_val = train_x.iloc[train_idx], train_x.iloc[val_idx]\n",
    "            y_train, y_val = train_y.iloc[train_idx].values.ravel(), train_y.iloc[val_idx].values.ravel()\n",
    "\n",
    "            vectorizer = TfidfVectorizer(ngram_range=(1, 2))\n",
    "            vectorizer.fit(x_train)\n",
    "            x_train = vectorizer.transform(x_train)\n",
    "            x_val = vectorizer.transform(x_val)\n",
    "            x_test = vectorizer.transform(test_x)\n",
    "\n",
    "            lgbmodel = LGBMClassifier(**params_lgb)\n",
    "\n",
    "#             print(f'fold {n+1} start')\n",
    "        \n",
    "            lgbmodel.fit(x_train, y_train, eval_set=[(x_val, y_val)], early_stopping_rounds=30, verbose=-1) \n",
    "            cv[val_idx, :] = lgbmodel.predict_proba(x_val)\n",
    "        \n",
    "#             print(f\"fold{n+1} log_loss:\", log_loss(y_val, cv[val_idx]))\n",
    "            score_hp.append(log_loss(y_val, cv[val_idx]))\n",
    "            break\n",
    "        \n",
    "#         score_hp.append(log_loss(train_y, cv))\n",
    "    \n",
    "    np.mean(score_hp)\n",
    "    return np.mean(score_hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9fbb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = TPESampler(seed=basic_seed)\n",
    "lgb_study = optuna.create_study(study_name=\"lgb_parameter_opt\", direction=\"minimize\", sampler=sampler)\n",
    "lgb_study.optimize(lgb_objective, n_trials=num_trial)\n",
    "\n",
    "lgb_best_hyperparams = lgb_study.best_trial.params\n",
    "lgb_base_hyperparams = {\"random_state\": basic_seed, \"verbosity\": -1, \n",
    "                        \"n_estimators\": 10000, \"objective\": \"multiclass\", \"metric\": \"multi_logloss\"}\n",
    "lgb_best_hyperparams.update(lgb_base_hyperparams)\n",
    "\n",
    "with open('../pickle/lgb_best_hyperparams.pickle', 'wb') as fw:\n",
    "    pickle.dump(lgb_best_hyperparams, fw)\n",
    "print(\"The best hyperparameters are:\\n\", lgb_best_hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76454fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../pickle/lgb_best_hyperparams.pickle', 'rb') as fw:\n",
    "#     lgb_best_hyperparams = pickle.load(fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c6b475",
   "metadata": {},
   "outputs": [],
   "source": [
    "lucky_seeds = np.random.randint(0, 1000, num_seed_tr)\n",
    "\n",
    "for i, seed in enumerate(lucky_seeds):\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=splits_tr, random_state=seed, shuffle=True)\n",
    "    cv = np.zeros((rows_train, num_classes))\n",
    "    pred_test = np.zeros((rows_test, num_classes))\n",
    "\n",
    "    for n, (train_idx, val_idx) in enumerate(kfold.split(train_x, train_y)):\n",
    "        \n",
    "        x_train, x_val = train_x.iloc[train_idx], train_x.iloc[val_idx]\n",
    "        y_train, y_val = train_y.iloc[train_idx].values.ravel(), train_y.iloc[val_idx].values.ravel()\n",
    "        \n",
    "        vectorizer = TfidfVectorizer(ngram_range=(1, 2))\n",
    "        vectorizer.fit(x_train)\n",
    "        x_train = vectorizer.transform(x_train)\n",
    "        x_val = vectorizer.transform(x_val)\n",
    "        x_test = vectorizer.transform(test_x)\n",
    "\n",
    "        lgbmodel = LGBMClassifier(**lgb_best_hyperparams)\n",
    "\n",
    "#         print(f'fold {n+1} start')\n",
    "        \n",
    "        lgbmodel.fit(x_train, y_train, eval_set=[(x_val, y_val)], early_stopping_rounds=30, verbose=-1) \n",
    "        cv[val_idx, :] = lgbmodel.predict_proba(x_val)\n",
    "        pred_test += lgbmodel.predict_proba(x_test) / splits_tr\n",
    "        \n",
    "        print(f'fold {n+1}', 'log_loss :', log_loss(y_val, cv[val_idx]))\n",
    "        print(f'fold {n+1}', 'accuracy_score :', accuracy_score(y_val, np.argmax(cv[val_idx], axis=1)))\n",
    "        \n",
    "    pred_dict['lgb'+str(seed)] = cv\n",
    "    pred_test_dict['lgb'+str(seed)] = pred_test\n",
    "    print(f'seed {seed}', 'log_loss :', log_loss(train_y, cv))\n",
    "    print(f'seed {seed}', 'accuracy_score :', accuracy_score(train_y, np.argmax(cv, axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db21de6",
   "metadata": {},
   "source": [
    "# MLP1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9967c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lucky_seeds = np.random.randint(0, 1000, num_seed_tr)\n",
    "\n",
    "for i, seed in enumerate(lucky_seeds):\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=splits_tr, random_state=seed, shuffle=True)\n",
    "    cv = np.zeros((rows_train, num_classes))\n",
    "    pred_test = np.zeros((rows_test, num_classes))\n",
    "\n",
    "    for n, (train_idx, val_idx) in enumerate(kfold.split(train_x, train_y)):\n",
    "        \n",
    "        x_train, x_val = train_x.iloc[train_idx], train_x.iloc[val_idx]\n",
    "        y_train, y_val = train_y.iloc[train_idx].values.ravel(), train_y.iloc[val_idx].values.ravel()\n",
    "        \n",
    "        vectorizer = TfidfVectorizer(ngram_range=(1, 2))\n",
    "        vectorizer.fit(x_train)\n",
    "        x_train = vectorizer.transform(x_train)\n",
    "        x_val = vectorizer.transform(x_val)\n",
    "        x_test = vectorizer.transform(test_x)\n",
    "        \n",
    "#         print(f'fold {n+1} start')\n",
    "        \n",
    "        MLPModel = MLPClassifier(max_iter=12, hidden_layer_sizes=100, random_state=basic_seed, verbose=False)\n",
    "        MLPModel.fit(x_train, y_train)\n",
    "        \n",
    "        cv[val_idx, :] = MLPModel.predict_proba(x_val)\n",
    "        \n",
    "        pred_test += MLPModel.predict_proba(x_test) / splits_tr\n",
    "        \n",
    "        print(f'fold {n+1}', 'log_loss :', log_loss(y_val, cv[val_idx]))\n",
    "        print(f'fold {n+1}', 'accuracy_score :', accuracy_score(y_val, np.argmax(cv[val_idx], axis=1)))\n",
    "        \n",
    "    pred_dict['mlp1'+str(seed)] = cv\n",
    "    pred_test_dict['mlp1'+str(seed)] = pred_test\n",
    "    print(f'seed {seed}', 'log_loss :', log_loss(train_y, cv))\n",
    "    print(f'seed {seed}', 'accuracy_score :', accuracy_score(train_y, np.argmax(cv, axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3745cb",
   "metadata": {},
   "source": [
    "# MLP2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81f4a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lucky_seeds = np.random.randint(0, 1000, num_seed_tr)\n",
    "\n",
    "for i, seed in enumerate(lucky_seeds):\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=splits_tr, random_state=seed, shuffle=True)\n",
    "    cv = np.zeros((rows_train, num_classes))\n",
    "    pred_test = np.zeros((rows_test, num_classes))\n",
    "\n",
    "    for n, (train_idx, val_idx) in enumerate(kfold.split(train_x, train_y)):\n",
    "        \n",
    "        x_train, x_val = train_x.iloc[train_idx], train_x.iloc[val_idx]\n",
    "        y_train, y_val = train_y.iloc[train_idx].values.ravel(), train_y.iloc[val_idx].values.ravel()\n",
    "        \n",
    "        vectorizer = TfidfVectorizer(ngram_range=(1, 2))\n",
    "        vectorizer.fit(x_train)\n",
    "        x_train = vectorizer.transform(x_train)\n",
    "        x_val = vectorizer.transform(x_val)\n",
    "        x_test = vectorizer.transform(test_x)\n",
    "        \n",
    "#         print(f'fold {n+1} start')\n",
    "        \n",
    "        MLPModel = MLPClassifier(max_iter=3, hidden_layer_sizes=250, random_state=basic_seed, verbose=False)\n",
    "        MLPModel.fit(x_train, y_train)\n",
    "        \n",
    "        cv[val_idx, :] = MLPModel.predict_proba(x_val)\n",
    "        \n",
    "        pred_test += MLPModel.predict_proba(x_test) / splits_tr\n",
    "        \n",
    "        print(f'fold {n+1}', 'log_loss :', log_loss(y_val, cv[val_idx]))\n",
    "        print(f'fold {n+1}', 'accuracy_score :', accuracy_score(y_val, np.argmax(cv[val_idx], axis=1)))\n",
    "        \n",
    "    pred_dict['mlp2'+str(seed)] = cv\n",
    "    pred_test_dict['mlp2'+str(seed)] = pred_test\n",
    "    print(f'seed {seed}', 'log_loss :', log_loss(train_y, cv))\n",
    "    print(f'seed {seed}', 'accuracy_score :', accuracy_score(train_y, np.argmax(cv, axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a02ddb",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb03d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_dict(model, pred_dict, pred_test_dict):\n",
    "    pred_dict_local = {}\n",
    "    for key, value in pred_dict.items():\n",
    "        if model in key:\n",
    "            pred_dict_local[key]=value\n",
    "\n",
    "    pred_test_dict_local = {}\n",
    "    for key, value in pred_test_dict.items():\n",
    "        if model in key:\n",
    "            pred_test_dict_local[key]=value\n",
    "\n",
    "    pred_dict_new_local = dict(sorted(\n",
    "        pred_dict_local.items(), \n",
    "        key=lambda x:accuracy_score((train_y), np.argmax(list(x[1]), axis=1)), reverse=False)[:5])\n",
    "    pred_test_dict_new_local = {}\n",
    "    for key, value in pred_dict_new_local.items():\n",
    "        pred_test_dict_new_local[key]=pred_test_dict_local[key]\n",
    "        \n",
    "    return pred_dict_new_local, pred_test_dict_new_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c321615",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dict(model, pred_dict, pred_test_dict):\n",
    "    with open('../pickle/pred_dict_'+model+'.pickle', 'wb') as fw:\n",
    "        pickle.dump(pred_dict, fw)\n",
    "    with open('../pickle/pred_test_dict_'+model+'.pickle', 'wb') as fw:\n",
    "        pickle.dump(pred_test_dict, fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775046bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dict_lgb, pred_test_dict_lgb = sort_dict('lgb', pred_dict, pred_test_dict)\n",
    "save_dict('lgb', pred_dict_lgb, pred_test_dict_lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7924c7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dict_mlp1, pred_test_dict_mlp1 = sort_dict('mlp1', pred_dict, pred_test_dict)\n",
    "save_dict('mlp_epoch3_layer250_cv15', pred_dict_mlp1, pred_test_dict_mlp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42317b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dict_mlp2, pred_test_dict_mlp2 = sort_dict('mlp2', pred_dict, pred_test_dict)\n",
    "save_dict('mlp_epoch3_layer250_cv15', pred_dict_mlp2, pred_test_dict_mlp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1162ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dict(model):\n",
    "    with open('../pickle/pred_dict_'+model+'.pickle', 'rb') as fw:\n",
    "        pred_dict_new_local = pickle.load(fw)\n",
    "    with open('../pickle/pred_test_dict_'+model+'.pickle', 'rb') as fw:\n",
    "        pred_test_dict_new_local = pickle.load(fw)\n",
    "    return pred_dict_new_local, pred_test_dict_new_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7f6635",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dict_lgb, pred_test_dict_lgb = load_dict('lgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609b7e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dict_mlp1, pred_test_dict_mlp1 = load_dict('mlp_epoch12_layer100_cv15')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61705932",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dict_mlp2, pred_test_dict_mlp2 = load_dict('mlp_epoch3_layer250_cv15')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a56b96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate = np.arange(0, 15)\n",
    "permute = permutations(candidate, 3)\n",
    "score = {}\n",
    "for i in tqdm(list(permute)):\n",
    "    pred_permute = (\n",
    "                    sum(pred_dict_lgb.values())/sel_seed * i[0] +\n",
    "                    sum(pred_dict_mlp1.values())/sel_seed * i[1] +\n",
    "                    sum(pred_dict_mlp2.values())/sel_seed * i[2]\n",
    "                   )\n",
    "    score[i] = accuracy_score(train_y, np.argmax(pred_permute/sum(i), axis=1))\n",
    "\n",
    "score = dict(sorted(score.items(), key=lambda x: x[1], reverse=True)[:5])\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470748d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = (sum(pred_dict_lgb.values())/sel_seed * list(score.keys())[0][0] +\n",
    "        sum(pred_dict_mlp1.values())/sel_seed * list(score.keys())[0][1] +\n",
    "        sum(pred_dict_mlp2.values())/sel_seed * list(score.keys())[0][2]\n",
    "       ) / sum(list(score.keys())[0])\n",
    "accuracy_score(train_y, np.argmax(pred, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62f8a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = (sum(pred_test_dict_lgb.values())/sel_seed * list(score.keys())[0][0] + \n",
    "             sum(pred_test_dict_mlp1.values())/sel_seed * list(score.keys())[0][1] +\n",
    "             sum(pred_test_dict_mlp2.values())/sel_seed * list(score.keys())[0][2]\n",
    "            ) / sum(list(score.keys())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd589551",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = np.argmax(pred_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abd55c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission[\"target\"] = pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f71e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1670641e",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_name = '20220415'\n",
    "submission_number = '3'\n",
    "submission.to_csv(f'../submission/{submission_name}-{submission_number}.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d166dc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
