{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf10b07d",
   "metadata": {},
   "source": [
    "# 로컬 예측 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10a5166a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import cv2\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import timm\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split\n",
    "import time\n",
    "import albumentations as albu\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import optuna\n",
    "from optuna import Trial\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.visualization import plot_contour, plot_optimization_history\n",
    "from optuna.visualization import plot_parallel_coordinate, plot_slice, plot_param_importances\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5011c3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_img_path = np.array(sorted(glob('../data/train/*.png')))\n",
    "test_img_path = np.array(sorted(glob('../data/test/*.png')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8936a780",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = pd.read_csv(\"../data/train_df.csv\")\n",
    "\n",
    "train_classes = train_y[\"class\"]\n",
    "\n",
    "class_unique = sorted(np.unique(train_classes))\n",
    "class_unique = {key:value for key,value in zip(class_unique, range(len(class_unique)))}\n",
    "class_decoder = {val:key for key, val in class_unique.items()}\n",
    "\n",
    "all_classes = np.array([class_unique[k] for k in train_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5c1e802",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = pd.read_csv(\"../data/train_df.csv\")\n",
    "\n",
    "train_labels = train_y[\"label\"]\n",
    "\n",
    "label_unique = sorted(np.unique(train_labels))\n",
    "label_unique = {key:value for key,value in zip(label_unique, range(len(label_unique)))}\n",
    "\n",
    "all_label = np.array([label_unique[k] for k in train_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "655f7ac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33f27df2610f49b297223f9a8e1c48dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4277 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b4763427ca845909838a388a07f6bb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2154 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def custom_metric(truth, predictions):\n",
    "    pred_labels = predictions.reshape(len(np.unique(truth)),-1).argmax(axis=0)\n",
    "    f1 = f1_score(truth, pred_labels, average='macro')\n",
    "    return ('macrF1', f1, True) \n",
    "\n",
    "def score_function(real, pred):\n",
    "    score = f1_score(real, pred, average=\"macro\")\n",
    "    return score\n",
    "\n",
    "def img_load(path):\n",
    "    img = cv2.imread(path)[:,:,::-1]\n",
    "    img = cv2.resize(img, (256, 256)).flatten()\n",
    "    return img\n",
    "\n",
    "train_imgs = np.array([img_load(m) for m in tqdm(all_img_path)])\n",
    "test_imgs = np.array([img_load(n) for n in tqdm(test_img_path)])\n",
    "\n",
    "train_imgs = train_imgs / 255\n",
    "test_imgs = test_imgs / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf05d4d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5531be7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7d00ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac4531bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'IMG_SIZE':512,\n",
    "    'EPOCHS':4,\n",
    "    'LEARNING_RATE':1e-2,\n",
    "    'BATCH_SIZE':8,\n",
    "    'SEED':42\n",
    "}\n",
    "\n",
    "rows_train = len(train_imgs) # 주어진 train data의 row 수\n",
    "rows_test = len(test_imgs) # 주어진 test data의 row 수\n",
    "# rows_train = len(all_img_path) # 주어진 train data의 row 수\n",
    "# rows_test = len(test_img_path) # 주어진 test data의 row 수\n",
    "num_trial = 100 # 파라미터 튜닝을 몇 번 진행하는지의 수\n",
    "splits_hp = 3 # 파라미터 튜닝을 진행할 때의 kfold 수\n",
    "splits_tr = 4 # 모델 트레이닝을 진행할 때의 kfold 수\n",
    "basic_seed = 42 # default seed\n",
    "num_seed_tr = 10 # 트레이닝 seed 개수\n",
    "sel_seed = 3 # 선택할 seed 개수\n",
    "num_classes = 88\n",
    "\n",
    "pred_dict = {}\n",
    "pred_test_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9793bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_label = pd.Series(all_label).astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a467615",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_objective(trial: Trial) -> float:\n",
    "    params_lgb = {\n",
    "        \"random_state\": basic_seed,\n",
    "        \"verbosity\": -1,\n",
    "        \"n_estimators\": 10000,\n",
    "        \"objective\": \"multiclass\",\n",
    "        \"metric\": \"multi_logloss\",\n",
    "#         \"device\": \"gpu\",\n",
    "        \"num_class\": num_classes,\n",
    "        \"learning_rate\": trial.suggest_uniform(\"learning_rate\", 1e-2, 1e-1), # default=0.1, range=[0,1]\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 4, 8), # default=-1\n",
    "        \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 1e-2, 1e+1), # default=0\n",
    "        \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 1e-2, 1e+1), # default=0\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 31, 2000), # default=31, range=(1,130172]\n",
    "        \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.2, 1.0), # feature_fraction, default=1\n",
    "        \"subsample\": trial.suggest_uniform(\"subsample\", 0.2, 1.0), # bagging_fraction, default=1, range=[0,1]\n",
    "        \"subsample_freq\": trial.suggest_int(\"subsample_freq\", 1, 20), # bagging_freq, default=0\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 1, 40), # min_data_in_leaf, default=20 \n",
    "#         \"max_bin\": trial.suggest_int(\"max_bin\", 100, 400),\n",
    "    }\n",
    "    \n",
    "    kfold = StratifiedKFold(n_splits=splits_hp, random_state=basic_seed, shuffle=True)\n",
    "    cv = np.zeros((rows_train, num_classes))\n",
    "\n",
    "    for n, (train_idx, val_idx) in enumerate(kfold.split(train_imgs, all_label)):\n",
    "\n",
    "        x_train, x_val = train_imgs[train_idx], train_imgs[val_idx]\n",
    "        y_train, y_val = all_label[train_idx], all_label[val_idx]\n",
    "\n",
    "        lgbmodel = LGBMClassifier(**params_lgb)\n",
    "                                                                                        # 진행상황 보고싶을때 -1을 100으로\n",
    "        lgbmodel.fit(x_train, y_train, eval_set=[(x_val, y_val)], early_stopping_rounds=200, verbose=30, eval_metric=custom_metric) \n",
    "        cv[val_idx, :] = lgbmodel.predict_proba(x_val)\n",
    "        \n",
    "#         print('fold', n+1, 'f1_score:', score_function(y_val, cv[val_idx, :].argmax(1)))\n",
    "        \n",
    "#     print('f1_score:', score_function(all_label, np.argmax(cv, axis=1)))\n",
    "    return score_function(all_label, np.argmax(cv, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d888aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = TPESampler(seed=basic_seed)\n",
    "lgb_study = optuna.create_study(study_name=\"lgb_parameter_opt\", direction=\"maximize\", sampler=sampler)\n",
    "lgb_study.optimize(lgb_objective, n_trials=num_trial)\n",
    "\n",
    "lgb_best_hyperparams = lgb_study.best_trial.params\n",
    "lgb_base_hyperparams = {'objective':'multiclass', 'n_estimators':10000, \"num_class\": num_classes, \n",
    "                        'lambda_l1':lgb_best_hyperparams['reg_alpha'],\n",
    "                        'lambda_l2':lgb_best_hyperparams['reg_lambda'],\n",
    "                        'reg_alpha':None, 'reg_lambda':None\n",
    "                       }\n",
    "lgb_best_hyperparams.update(lgb_base_hyperparams)\n",
    "print(\"The best hyperparameters are:\\n\", lgb_best_hyperparams)\n",
    "with open('../pickle/lgb_best_hyperparams.pickle', 'wb') as fw:\n",
    "    pickle.dump(lgb_best_hyperparams, fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c043ba12",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.matplotlib.plot_param_importances(lgb_study);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3af388",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.matplotlib.plot_slice(lgb_study);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3a73bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../pickle/lgb_best_hyperparams.pickle', 'rb') as fw:\n",
    "    lgb_best_hyperparams = pickle.load(fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a184d734",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30]\tvalid_0's multi_logloss: 1.26766\tvalid_0's macrF1: 0.150376\n",
      "[60]\tvalid_0's multi_logloss: 1.11255\tvalid_0's macrF1: 0.157372\n",
      "[90]\tvalid_0's multi_logloss: 1.06944\tvalid_0's macrF1: 0.152294\n",
      "[120]\tvalid_0's multi_logloss: 1.05737\tvalid_0's macrF1: 0.157902\n",
      "[150]\tvalid_0's multi_logloss: 1.05053\tvalid_0's macrF1: 0.158099\n",
      "[180]\tvalid_0's multi_logloss: 1.04385\tvalid_0's macrF1: 0.158833\n",
      "[210]\tvalid_0's multi_logloss: 1.04106\tvalid_0's macrF1: 0.159105\n",
      "[240]\tvalid_0's multi_logloss: 1.0402\tvalid_0's macrF1: 0.15893\n",
      "[270]\tvalid_0's multi_logloss: 1.03876\tvalid_0's macrF1: 0.158754\n",
      "[300]\tvalid_0's multi_logloss: 1.03845\tvalid_0's macrF1: 0.158931\n",
      "[330]\tvalid_0's multi_logloss: 1.03784\tvalid_0's macrF1: 0.158931\n",
      "[360]\tvalid_0's multi_logloss: 1.0366\tvalid_0's macrF1: 0.159108\n",
      "[390]\tvalid_0's multi_logloss: 1.0348\tvalid_0's macrF1: 0.159208\n",
      "[420]\tvalid_0's multi_logloss: 1.03531\tvalid_0's macrF1: 0.159208\n",
      "[450]\tvalid_0's multi_logloss: 1.03534\tvalid_0's macrF1: 0.159388\n",
      "[480]\tvalid_0's multi_logloss: 1.03559\tvalid_0's macrF1: 0.159388\n",
      "[510]\tvalid_0's multi_logloss: 1.03554\tvalid_0's macrF1: 0.159208\n",
      "[540]\tvalid_0's multi_logloss: 1.03596\tvalid_0's macrF1: 0.159453\n",
      "[570]\tvalid_0's multi_logloss: 1.03662\tvalid_0's macrF1: 0.159453\n",
      "fold 1 f1 score : 0.15943530422503194\n",
      "[30]\tvalid_0's multi_logloss: 1.24691\tvalid_0's macrF1: 0.181769\n",
      "[60]\tvalid_0's multi_logloss: 1.08714\tvalid_0's macrF1: 0.194392\n",
      "[90]\tvalid_0's multi_logloss: 1.04897\tvalid_0's macrF1: 0.194823\n",
      "[120]\tvalid_0's multi_logloss: 1.03283\tvalid_0's macrF1: 0.195382\n",
      "[150]\tvalid_0's multi_logloss: 1.03076\tvalid_0's macrF1: 0.195993\n",
      "[180]\tvalid_0's multi_logloss: 1.02543\tvalid_0's macrF1: 0.195921\n",
      "[210]\tvalid_0's multi_logloss: 1.02247\tvalid_0's macrF1: 0.195746\n",
      "[240]\tvalid_0's multi_logloss: 1.02068\tvalid_0's macrF1: 0.195515\n",
      "[270]\tvalid_0's multi_logloss: 1.01891\tvalid_0's macrF1: 0.195618\n",
      "[300]\tvalid_0's multi_logloss: 1.01867\tvalid_0's macrF1: 0.195618\n",
      "[330]\tvalid_0's multi_logloss: 1.01895\tvalid_0's macrF1: 0.195618\n",
      "[360]\tvalid_0's multi_logloss: 1.01882\tvalid_0's macrF1: 0.195618\n",
      "[390]\tvalid_0's multi_logloss: 1.01882\tvalid_0's macrF1: 0.195508\n",
      "fold 2 f1 score : 0.19616117065592176\n",
      "[30]\tvalid_0's multi_logloss: 1.198\tvalid_0's macrF1: 0.184399\n",
      "[60]\tvalid_0's multi_logloss: 1.03466\tvalid_0's macrF1: 0.172478\n",
      "[90]\tvalid_0's multi_logloss: 1.00419\tvalid_0's macrF1: 0.172565\n",
      "[120]\tvalid_0's multi_logloss: 0.98772\tvalid_0's macrF1: 0.171546\n",
      "[150]\tvalid_0's multi_logloss: 0.979092\tvalid_0's macrF1: 0.1721\n",
      "[180]\tvalid_0's multi_logloss: 0.97508\tvalid_0's macrF1: 0.177939\n",
      "[210]\tvalid_0's multi_logloss: 0.973965\tvalid_0's macrF1: 0.177428\n",
      "fold 3 f1 score : 0.18821776434771847\n",
      "[30]\tvalid_0's multi_logloss: 1.24444\tvalid_0's macrF1: 0.161065\n",
      "[60]\tvalid_0's multi_logloss: 1.08474\tvalid_0's macrF1: 0.170175\n",
      "[90]\tvalid_0's multi_logloss: 1.0416\tvalid_0's macrF1: 0.181984\n",
      "[120]\tvalid_0's multi_logloss: 1.02815\tvalid_0's macrF1: 0.190176\n",
      "[150]\tvalid_0's multi_logloss: 1.01684\tvalid_0's macrF1: 0.189558\n",
      "[180]\tvalid_0's multi_logloss: 1.0097\tvalid_0's macrF1: 0.190069\n",
      "[210]\tvalid_0's multi_logloss: 1.00958\tvalid_0's macrF1: 0.189341\n",
      "[240]\tvalid_0's multi_logloss: 1.0085\tvalid_0's macrF1: 0.189365\n",
      "[270]\tvalid_0's multi_logloss: 1.0072\tvalid_0's macrF1: 0.189365\n",
      "[300]\tvalid_0's multi_logloss: 1.00744\tvalid_0's macrF1: 0.189535\n"
     ]
    }
   ],
   "source": [
    "lucky_seeds = np.random.randint(0, 1000, num_seed_tr)\n",
    "\n",
    "for i, seed in enumerate(lucky_seeds):\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=splits_tr, random_state=seed, shuffle=True) # CV 늘려가면서 하기\n",
    "    cv = np.zeros((rows_train, num_classes))\n",
    "    pred_test = np.zeros((rows_test, num_classes))\n",
    "\n",
    "    for n, (train_idx, val_idx) in enumerate(kfold.split(train_imgs, all_label)):\n",
    "        \n",
    "        x_train, x_val = train_imgs[train_idx], train_imgs[val_idx]\n",
    "        y_train, y_val = all_label[train_idx], all_label[val_idx]\n",
    "\n",
    "        lgbmodel = LGBMClassifier(**lgb_best_hyperparams)\n",
    "                                                                                        # 진행상황 보고싶을때 -1을 100으로\n",
    "        lgbmodel.fit(x_train, y_train, eval_set=[(x_val, y_val)], early_stopping_rounds=200, verbose=30, eval_metric=custom_metric) \n",
    "        cv[val_idx, :] = lgbmodel.predict_proba(x_val)\n",
    "        pred_test += lgbmodel.predict_proba(test_imgs) / splits_tr\n",
    "        print('fold', n+1, 'f1 score :', score_function(y_val, cv[val_idx, :].argmax(1)))\n",
    "        \n",
    "    pred_dict['lgb'+str(seed)] = cv\n",
    "    pred_test_dict['lgb'+str(seed)] = pred_test\n",
    "    print(f'seed {seed}', 'f1 score :', score_function(all_label, np.argmax(cv, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28b9764",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c9b716",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44cc320",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcb5c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalDataset(Dataset):\n",
    "    def __init__(self, img_path_list, label_list, train_mode=True):\n",
    "        self.train_mode = train_mode\n",
    "        self.img_path_list = img_path_list\n",
    "        self.label_list = label_list\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.img_path_list[index]\n",
    "        # Get image data\n",
    "        img = cv2.imread(img_path)\n",
    "\n",
    "        if self.train_mode:\n",
    "            label = self.label_list[index]\n",
    "            return image, label\n",
    "        else:\n",
    "            return image\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749833b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits_tr = 4\n",
    "num_classes = 15\n",
    "basic_seed = 42\n",
    "rows_train = len(all_img_path) # 주어진 train data의 row 수\n",
    "rows_test = len(test_img_path) # 주어진 test data의 row 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07e5dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local(model, optimizer, train_loader, vali_loader, device):\n",
    "    model.to(device)\n",
    "\n",
    "    # Loss Function\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    best_score = 0\n",
    "    \n",
    "    for epoch in range(1,CFG[\"EPOCHS\"]+1):\n",
    "        train_pred=[]\n",
    "        train_y=[]\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for img, label in tqdm(iter(train_loader)):\n",
    "            \n",
    "            img, label = img.float().to(device), label.float().to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Data -> Model -> Output\n",
    "            logit = model(img)\n",
    "            label = label.to(torch.int64)\n",
    "            loss = criterion(logit, label)\n",
    "\n",
    "            # backpropagation\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()/len(train_loader)\n",
    "            train_pred += logit.argmax(1).detach().cpu().numpy().tolist()\n",
    "            train_y += label.detach().cpu().numpy().tolist()\n",
    "            \n",
    "        # Evaluation Validation set\n",
    "        vali_score = validation_local(model, vali_loader, device)\n",
    "        \n",
    "        # vali_score가 더 이상 커지지 않으면\n",
    "        if scheduler is not None:\n",
    "            scheduler.step(vali_score)\n",
    "        \n",
    "        print(f'Epoch [{epoch}] Train Score : [{accuracy_score(train_y, train_pred):.5f}] Validation Score : [{vali_score:.5f}]\\n')\n",
    "        \n",
    "        # Model Saved\n",
    "        if best_score < vali_score:\n",
    "            best_score = vali_score\n",
    "            torch.save(model.state_dict(), '../model/local_model.pth')\n",
    "            print('Model Saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b318d69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_local(model, vali_loader, device):\n",
    "    model.eval() # Evaluation\n",
    "    logit_list = []\n",
    "    label_list = []\n",
    "    with torch.no_grad():\n",
    "        for img, label in tqdm(iter(vali_loader)):\n",
    "            img, label = img.float().to(device), label.float().to(device)\n",
    "            label = label.to(torch.int64)\n",
    "\n",
    "            logit_list.extend(model(img).argmax(1).detach().cpu().numpy().tolist())\n",
    "            label_list.extend(label.detach().cpu().numpy().tolist())\n",
    "\n",
    "    vali_f1_score = accuracy_score(label_list, logit_list)\n",
    "    return vali_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b935727",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_local(model, test_loader, device):\n",
    "    model.eval()\n",
    "    model_pred = []\n",
    "    with torch.no_grad():\n",
    "        for img in tqdm(iter(test_loader)):\n",
    "            \n",
    "            img = img.float().to(device)\n",
    "\n",
    "            pred_logit = model(img).detach().cpu()\n",
    "            model_pred.extend(pred_logit.tolist())\n",
    "    return model_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da7ea3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, img_path_list, label_list, train_mode=True, transforms=None):\n",
    "        self.transforms = transforms\n",
    "        self.train_mode = train_mode\n",
    "        self.img_path_list = img_path_list\n",
    "        self.label_list = label_list\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.img_path_list[index]\n",
    "        # Get image data\n",
    "        img = cv2.imread(img_path)\n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(image=img)[\"image\"]\n",
    "\n",
    "        if self.train_mode:\n",
    "            label = self.label_list[index]\n",
    "            return image, label\n",
    "        else:\n",
    "            return image\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img_path_list)\n",
    "    \n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.model = timm.create_model('efficientnet_b0', pretrained=True, num_classes=num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07269d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = albu.Compose([\n",
    "    albu.Resize(CFG['IMG_SIZE'], CFG['IMG_SIZE']),\n",
    "    ToTensorV2()]\n",
    ")\n",
    "\n",
    "valid_transform = albu.Compose([\n",
    "    albu.Resize(CFG['IMG_SIZE'], CFG['IMG_SIZE']),\n",
    "    ToTensorV2()]\n",
    ")\n",
    "\n",
    "test_transform = albu.Compose([\n",
    "    albu.Resize(CFG['IMG_SIZE'], CFG['IMG_SIZE']),\n",
    "    ToTensorV2()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf86e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CustomDataset(test_img_path, None, train_mode=False, transforms=test_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=0)\n",
    "\n",
    "kfold = KFold(n_splits=splits_tr, random_state=basic_seed, shuffle=True) # CV 늘려가면서 하기\n",
    "cv = np.zeros((rows_train, num_classes))\n",
    "pred_test = np.zeros((rows_test, num_classes))\n",
    "for n, (train_idx, val_idx) in enumerate(kfold.split(all_img_path, all_classes)):\n",
    "    \n",
    "    train_img_path, vali_img_path = all_img_path[train_idx], all_img_path[val_idx]\n",
    "    train_classes, vali_classes = all_classes[train_idx], all_classes[val_idx]\n",
    "    \n",
    "    # Get Dataloader\n",
    "    train_dataset = CustomDataset(train_img_path.tolist(), train_classes.tolist(), train_mode=True, transforms=train_transform)\n",
    "    train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=True, num_workers=0)\n",
    "\n",
    "    vali_dataset = CustomDataset(vali_img_path.tolist(), vali_classes.tolist(), train_mode=True, transforms=valid_transform)\n",
    "    vali_loader = DataLoader(vali_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=0)\n",
    "    \n",
    "    model = Network().to(device)\n",
    "    optimizer = torch.optim.SGD(params = model.parameters(), lr = CFG[\"LEARNING_RATE\"])\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, mode='max', patience=3, factor=0.2)\n",
    "    \n",
    "    train_local(model, optimizer, train_loader, vali_loader, device)\n",
    "    \n",
    "#     checkpoint = torch.load('../model/local_model.pth')\n",
    "#     model = Network().to(device)\n",
    "#     model.load_state_dict(checkpoint)\n",
    "    \n",
    "    vali_dataset = CustomDataset(vali_img_path.tolist(), vali__classes.tolist(), train_mode=False, transforms=test_transform)\n",
    "    vali_loader = DataLoader(vali_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=0)\n",
    "    \n",
    "    cv[val_idx, :] = predict_local(model, vali_loader, device)\n",
    "    pred_test += np.array(predict_local(model, test_loader, device)) / splits_tr\n",
    "    print(f\"Fold {n+1} Score: {accuracy_score(vali__classes, cv[val_idx].argmax(axis=1))}\")\n",
    "\n",
    "print(f\"Final Score: {accuracy_score(all_classes, cv.argmax(axis=1))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3341d9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_local_final = [class_decoder[result] for result in pred_test.argmax(1)]\n",
    "with open('../pickle/pred_local_final.pickle', 'wb') as fw:\n",
    "    pickle.dump(pred_local_final, fw)\n",
    "test_local_df = pd.DataFrame(np.column_stack([test_img_path, pred_local_final]), columns=[\"path\", \"class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59d30c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../pickle/pred_local_final.pickle', 'rb') as fw:\n",
    "    pred_local_final = pickle.load(fw)\n",
    "test_local_df = pd.DataFrame(np.column_stack([test_img_path, pred_local_final]), columns=[\"path\", \"class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d465750c",
   "metadata": {},
   "outputs": [],
   "source": [
    "classList = train_y['class'].unique()\n",
    "anomaly_test_dict = {}\n",
    "for className in classList:\n",
    "    anomaly_test_dict[className] = test_local_df[test_local_df[\"class\"]==className]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2380e97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classList = train_y['class'].unique()\n",
    "anomaly_dict = {}\n",
    "for className in classList:\n",
    "    index = train_classes[train_classes==className].index\n",
    "    df = pd.DataFrame(np.column_stack([all_img_path[index], all_label[index]]), columns=[\"path\", \"label\"])\n",
    "    anomaly_dict[className] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc80e467",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits_tr = 4\n",
    "num_classes = len(anomaly_dict['wood']['label'].unique())\n",
    "basic_seed = 42\n",
    "rows_train = len(anomaly_dict['wood']) # 주어진 train data의 row 수\n",
    "rows_test = len(anomaly_test_dict['wood']) # 주어진 test data의 row 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23c608d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.model = timm.create_model('efficientnet_b7', pretrained=True, num_classes=num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8321f69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = albu.Compose([\n",
    "    albu.Resize(CFG['IMG_SIZE'], CFG['IMG_SIZE']),\n",
    "#     albu.RandomCrop(CFG['IMG_SIZE']-64, CFG['IMG_SIZE']-64),\n",
    "#     albu.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.1,\n",
    "#                           rotate_limit=30, interpolation=1, border_mode=0,\n",
    "#                           value=0, p=0.5),\n",
    "#     albu.HorizontalFlip(p=0.2),\n",
    "#     albu.VerticalFlip(p=0.2),\n",
    "#     albu.RandomRotate90(p=0.2),\n",
    "#     albu.CLAHE(clip_limit=2, p=0.25),\n",
    "#     albu.Sharpen(p=0.25),\n",
    "#     albu.RandomBrightnessContrast(brightness_limit=(-0.1, 0.1),\n",
    "#                                   contrast_limit=(-0.1, 0.1), p=0.25),\n",
    "#     albu.RandomResizedCrop(height=CFG['IMG_SIZE'], width=CFG['IMG_SIZE'],\n",
    "#                            scale=(0.5, 1.0), ratio=(0.75, 1.3333333333333333),\n",
    "#                            interpolation=1, p=1.0),\n",
    "#     albu.Normalize(mean=IMAGENET_DEFAULT_MEAN, std=IMAGENET_DEFAULT_STD, max_pixel_value=512.0, p=1.0),\n",
    "    ToTensorV2()]\n",
    ")\n",
    "\n",
    "valid_transform = albu.Compose([\n",
    "    albu.Resize(CFG['IMG_SIZE'], CFG['IMG_SIZE']),\n",
    "#     albu.HorizontalFlip(p=0.5),\n",
    "#     albu.VerticalFlip(p=0.5),\n",
    "#     albu.Normalize(mean=IMAGENET_DEFAULT_MEAN, std=IMAGENET_DEFAULT_STD, max_pixel_value=512.0, p=1.0),\n",
    "    ToTensorV2()]\n",
    ")\n",
    "\n",
    "test_transform = albu.Compose([\n",
    "    albu.Resize(CFG['IMG_SIZE'], CFG['IMG_SIZE']),\n",
    "#     albu.Normalize(mean=IMAGENET_DEFAULT_MEAN, std=IMAGENET_DEFAULT_STD, max_pixel_value=512.0, p=1.0),\n",
    "    ToTensorV2()]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048cafbe",
   "metadata": {},
   "source": [
    "### 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7993bc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_loader, vali_loader, scheduler, device):\n",
    "    model.to(device)\n",
    "\n",
    "    # Loss Function\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    best_score = 0\n",
    "    \n",
    "    for epoch in range(1,CFG[\"EPOCHS\"]+1):\n",
    "        train_pred=[]\n",
    "        train_y=[]\n",
    "        model.train()\n",
    "#         train_loss = 0\n",
    "        for img, label in tqdm(iter(train_loader)):\n",
    "            \n",
    "            img, label = img.float().to(device), label.float().to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Data -> Model -> Output\n",
    "            logit = model(img)\n",
    "            label = label.to(torch.int64)\n",
    "            loss = criterion(logit, label)\n",
    "\n",
    "            # backpropagation\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "#             train_loss += loss.item()/len(train_loader)\n",
    "            train_pred += logit.argmax(1).detach().cpu().numpy().tolist()\n",
    "            train_y += label.detach().cpu().numpy().tolist()\n",
    "            \n",
    "        # Evaluation Validation set\n",
    "        vali_score = validation(model, vali_loader, device)\n",
    "        \n",
    "        # vali_score가 더 이상 커지지 않으면\n",
    "        if scheduler is not None:\n",
    "            scheduler.step(vali_score)\n",
    "        \n",
    "        print(f'Epoch [{epoch}] Train Score : [{score_function(train_y, train_pred):.5f}] Validation Score : [{vali_score:.5f}]\\n')\n",
    "        \n",
    "        # Model Saved\n",
    "        if best_score < vali_score:\n",
    "            best_score = vali_score\n",
    "            torch.save(model.state_dict(), '../model/best_model.pth')\n",
    "            print('Model Saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a9d155",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, vali_loader, device):\n",
    "    model.eval() # Evaluation\n",
    "    logit_list = []\n",
    "    label_list = []\n",
    "    with torch.no_grad():\n",
    "        for img, label in tqdm(iter(vali_loader)):\n",
    "            img, label = img.float().to(device), label.float().to(device)\n",
    "            label = label.to(torch.int64)\n",
    "\n",
    "            logit_list.extend(model(img).argmax(1).detach().cpu().numpy().tolist())\n",
    "            label_list.extend(label.detach().cpu().numpy().tolist())\n",
    "\n",
    "    vali_f1_score = score_function(label_list, logit_list)\n",
    "    return vali_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e6bacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset = CustomDataset(test_img_path, None, train_mode=False, transforms=test_transform)\n",
    "# test_loader = DataLoader(test_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=0)\n",
    "\n",
    "def predict(model, test_loader, device):\n",
    "    model.eval()\n",
    "    model_pred = []\n",
    "    with torch.no_grad():\n",
    "        for img in tqdm(iter(test_loader)):\n",
    "            \n",
    "            img = img.float().to(device)\n",
    "\n",
    "            pred_logit = model(img).detach().cpu()\n",
    "            model_pred.extend(pred_logit.tolist())\n",
    "    return model_pred\n",
    "\n",
    "def score_function(real, pred):\n",
    "    score = f1_score(real, pred, average=\"macro\")\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedc706b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rows_train = len(all_img_path) # 주어진 train data의 row 수\n",
    "# rows_test = len(test_img_path) # 주어진 test data의 row 수\n",
    "# num_trial = 100 # 파라미터 튜닝을 몇 번 진행하는지의 수\n",
    "# splits_hp = 5 # 파라미터 튜닝을 진행할 때의 kfold 수\n",
    "# splits_tr = 5 # 모델 트레이닝을 진행할 때의 kfold 수\n",
    "# basic_seed = 42 # default seed\n",
    "# num_seed_tr = 10 # 트레이닝 seed 개수\n",
    "# sel_seed = 3 # 선택할 seed 개수\n",
    "# num_classes = 88\n",
    "\n",
    "# pred_dict = {}\n",
    "# pred_test_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f946c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_img_path = np.array(anomaly_dict['wood']['path'])\n",
    "local_label_raw = np.array(anomaly_dict['wood']['label']).astype(\"int32\")\n",
    "local_test_path = np.array(anomaly_test_dict['wood']['path'])\n",
    "\n",
    "test_dataset = CustomDataset(local_test_path.tolist(), None, train_mode=False, transforms=test_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da4c87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_unique = sorted(np.unique(local_label_raw))\n",
    "local_unique = {key:value for key,value in zip(local_unique, range(len(local_unique)))}\n",
    "local_label = np.array([local_unique[k] for k in local_label_raw])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc3450e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'IMG_SIZE':512,\n",
    "    'EPOCHS':30,\n",
    "    'LEARNING_RATE':5e-2,\n",
    "    'BATCH_SIZE':1,\n",
    "    'SEED':42\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1839d4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna import Trial\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.visualization import plot_contour, plot_optimization_history\n",
    "from optuna.visualization import plot_parallel_coordinate, plot_slice, plot_param_importances\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd77855",
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_load(path):\n",
    "    img = cv2.imread(path)[:,:,::-1]\n",
    "    img = cv2.resize(img, (64, 64)).flatten()\n",
    "    return img\n",
    "\n",
    "# train_imgs = [img_load(m) for m in tqdm(train_png)]\n",
    "# test_imgs = [img_load(n) for n in tqdm(test_png)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fef352",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_img = np.array([img_load(m) for m in tqdm(local_img_path)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431a7faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a611230",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_objective(trial: Trial) -> float:\n",
    "    params_lgb = {\n",
    "        \"random_state\": basic_seed,\n",
    "        \"verbosity\": -1,\n",
    "        \"n_estimators\": 10000,\n",
    "        \"objective\": \"multiclass\",\n",
    "        \"metric\": \"multi_logloss\",\n",
    "        'learning_rate': trial.suggest_uniform(\"learning_rate\", 0.001, 0.01),\n",
    "        \"reg_alpha\": trial.suggest_uniform(\"reg_alpha\", 0.0, 1),\n",
    "        \"reg_lambda\": trial.suggest_uniform(\"reg_lambda\", 0.0, 1),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 5, 10),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 200, 1200),\n",
    "        \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0), # feature_fraction\n",
    "        \"subsample\": trial.suggest_uniform(\"subsample\", 0.0, 1.0),\n",
    "        \"subsample_freq\": trial.suggest_int(\"subsample_freq\", 1, 10),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 1, 10),\n",
    "        \"max_bin\": trial.suggest_int(\"max_bin\", 150, 400),\n",
    "    }\n",
    "    \n",
    "    kfold = StratifiedKFold(n_splits=splits_hp, random_state=basic_seed, shuffle = True) # Cross-validation cv=5\n",
    "    cv = np.zeros((rows_train, num_classes))\n",
    "\n",
    "    for n, (train_idx, val_idx) in enumerate(kfold.split(local_img, local_label)):\n",
    "\n",
    "        x_train, x_val = local_img[train_idx], local_img[val_idx]\n",
    "        y_train, y_val = local_label[train_idx], local_label[val_idx]\n",
    "\n",
    "        lgbmodel = LGBMClassifier(**params_lgb)\n",
    "                                                                                        # 진행상황 보고싶을때 -1을 100으로\n",
    "        lgbmodel.fit(x_train, y_train, eval_set=[(x_val, y_val)], early_stopping_rounds=100, verbose=-1, eval_metric=custom_metric) \n",
    "        cv[val_idx, :] = lgbmodel.predict_proba(x_val)\n",
    "        \n",
    "#         print('fold', n+1, 'f1_score:', score_function(y_val, cv[val_idx, :].argmax(1)))\n",
    "        \n",
    "#     print('f1_score:', score_function(local_label, np.argmax(cv, axis=1)))\n",
    "    return score_function(local_label, np.argmax(cv, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ea4f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trial = 100\n",
    "splits_hp = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d9970d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_metric(truth, predictions):  \n",
    "    pred_labels = predictions.reshape(len(np.unique(truth)),-1).argmax(axis=0)\n",
    "    f1 = f1_score(truth, pred_labels, average='macro')\n",
    "    return ('macroF1', f1, True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044f232b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = TPESampler(seed=basic_seed)\n",
    "lgb_study = optuna.create_study(study_name=\"lgb_parameter_opt\", direction=\"maximize\", sampler=sampler)\n",
    "lgb_study.optimize(lgb_objective, n_trials=num_trial)\n",
    "\n",
    "lgb_best_hyperparams = lgb_study.best_trial.params\n",
    "lgb_base_hyperparams = {'objective':'multiclass', 'n_estimators':10000,\n",
    "                        'lambda_l1':lgb_best_hyperparams['reg_alpha'],\n",
    "                        'lambda_l2':lgb_best_hyperparams['reg_lambda'],\n",
    "                        'reg_alpha':None, 'reg_lambda':None\n",
    "                       }\n",
    "lgb_best_hyperparams.update(lgb_base_hyperparams)\n",
    "print(\"The best hyperparameters are:\\n\", lgb_best_hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e971296",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c3748a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e60125",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49e8486",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0662c7c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebeb5a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefa63a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00253373",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b684f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556db972",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c41125",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=splits_tr, random_state=basic_seed, shuffle=True) # CV 늘려가면서 하기\n",
    "cv = np.zeros((rows_train, num_classes))\n",
    "pred_test = np.zeros((rows_test, num_classes))\n",
    "for n, (train_idx, val_idx) in enumerate(kfold.split(local_img_path, local_label)):\n",
    "    \n",
    "    train_img_path, vali_img_path = local_img_path[train_idx], local_img_path[val_idx]\n",
    "    train_label, vali_label = local_label[train_idx], local_label[val_idx]\n",
    "    \n",
    "    # Get Dataloader\n",
    "    train_dataset = CustomDataset(train_img_path.tolist(), train_label.tolist(), train_mode=True, transforms=train_transform)\n",
    "    train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=True, num_workers=0)\n",
    "\n",
    "    vali_dataset = CustomDataset(vali_img_path.tolist(), vali_label.tolist(), train_mode=True, transforms=valid_transform)\n",
    "    vali_loader = DataLoader(vali_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=0)\n",
    "    \n",
    "    model = Network().to(device)\n",
    "    optimizer = torch.optim.SGD(params = model.parameters(), lr = CFG[\"LEARNING_RATE\"])\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, mode='max', patience=5, factor=0.2)\n",
    "    \n",
    "    train(model, optimizer, train_loader, vali_loader, scheduler, device)\n",
    "    \n",
    "    checkpoint = torch.load('../model/best_model.pth')\n",
    "    model = Network().to(device)\n",
    "    model.load_state_dict(checkpoint)\n",
    "    \n",
    "    vali_dataset = CustomDataset(vali_img_path.tolist(), vali_label.tolist(), train_mode=False, transforms=test_transform)\n",
    "    vali_loader = DataLoader(vali_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=0)\n",
    "    \n",
    "    cv[val_idx, :] = predict(model, vali_loader, device)\n",
    "    pred_test += np.array(predict(model, test_loader, device)) / splits_tr\n",
    "    print(f\"Fold {n+1} Score: {score_function(vali_label, cv[val_idx].argmax(axis=1))}\")\n",
    "    \n",
    "pred_dict['eff_b0'+str(seed)] = cv\n",
    "pred_test_dict['eff_b0'+str(seed)] = pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e973e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dict = {}\n",
    "pred_test_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9ea28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dict['eff_b0'+str(42)] = cv\n",
    "pred_test_dict['eff_b0'+str(42)] = pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3434683b",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=splits_tr, random_state=basic_seed, shuffle=True) # CV 늘려가면서 하기\n",
    "cv = np.zeros((rows_train, num_classes))\n",
    "pred_test = np.zeros((rows_test, num_classes))\n",
    "for n, (train_idx, val_idx) in enumerate(kfold.split(all_img_path, all_label)):\n",
    "    \n",
    "    train_img_path, vali_img_path = all_img_path[train_idx], all_img_path[val_idx]\n",
    "    train_label, vali_label = all_label[train_idx], all_label[val_idx]\n",
    "    \n",
    "    # Get Dataloader\n",
    "    train_dataset = CustomDataset(train_img_path.tolist(), train_label.tolist(), train_mode=True, transforms=train_transform)\n",
    "    train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=True, num_workers=0)\n",
    "\n",
    "    vali_dataset = CustomDataset(vali_img_path.tolist(), vali_label.tolist(), train_mode=True, transforms=valid_transform)\n",
    "    vali_loader = DataLoader(vali_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=0)\n",
    "    \n",
    "    model = Network().to(device)\n",
    "    optimizer = torch.optim.SGD(params = model.parameters(), lr = CFG[\"LEARNING_RATE\"])\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, mode='max', patience=3, factor=0.2)\n",
    "    \n",
    "    train(model, optimizer, train_loader, vali_loader, scheduler, device)\n",
    "    \n",
    "    checkpoint = torch.load('../model/best_model.pth')\n",
    "    model = Network().to(device)\n",
    "    model.load_state_dict(checkpoint)\n",
    "    \n",
    "    vali_dataset = CustomDataset(vali_img_path.tolist(), vali_label.tolist(), train_mode=False, transforms=test_transform)\n",
    "    vali_loader = DataLoader(vali_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=0)\n",
    "    \n",
    "    cv[val_idx, :] = predict(model, vali_loader, device)\n",
    "    pred_test += np.array(predict(model, test_loader, device)) / splits_tr\n",
    "    print(f\"Fold {n+1} Score: {score_function(vali_label, cv[val_idx].argmax(axis=1))}\")\n",
    "    \n",
    "pred_dict['eff_b0'+str(seed)] = cv\n",
    "pred_test_dict['eff_b0'+str(seed)] = pred_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443bced0",
   "metadata": {},
   "source": [
    "### 추론"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac561815",
   "metadata": {},
   "source": [
    "### 제출물 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b0ce22",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_decoder = {val:key for key, val in label_unique.items()}\n",
    "pred_final = [label_decoder[result] for result in pred_test.argmax(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0587dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "submission = pd.read_csv('../data/sample_submission.csv')\n",
    "submission[\"label\"] = pred_final\n",
    "submission_time = datetime.today().strftime('%Y-%m-%d-%M-%S')\n",
    "submission.to_csv(f'../submission/{submission_time}.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e73a637",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
