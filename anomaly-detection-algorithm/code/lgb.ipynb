{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf10b07d",
   "metadata": {},
   "source": [
    "# 로컬 예측 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10a5166a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import cv2\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import timm\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split\n",
    "import time\n",
    "import albumentations as albu\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import optuna\n",
    "from optuna import Trial\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.visualization import plot_contour, plot_optimization_history\n",
    "from optuna.visualization import plot_parallel_coordinate, plot_slice, plot_param_importances\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5011c3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_img_path = np.array(sorted(glob('../data/train/*.png')))\n",
    "test_img_path = np.array(sorted(glob('../data/test/*.png')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8936a780",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = pd.read_csv(\"../data/train_df.csv\")\n",
    "\n",
    "train_classes = train_y[\"class\"]\n",
    "\n",
    "class_unique = sorted(np.unique(train_classes))\n",
    "class_unique = {key:value for key,value in zip(class_unique, range(len(class_unique)))}\n",
    "class_decoder = {val:key for key, val in class_unique.items()}\n",
    "\n",
    "all_classes = np.array([class_unique[k] for k in train_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5c1e802",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = pd.read_csv(\"../data/train_df.csv\")\n",
    "\n",
    "train_labels = train_y[\"label\"]\n",
    "\n",
    "label_unique = sorted(np.unique(train_labels))\n",
    "label_unique = {key:value for key,value in zip(label_unique, range(len(label_unique)))}\n",
    "\n",
    "all_label = np.array([label_unique[k] for k in train_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "655f7ac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33f27df2610f49b297223f9a8e1c48dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4277 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b4763427ca845909838a388a07f6bb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2154 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def custom_metric(truth, predictions):\n",
    "    pred_labels = predictions.reshape(len(np.unique(truth)),-1).argmax(axis=0)\n",
    "    f1 = f1_score(truth, pred_labels, average='macro')\n",
    "    return ('macrF1', f1, True) \n",
    "\n",
    "def score_function(real, pred):\n",
    "    score = f1_score(real, pred, average=\"macro\")\n",
    "    return score\n",
    "\n",
    "def img_load(path):\n",
    "    img = cv2.imread(path)[:,:,::-1]\n",
    "    img = cv2.resize(img, (256, 256)).flatten()\n",
    "    return img\n",
    "\n",
    "train_imgs = np.array([img_load(m) for m in tqdm(all_img_path)])\n",
    "test_imgs = np.array([img_load(n) for n in tqdm(test_img_path)])\n",
    "\n",
    "train_imgs = train_imgs / 255\n",
    "test_imgs = test_imgs / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70941de3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b809a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1928a39a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac4531bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'IMG_SIZE':512,\n",
    "    'EPOCHS':4,\n",
    "    'LEARNING_RATE':1e-2,\n",
    "    'BATCH_SIZE':8,\n",
    "    'SEED':42\n",
    "}\n",
    "\n",
    "rows_train = len(train_imgs) # 주어진 train data의 row 수\n",
    "rows_test = len(test_imgs) # 주어진 test data의 row 수\n",
    "# rows_train = len(all_img_path) # 주어진 train data의 row 수\n",
    "# rows_test = len(test_img_path) # 주어진 test data의 row 수\n",
    "num_trial = 100 # 파라미터 튜닝을 몇 번 진행하는지의 수\n",
    "splits_hp = 3 # 파라미터 튜닝을 진행할 때의 kfold 수\n",
    "splits_tr = 4 # 모델 트레이닝을 진행할 때의 kfold 수\n",
    "basic_seed = 42 # default seed\n",
    "num_seed_tr = 10 # 트레이닝 seed 개수\n",
    "sel_seed = 3 # 선택할 seed 개수\n",
    "num_classes = 88\n",
    "\n",
    "pred_dict = {}\n",
    "pred_test_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a9793bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_label = pd.Series(all_label).astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a467615",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_objective(trial: Trial) -> float:\n",
    "    params_lgb = {\n",
    "        \"random_state\": basic_seed,\n",
    "        \"verbosity\": -1,\n",
    "        \"n_estimators\": 10000,\n",
    "        \"objective\": \"multiclass\",\n",
    "        \"metric\": \"multi_logloss\",\n",
    "#         \"device\": \"gpu\",\n",
    "        \"num_class\": num_classes,\n",
    "        \"learning_rate\": trial.suggest_uniform(\"learning_rate\", 1e-2, 1e-1), # default=0.1, range=[0,1]\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 4, 8), # default=-1\n",
    "        \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 1e-2, 1e+1), # default=0\n",
    "        \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 1e-2, 1e+1), # default=0\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 31, 2000), # default=31, range=(1,130172]\n",
    "        \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.2, 1.0), # feature_fraction, default=1\n",
    "        \"subsample\": trial.suggest_uniform(\"subsample\", 0.2, 1.0), # bagging_fraction, default=1, range=[0,1]\n",
    "        \"subsample_freq\": trial.suggest_int(\"subsample_freq\", 1, 20), # bagging_freq, default=0\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 1, 40), # min_data_in_leaf, default=20 \n",
    "#         \"max_bin\": trial.suggest_int(\"max_bin\", 100, 400),\n",
    "    }\n",
    "    \n",
    "    kfold = StratifiedKFold(n_splits=splits_hp, random_state=basic_seed, shuffle=True)\n",
    "    cv = np.zeros((rows_train, num_classes))\n",
    "\n",
    "    for n, (train_idx, val_idx) in enumerate(kfold.split(train_imgs, all_label)):\n",
    "\n",
    "        x_train, x_val = train_imgs[train_idx], train_imgs[val_idx]\n",
    "        y_train, y_val = all_label[train_idx], all_label[val_idx]\n",
    "\n",
    "        lgbmodel = LGBMClassifier(**params_lgb)\n",
    "                                                                                        # 진행상황 보고싶을때 -1을 100으로\n",
    "        lgbmodel.fit(x_train, y_train, eval_set=[(x_val, y_val)], early_stopping_rounds=200, verbose=30, eval_metric=custom_metric) \n",
    "        cv[val_idx, :] = lgbmodel.predict_proba(x_val)\n",
    "        \n",
    "#         print('fold', n+1, 'f1_score:', score_function(y_val, cv[val_idx, :].argmax(1)))\n",
    "        \n",
    "#     print('f1_score:', score_function(all_label, np.argmax(cv, axis=1)))\n",
    "    return score_function(all_label, np.argmax(cv, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62dd57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = TPESampler(seed=basic_seed)\n",
    "lgb_study = optuna.create_study(study_name=\"lgb_parameter_opt\", direction=\"maximize\", sampler=sampler)\n",
    "lgb_study.optimize(lgb_objective, n_trials=num_trial)\n",
    "\n",
    "lgb_best_hyperparams = lgb_study.best_trial.params\n",
    "lgb_base_hyperparams = {'objective':'multiclass', 'n_estimators':10000, \"num_class\": num_classes, \n",
    "                        'lambda_l1':lgb_best_hyperparams['reg_alpha'],\n",
    "                        'lambda_l2':lgb_best_hyperparams['reg_lambda'],\n",
    "                        'reg_alpha':None, 'reg_lambda':None\n",
    "                       }\n",
    "lgb_best_hyperparams.update(lgb_base_hyperparams)\n",
    "print(\"The best hyperparameters are:\\n\", lgb_best_hyperparams)\n",
    "with open('../pickle/lgb_best_hyperparams.pickle', 'wb') as fw:\n",
    "    pickle.dump(lgb_best_hyperparams, fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b415212b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.matplotlib.plot_param_importances(lgb_study);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cacabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.matplotlib.plot_slice(lgb_study);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "873e32f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../pickle/lgb_best_hyperparams.pickle', 'rb') as fw:\n",
    "    lgb_best_hyperparams = pickle.load(fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9823873f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lgb452': array([[1.10073597e-04, 8.33608628e-05, 1.01125931e-04, ...,\n",
       "         4.45876348e-05, 7.65392523e-05, 8.83422371e-05],\n",
       "        [2.75647268e-05, 2.36852120e-05, 3.00717816e-05, ...,\n",
       "         1.07865431e-05, 2.21904418e-05, 2.62071409e-05],\n",
       "        [3.12194834e-04, 2.99542594e-04, 2.65148572e-04, ...,\n",
       "         3.52129214e-04, 2.32698079e-04, 2.91451488e-04],\n",
       "        ...,\n",
       "        [7.16435572e-04, 8.52659211e-04, 8.49488763e-04, ...,\n",
       "         7.58827148e-04, 8.19252391e-04, 4.54377519e-04],\n",
       "        [2.27709072e-04, 2.02499141e-04, 2.84418114e-04, ...,\n",
       "         3.49181229e-03, 4.62815526e-04, 2.11499152e-04],\n",
       "        [8.26567564e-04, 8.48735489e-04, 8.88222975e-04, ...,\n",
       "         8.19595513e-04, 7.58519280e-04, 7.35531417e-04]]),\n",
       " 'lgb226': array([[3.98766877e-05, 3.23916366e-05, 2.40799245e-05, ...,\n",
       "         2.17610666e-05, 2.71788659e-05, 2.49859324e-05],\n",
       "        [4.84891287e-05, 2.99203914e-05, 4.22698874e-05, ...,\n",
       "         3.81993655e-05, 4.77097677e-05, 4.38602934e-05],\n",
       "        [4.58650834e-04, 4.80416520e-04, 2.24894151e-04, ...,\n",
       "         2.45519452e-04, 4.50589953e-04, 2.24438740e-04],\n",
       "        ...,\n",
       "        [8.09087134e-04, 8.06224500e-04, 8.33058439e-04, ...,\n",
       "         6.72532851e-04, 6.68858566e-04, 7.36048842e-04],\n",
       "        [8.97940276e-04, 4.49694376e-04, 5.16562289e-04, ...,\n",
       "         3.78953575e-03, 9.20081333e-04, 1.15509149e-03],\n",
       "        [7.43683627e-04, 7.41052398e-04, 7.65717184e-04, ...,\n",
       "         5.95999755e-04, 6.14790600e-04, 6.38373885e-04]])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e645fd1a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30]\tvalid_0's multi_logloss: 1.26766\tvalid_0's macrF1: 0.150376\n",
      "[60]\tvalid_0's multi_logloss: 1.11255\tvalid_0's macrF1: 0.157372\n",
      "[90]\tvalid_0's multi_logloss: 1.06944\tvalid_0's macrF1: 0.152294\n",
      "[120]\tvalid_0's multi_logloss: 1.05737\tvalid_0's macrF1: 0.157902\n",
      "[150]\tvalid_0's multi_logloss: 1.05053\tvalid_0's macrF1: 0.158099\n",
      "[180]\tvalid_0's multi_logloss: 1.04385\tvalid_0's macrF1: 0.158833\n",
      "[210]\tvalid_0's multi_logloss: 1.04106\tvalid_0's macrF1: 0.159105\n",
      "[240]\tvalid_0's multi_logloss: 1.0402\tvalid_0's macrF1: 0.15893\n",
      "[270]\tvalid_0's multi_logloss: 1.03876\tvalid_0's macrF1: 0.158754\n",
      "[300]\tvalid_0's multi_logloss: 1.03845\tvalid_0's macrF1: 0.158931\n",
      "[330]\tvalid_0's multi_logloss: 1.03784\tvalid_0's macrF1: 0.158931\n",
      "[360]\tvalid_0's multi_logloss: 1.0366\tvalid_0's macrF1: 0.159108\n",
      "[390]\tvalid_0's multi_logloss: 1.0348\tvalid_0's macrF1: 0.159208\n",
      "[420]\tvalid_0's multi_logloss: 1.03531\tvalid_0's macrF1: 0.159208\n",
      "[450]\tvalid_0's multi_logloss: 1.03534\tvalid_0's macrF1: 0.159388\n",
      "[480]\tvalid_0's multi_logloss: 1.03559\tvalid_0's macrF1: 0.159388\n",
      "[510]\tvalid_0's multi_logloss: 1.03554\tvalid_0's macrF1: 0.159208\n",
      "[540]\tvalid_0's multi_logloss: 1.03596\tvalid_0's macrF1: 0.159453\n",
      "[570]\tvalid_0's multi_logloss: 1.03662\tvalid_0's macrF1: 0.159453\n",
      "fold 1 f1 score : 0.15943530422503194\n",
      "[30]\tvalid_0's multi_logloss: 1.24691\tvalid_0's macrF1: 0.181769\n",
      "[60]\tvalid_0's multi_logloss: 1.08714\tvalid_0's macrF1: 0.194392\n",
      "[90]\tvalid_0's multi_logloss: 1.04897\tvalid_0's macrF1: 0.194823\n",
      "[120]\tvalid_0's multi_logloss: 1.03283\tvalid_0's macrF1: 0.195382\n",
      "[150]\tvalid_0's multi_logloss: 1.03076\tvalid_0's macrF1: 0.195993\n",
      "[180]\tvalid_0's multi_logloss: 1.02543\tvalid_0's macrF1: 0.195921\n",
      "[210]\tvalid_0's multi_logloss: 1.02247\tvalid_0's macrF1: 0.195746\n",
      "[240]\tvalid_0's multi_logloss: 1.02068\tvalid_0's macrF1: 0.195515\n",
      "[270]\tvalid_0's multi_logloss: 1.01891\tvalid_0's macrF1: 0.195618\n",
      "[300]\tvalid_0's multi_logloss: 1.01867\tvalid_0's macrF1: 0.195618\n",
      "[330]\tvalid_0's multi_logloss: 1.01895\tvalid_0's macrF1: 0.195618\n",
      "[360]\tvalid_0's multi_logloss: 1.01882\tvalid_0's macrF1: 0.195618\n",
      "[390]\tvalid_0's multi_logloss: 1.01882\tvalid_0's macrF1: 0.195508\n",
      "fold 2 f1 score : 0.19616117065592176\n",
      "[30]\tvalid_0's multi_logloss: 1.198\tvalid_0's macrF1: 0.184399\n",
      "[60]\tvalid_0's multi_logloss: 1.03466\tvalid_0's macrF1: 0.172478\n",
      "[90]\tvalid_0's multi_logloss: 1.00419\tvalid_0's macrF1: 0.172565\n",
      "[120]\tvalid_0's multi_logloss: 0.98772\tvalid_0's macrF1: 0.171546\n",
      "[150]\tvalid_0's multi_logloss: 0.979092\tvalid_0's macrF1: 0.1721\n",
      "[180]\tvalid_0's multi_logloss: 0.97508\tvalid_0's macrF1: 0.177939\n",
      "[210]\tvalid_0's multi_logloss: 0.973965\tvalid_0's macrF1: 0.177428\n",
      "fold 3 f1 score : 0.18821776434771847\n",
      "[30]\tvalid_0's multi_logloss: 1.24444\tvalid_0's macrF1: 0.161065\n",
      "[60]\tvalid_0's multi_logloss: 1.08474\tvalid_0's macrF1: 0.170175\n",
      "[90]\tvalid_0's multi_logloss: 1.0416\tvalid_0's macrF1: 0.181984\n",
      "[120]\tvalid_0's multi_logloss: 1.02815\tvalid_0's macrF1: 0.190176\n",
      "[150]\tvalid_0's multi_logloss: 1.01684\tvalid_0's macrF1: 0.189558\n",
      "[180]\tvalid_0's multi_logloss: 1.0097\tvalid_0's macrF1: 0.190069\n",
      "[210]\tvalid_0's multi_logloss: 1.00958\tvalid_0's macrF1: 0.189341\n",
      "[240]\tvalid_0's multi_logloss: 1.0085\tvalid_0's macrF1: 0.189365\n",
      "[270]\tvalid_0's multi_logloss: 1.0072\tvalid_0's macrF1: 0.189365\n",
      "[300]\tvalid_0's multi_logloss: 1.00744\tvalid_0's macrF1: 0.189535\n",
      "[330]\tvalid_0's multi_logloss: 1.00745\tvalid_0's macrF1: 0.189341\n",
      "fold 4 f1 score : 0.18910889998154812\n",
      "seed 452 f1 score : 0.19199858656887728\n",
      "[30]\tvalid_0's multi_logloss: 1.23239\tvalid_0's macrF1: 0.175514\n",
      "[60]\tvalid_0's multi_logloss: 1.07704\tvalid_0's macrF1: 0.177289\n",
      "[90]\tvalid_0's multi_logloss: 1.04575\tvalid_0's macrF1: 0.178957\n",
      "[120]\tvalid_0's multi_logloss: 1.02831\tvalid_0's macrF1: 0.188927\n",
      "[150]\tvalid_0's multi_logloss: 1.019\tvalid_0's macrF1: 0.192908\n",
      "[180]\tvalid_0's multi_logloss: 1.01839\tvalid_0's macrF1: 0.189171\n",
      "[210]\tvalid_0's multi_logloss: 1.01794\tvalid_0's macrF1: 0.189243\n",
      "[240]\tvalid_0's multi_logloss: 1.01513\tvalid_0's macrF1: 0.188969\n",
      "[270]\tvalid_0's multi_logloss: 1.01372\tvalid_0's macrF1: 0.188396\n",
      "[300]\tvalid_0's multi_logloss: 1.01357\tvalid_0's macrF1: 0.188576\n",
      "[330]\tvalid_0's multi_logloss: 1.01383\tvalid_0's macrF1: 0.188215\n",
      "fold 1 f1 score : 0.17829239784971074\n",
      "[30]\tvalid_0's multi_logloss: 1.25992\tvalid_0's macrF1: 0.160191\n",
      "[60]\tvalid_0's multi_logloss: 1.09935\tvalid_0's macrF1: 0.162987\n",
      "[90]\tvalid_0's multi_logloss: 1.05244\tvalid_0's macrF1: 0.173001\n",
      "[120]\tvalid_0's multi_logloss: 1.04037\tvalid_0's macrF1: 0.174073\n",
      "[150]\tvalid_0's multi_logloss: 1.0366\tvalid_0's macrF1: 0.174891\n",
      "[180]\tvalid_0's multi_logloss: 1.03539\tvalid_0's macrF1: 0.174986\n",
      "[210]\tvalid_0's multi_logloss: 1.03583\tvalid_0's macrF1: 0.174787\n",
      "[240]\tvalid_0's multi_logloss: 1.03353\tvalid_0's macrF1: 0.175145\n",
      "[270]\tvalid_0's multi_logloss: 1.03414\tvalid_0's macrF1: 0.174787\n",
      "[300]\tvalid_0's multi_logloss: 1.03485\tvalid_0's macrF1: 0.174608\n",
      "[330]\tvalid_0's multi_logloss: 1.03371\tvalid_0's macrF1: 0.174608\n",
      "fold 2 f1 score : 0.1733819636260896\n",
      "[30]\tvalid_0's multi_logloss: 1.20696\tvalid_0's macrF1: 0.16256\n",
      "[60]\tvalid_0's multi_logloss: 1.04659\tvalid_0's macrF1: 0.170322\n",
      "[90]\tvalid_0's multi_logloss: 1.01311\tvalid_0's macrF1: 0.171475\n",
      "[120]\tvalid_0's multi_logloss: 0.997464\tvalid_0's macrF1: 0.17801\n",
      "[150]\tvalid_0's multi_logloss: 0.993035\tvalid_0's macrF1: 0.177998\n",
      "[180]\tvalid_0's multi_logloss: 0.988255\tvalid_0's macrF1: 0.178348\n",
      "[210]\tvalid_0's multi_logloss: 0.992506\tvalid_0's macrF1: 0.178771\n",
      "[240]\tvalid_0's multi_logloss: 0.993073\tvalid_0's macrF1: 0.178764\n",
      "[270]\tvalid_0's multi_logloss: 0.992033\tvalid_0's macrF1: 0.178665\n",
      "[300]\tvalid_0's multi_logloss: 0.991554\tvalid_0's macrF1: 0.178825\n",
      "[330]\tvalid_0's multi_logloss: 0.990755\tvalid_0's macrF1: 0.178667\n",
      "[360]\tvalid_0's multi_logloss: 0.990635\tvalid_0's macrF1: 0.178645\n",
      "fold 3 f1 score : 0.17814292356956266\n",
      "[30]\tvalid_0's multi_logloss: 1.22312\tvalid_0's macrF1: 0.196461\n",
      "[60]\tvalid_0's multi_logloss: 1.08031\tvalid_0's macrF1: 0.193351\n",
      "[90]\tvalid_0's multi_logloss: 1.04982\tvalid_0's macrF1: 0.194053\n",
      "[120]\tvalid_0's multi_logloss: 1.03828\tvalid_0's macrF1: 0.186475\n",
      "[150]\tvalid_0's multi_logloss: 1.03352\tvalid_0's macrF1: 0.186936\n",
      "[180]\tvalid_0's multi_logloss: 1.02656\tvalid_0's macrF1: 0.191458\n",
      "[210]\tvalid_0's multi_logloss: 1.02093\tvalid_0's macrF1: 0.183378\n",
      "fold 4 f1 score : 0.19716395074152307\n",
      "seed 226 f1 score : 0.18629425642272193\n",
      "[30]\tvalid_0's multi_logloss: 1.26204\tvalid_0's macrF1: 0.159828\n",
      "[60]\tvalid_0's multi_logloss: 1.1042\tvalid_0's macrF1: 0.180692\n",
      "[90]\tvalid_0's multi_logloss: 1.06998\tvalid_0's macrF1: 0.179469\n",
      "[120]\tvalid_0's multi_logloss: 1.05271\tvalid_0's macrF1: 0.179448\n",
      "[150]\tvalid_0's multi_logloss: 1.04546\tvalid_0's macrF1: 0.179446\n",
      "[180]\tvalid_0's multi_logloss: 1.0471\tvalid_0's macrF1: 0.179528\n",
      "[210]\tvalid_0's multi_logloss: 1.04466\tvalid_0's macrF1: 0.187429\n",
      "[240]\tvalid_0's multi_logloss: 1.04525\tvalid_0's macrF1: 0.187429\n",
      "[270]\tvalid_0's multi_logloss: 1.04504\tvalid_0's macrF1: 0.187429\n",
      "[300]\tvalid_0's multi_logloss: 1.04644\tvalid_0's macrF1: 0.187439\n",
      "[330]\tvalid_0's multi_logloss: 1.0445\tvalid_0's macrF1: 0.187429\n",
      "[360]\tvalid_0's multi_logloss: 1.04423\tvalid_0's macrF1: 0.187429\n",
      "[390]\tvalid_0's multi_logloss: 1.04391\tvalid_0's macrF1: 0.187614\n",
      "[420]\tvalid_0's multi_logloss: 1.04414\tvalid_0's macrF1: 0.187703\n",
      "[450]\tvalid_0's multi_logloss: 1.04351\tvalid_0's macrF1: 0.187703\n",
      "[480]\tvalid_0's multi_logloss: 1.04348\tvalid_0's macrF1: 0.187703\n",
      "[510]\tvalid_0's multi_logloss: 1.04328\tvalid_0's macrF1: 0.187703\n",
      "[540]\tvalid_0's multi_logloss: 1.04318\tvalid_0's macrF1: 0.187518\n",
      "[570]\tvalid_0's multi_logloss: 1.04258\tvalid_0's macrF1: 0.187703\n",
      "[600]\tvalid_0's multi_logloss: 1.04204\tvalid_0's macrF1: 0.187703\n",
      "fold 1 f1 score : 0.18981378338711716\n",
      "[30]\tvalid_0's multi_logloss: 1.22288\tvalid_0's macrF1: 0.181946\n",
      "[60]\tvalid_0's multi_logloss: 1.07773\tvalid_0's macrF1: 0.178078\n",
      "[90]\tvalid_0's multi_logloss: 1.0423\tvalid_0's macrF1: 0.179969\n",
      "[120]\tvalid_0's multi_logloss: 1.02929\tvalid_0's macrF1: 0.180014\n",
      "[150]\tvalid_0's multi_logloss: 1.02283\tvalid_0's macrF1: 0.18621\n",
      "[180]\tvalid_0's multi_logloss: 1.01637\tvalid_0's macrF1: 0.186307\n",
      "[210]\tvalid_0's multi_logloss: 1.01443\tvalid_0's macrF1: 0.19387\n",
      "[240]\tvalid_0's multi_logloss: 1.01279\tvalid_0's macrF1: 0.19206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[270]\tvalid_0's multi_logloss: 1.01375\tvalid_0's macrF1: 0.19678\n",
      "[300]\tvalid_0's multi_logloss: 1.01393\tvalid_0's macrF1: 0.19678\n",
      "[330]\tvalid_0's multi_logloss: 1.01271\tvalid_0's macrF1: 0.19678\n",
      "[360]\tvalid_0's multi_logloss: 1.01103\tvalid_0's macrF1: 0.19678\n",
      "[390]\tvalid_0's multi_logloss: 1.01197\tvalid_0's macrF1: 0.197044\n",
      "[420]\tvalid_0's multi_logloss: 1.0122\tvalid_0's macrF1: 0.197044\n",
      "[450]\tvalid_0's multi_logloss: 1.01237\tvalid_0's macrF1: 0.197044\n",
      "[480]\tvalid_0's multi_logloss: 1.01237\tvalid_0's macrF1: 0.196875\n",
      "[510]\tvalid_0's multi_logloss: 1.01095\tvalid_0's macrF1: 0.196875\n",
      "[540]\tvalid_0's multi_logloss: 1.01051\tvalid_0's macrF1: 0.197212\n",
      "[570]\tvalid_0's multi_logloss: 1.01052\tvalid_0's macrF1: 0.197212\n",
      "fold 2 f1 score : 0.19714344748662513\n",
      "[30]\tvalid_0's multi_logloss: 1.24051\tvalid_0's macrF1: 0.168056\n",
      "[60]\tvalid_0's multi_logloss: 1.07692\tvalid_0's macrF1: 0.16691\n",
      "[90]\tvalid_0's multi_logloss: 1.03894\tvalid_0's macrF1: 0.176635\n",
      "[120]\tvalid_0's multi_logloss: 1.03097\tvalid_0's macrF1: 0.171467\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9368/2253600958.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mlgbmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLGBMClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mlgb_best_hyperparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m                                                                                         \u001b[1;31m# 진행상황 보고싶을때 -1을 100으로\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mlgbmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_metric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcustom_metric\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[0mcv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlgbmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mpred_test\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mlgbmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_imgs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0msplits_tr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m    965\u001b[0m                     \u001b[0mvalid_sets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mvalid_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_le\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    966\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 967\u001b[1;33m         super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n\u001b[0m\u001b[0;32m    968\u001b[0m                     \u001b[0meval_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_sample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    969\u001b[0m                     \u001b[0meval_class_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_class_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_init_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_init_score\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m    746\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecord_evaluation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    747\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 748\u001b[1;33m         self._Booster = train(\n\u001b[0m\u001b[0;32m    749\u001b[0m             \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m             \u001b[0mtrain_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    290\u001b[0m                                     evaluation_result_list=None))\n\u001b[0;32m    291\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m         \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   3019\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__set_objective_to_none\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3020\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mLightGBMError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Cannot update due to null objective function.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3021\u001b[1;33m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0m\u001b[0;32m   3022\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3023\u001b[0m                 ctypes.byref(is_finished)))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lucky_seeds = np.random.randint(0, 1000, num_seed_tr)\n",
    "\n",
    "for i, seed in enumerate(lucky_seeds):\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=splits_tr, random_state=seed, shuffle=True) # CV 늘려가면서 하기\n",
    "    cv = np.zeros((rows_train, num_classes))\n",
    "    pred_test = np.zeros((rows_test, num_classes))\n",
    "\n",
    "    for n, (train_idx, val_idx) in enumerate(kfold.split(train_imgs, all_label)):\n",
    "        \n",
    "        x_train, x_val = train_imgs[train_idx], train_imgs[val_idx]\n",
    "        y_train, y_val = all_label[train_idx], all_label[val_idx]\n",
    "\n",
    "        lgbmodel = LGBMClassifier(**lgb_best_hyperparams)\n",
    "                                                                                        # 진행상황 보고싶을때 -1을 100으로\n",
    "        lgbmodel.fit(x_train, y_train, eval_set=[(x_val, y_val)], early_stopping_rounds=200, verbose=30, eval_metric=custom_metric) \n",
    "        cv[val_idx, :] = lgbmodel.predict_proba(x_val)\n",
    "        pred_test += lgbmodel.predict_proba(test_imgs) / splits_tr\n",
    "        print('fold', n+1, 'f1 score :', score_function(y_val, cv[val_idx, :].argmax(1)))\n",
    "        \n",
    "    pred_dict['lgb'+str(seed)] = cv\n",
    "    pred_test_dict['lgb'+str(seed)] = pred_test\n",
    "    print(f'seed {seed}', 'f1 score :', score_function(all_label, np.argmax(cv, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7fe5b4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_label = pd.Series(all_label).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0c21529d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_dict(model, pred_dict, pred_test_dict):\n",
    "    pred_dict_local = {}\n",
    "    for key, value in pred_dict.items():\n",
    "        if model in key:\n",
    "            pred_dict_local[key]=value\n",
    "\n",
    "    pred_test_dict_local = {}\n",
    "    for key, value in pred_test_dict.items():\n",
    "        if model in key:\n",
    "            pred_test_dict_local[key]=value\n",
    "\n",
    "    pred_dict_new_local = dict(sorted(\n",
    "        pred_dict_local.items(), \n",
    "        key=lambda x:score_function((all_label), np.argmax(list(x[1]), axis=1)), reverse=False)[:5])\n",
    "    pred_test_dict_new_local = {}\n",
    "    for key, value in pred_dict_new_local.items():\n",
    "        pred_test_dict_new_local[key]=pred_test_dict_local[key]\n",
    "        \n",
    "    return pred_dict_new_local, pred_test_dict_new_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f37f5c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dict(model, pred_dict, pred_test_dict):\n",
    "    with open('../pickle/pred_dict_'+model+'.pickle', 'wb') as fw:\n",
    "        pickle.dump(pred_dict, fw)\n",
    "    with open('../pickle/pred_test_dict_'+model+'.pickle', 'wb') as fw:\n",
    "        pickle.dump(pred_test_dict, fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "92efa523",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dict_lgb, pred_test_dict_lgb = sort_dict('lgb', pred_dict, pred_test_dict)\n",
    "save_dict('lgb', pred_dict_lgb, pred_test_dict_lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f879e983",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ca71a135",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dict(model):\n",
    "    with open('../pickle/pred_dict_'+model+'.pickle', 'rb') as fw:\n",
    "        pred_dict_new_local = pickle.load(fw)\n",
    "    with open('../pickle/pred_test_dict_'+model+'.pickle', 'rb') as fw:\n",
    "        pred_test_dict_new_local = pickle.load(fw)\n",
    "    return pred_dict_new_local, pred_test_dict_new_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e7f2c7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dict_lgb, pred_test_dict_lgb = load_dict('lgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac06cc8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcb5c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalDataset(Dataset):\n",
    "    def __init__(self, img_path_list, label_list, train_mode=True):\n",
    "        self.train_mode = train_mode\n",
    "        self.img_path_list = img_path_list\n",
    "        self.label_list = label_list\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.img_path_list[index]\n",
    "        # Get image data\n",
    "        img = cv2.imread(img_path)\n",
    "\n",
    "        if self.train_mode:\n",
    "            label = self.label_list[index]\n",
    "            return image, label\n",
    "        else:\n",
    "            return image\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749833b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits_tr = 4\n",
    "num_classes = 15\n",
    "basic_seed = 42\n",
    "rows_train = len(all_img_path) # 주어진 train data의 row 수\n",
    "rows_test = len(test_img_path) # 주어진 test data의 row 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07e5dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local(model, optimizer, train_loader, vali_loader, device):\n",
    "    model.to(device)\n",
    "\n",
    "    # Loss Function\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    best_score = 0\n",
    "    \n",
    "    for epoch in range(1,CFG[\"EPOCHS\"]+1):\n",
    "        train_pred=[]\n",
    "        train_y=[]\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for img, label in tqdm(iter(train_loader)):\n",
    "            \n",
    "            img, label = img.float().to(device), label.float().to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Data -> Model -> Output\n",
    "            logit = model(img)\n",
    "            label = label.to(torch.int64)\n",
    "            loss = criterion(logit, label)\n",
    "\n",
    "            # backpropagation\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()/len(train_loader)\n",
    "            train_pred += logit.argmax(1).detach().cpu().numpy().tolist()\n",
    "            train_y += label.detach().cpu().numpy().tolist()\n",
    "            \n",
    "        # Evaluation Validation set\n",
    "        vali_score = validation_local(model, vali_loader, device)\n",
    "        \n",
    "        # vali_score가 더 이상 커지지 않으면\n",
    "        if scheduler is not None:\n",
    "            scheduler.step(vali_score)\n",
    "        \n",
    "        print(f'Epoch [{epoch}] Train Score : [{accuracy_score(train_y, train_pred):.5f}] Validation Score : [{vali_score:.5f}]\\n')\n",
    "        \n",
    "        # Model Saved\n",
    "        if best_score < vali_score:\n",
    "            best_score = vali_score\n",
    "            torch.save(model.state_dict(), '../model/local_model.pth')\n",
    "            print('Model Saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b318d69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_local(model, vali_loader, device):\n",
    "    model.eval() # Evaluation\n",
    "    logit_list = []\n",
    "    label_list = []\n",
    "    with torch.no_grad():\n",
    "        for img, label in tqdm(iter(vali_loader)):\n",
    "            img, label = img.float().to(device), label.float().to(device)\n",
    "            label = label.to(torch.int64)\n",
    "\n",
    "            logit_list.extend(model(img).argmax(1).detach().cpu().numpy().tolist())\n",
    "            label_list.extend(label.detach().cpu().numpy().tolist())\n",
    "\n",
    "    vali_f1_score = accuracy_score(label_list, logit_list)\n",
    "    return vali_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b935727",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_local(model, test_loader, device):\n",
    "    model.eval()\n",
    "    model_pred = []\n",
    "    with torch.no_grad():\n",
    "        for img in tqdm(iter(test_loader)):\n",
    "            \n",
    "            img = img.float().to(device)\n",
    "\n",
    "            pred_logit = model(img).detach().cpu()\n",
    "            model_pred.extend(pred_logit.tolist())\n",
    "    return model_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da7ea3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, img_path_list, label_list, train_mode=True, transforms=None):\n",
    "        self.transforms = transforms\n",
    "        self.train_mode = train_mode\n",
    "        self.img_path_list = img_path_list\n",
    "        self.label_list = label_list\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.img_path_list[index]\n",
    "        # Get image data\n",
    "        img = cv2.imread(img_path)\n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(image=img)[\"image\"]\n",
    "\n",
    "        if self.train_mode:\n",
    "            label = self.label_list[index]\n",
    "            return image, label\n",
    "        else:\n",
    "            return image\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img_path_list)\n",
    "    \n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.model = timm.create_model('efficientnet_b0', pretrained=True, num_classes=num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07269d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = albu.Compose([\n",
    "    albu.Resize(CFG['IMG_SIZE'], CFG['IMG_SIZE']),\n",
    "    ToTensorV2()]\n",
    ")\n",
    "\n",
    "valid_transform = albu.Compose([\n",
    "    albu.Resize(CFG['IMG_SIZE'], CFG['IMG_SIZE']),\n",
    "    ToTensorV2()]\n",
    ")\n",
    "\n",
    "test_transform = albu.Compose([\n",
    "    albu.Resize(CFG['IMG_SIZE'], CFG['IMG_SIZE']),\n",
    "    ToTensorV2()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf86e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CustomDataset(test_img_path, None, train_mode=False, transforms=test_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=0)\n",
    "\n",
    "kfold = KFold(n_splits=splits_tr, random_state=basic_seed, shuffle=True) # CV 늘려가면서 하기\n",
    "cv = np.zeros((rows_train, num_classes))\n",
    "pred_test = np.zeros((rows_test, num_classes))\n",
    "for n, (train_idx, val_idx) in enumerate(kfold.split(all_img_path, all_classes)):\n",
    "    \n",
    "    train_img_path, vali_img_path = all_img_path[train_idx], all_img_path[val_idx]\n",
    "    train_classes, vali_classes = all_classes[train_idx], all_classes[val_idx]\n",
    "    \n",
    "    # Get Dataloader\n",
    "    train_dataset = CustomDataset(train_img_path.tolist(), train_classes.tolist(), train_mode=True, transforms=train_transform)\n",
    "    train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=True, num_workers=0)\n",
    "\n",
    "    vali_dataset = CustomDataset(vali_img_path.tolist(), vali_classes.tolist(), train_mode=True, transforms=valid_transform)\n",
    "    vali_loader = DataLoader(vali_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=0)\n",
    "    \n",
    "    model = Network().to(device)\n",
    "    optimizer = torch.optim.SGD(params = model.parameters(), lr = CFG[\"LEARNING_RATE\"])\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, mode='max', patience=3, factor=0.2)\n",
    "    \n",
    "    train_local(model, optimizer, train_loader, vali_loader, device)\n",
    "    \n",
    "#     checkpoint = torch.load('../model/local_model.pth')\n",
    "#     model = Network().to(device)\n",
    "#     model.load_state_dict(checkpoint)\n",
    "    \n",
    "    vali_dataset = CustomDataset(vali_img_path.tolist(), vali__classes.tolist(), train_mode=False, transforms=test_transform)\n",
    "    vali_loader = DataLoader(vali_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=0)\n",
    "    \n",
    "    cv[val_idx, :] = predict_local(model, vali_loader, device)\n",
    "    pred_test += np.array(predict_local(model, test_loader, device)) / splits_tr\n",
    "    print(f\"Fold {n+1} Score: {accuracy_score(vali__classes, cv[val_idx].argmax(axis=1))}\")\n",
    "\n",
    "print(f\"Final Score: {accuracy_score(all_classes, cv.argmax(axis=1))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3341d9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_local_final = [class_decoder[result] for result in pred_test.argmax(1)]\n",
    "with open('../pickle/pred_local_final.pickle', 'wb') as fw:\n",
    "    pickle.dump(pred_local_final, fw)\n",
    "test_local_df = pd.DataFrame(np.column_stack([test_img_path, pred_local_final]), columns=[\"path\", \"class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59d30c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../pickle/pred_local_final.pickle', 'rb') as fw:\n",
    "    pred_local_final = pickle.load(fw)\n",
    "test_local_df = pd.DataFrame(np.column_stack([test_img_path, pred_local_final]), columns=[\"path\", \"class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d465750c",
   "metadata": {},
   "outputs": [],
   "source": [
    "classList = train_y['class'].unique()\n",
    "anomaly_test_dict = {}\n",
    "for className in classList:\n",
    "    anomaly_test_dict[className] = test_local_df[test_local_df[\"class\"]==className]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2380e97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classList = train_y['class'].unique()\n",
    "anomaly_dict = {}\n",
    "for className in classList:\n",
    "    index = train_classes[train_classes==className].index\n",
    "    df = pd.DataFrame(np.column_stack([all_img_path[index], all_label[index]]), columns=[\"path\", \"label\"])\n",
    "    anomaly_dict[className] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc80e467",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits_tr = 4\n",
    "num_classes = len(anomaly_dict['wood']['label'].unique())\n",
    "basic_seed = 42\n",
    "rows_train = len(anomaly_dict['wood']) # 주어진 train data의 row 수\n",
    "rows_test = len(anomaly_test_dict['wood']) # 주어진 test data의 row 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23c608d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.model = timm.create_model('efficientnet_b7', pretrained=True, num_classes=num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8321f69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = albu.Compose([\n",
    "    albu.Resize(CFG['IMG_SIZE'], CFG['IMG_SIZE']),\n",
    "#     albu.RandomCrop(CFG['IMG_SIZE']-64, CFG['IMG_SIZE']-64),\n",
    "#     albu.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.1,\n",
    "#                           rotate_limit=30, interpolation=1, border_mode=0,\n",
    "#                           value=0, p=0.5),\n",
    "#     albu.HorizontalFlip(p=0.2),\n",
    "#     albu.VerticalFlip(p=0.2),\n",
    "#     albu.RandomRotate90(p=0.2),\n",
    "#     albu.CLAHE(clip_limit=2, p=0.25),\n",
    "#     albu.Sharpen(p=0.25),\n",
    "#     albu.RandomBrightnessContrast(brightness_limit=(-0.1, 0.1),\n",
    "#                                   contrast_limit=(-0.1, 0.1), p=0.25),\n",
    "#     albu.RandomResizedCrop(height=CFG['IMG_SIZE'], width=CFG['IMG_SIZE'],\n",
    "#                            scale=(0.5, 1.0), ratio=(0.75, 1.3333333333333333),\n",
    "#                            interpolation=1, p=1.0),\n",
    "#     albu.Normalize(mean=IMAGENET_DEFAULT_MEAN, std=IMAGENET_DEFAULT_STD, max_pixel_value=512.0, p=1.0),\n",
    "    ToTensorV2()]\n",
    ")\n",
    "\n",
    "valid_transform = albu.Compose([\n",
    "    albu.Resize(CFG['IMG_SIZE'], CFG['IMG_SIZE']),\n",
    "#     albu.HorizontalFlip(p=0.5),\n",
    "#     albu.VerticalFlip(p=0.5),\n",
    "#     albu.Normalize(mean=IMAGENET_DEFAULT_MEAN, std=IMAGENET_DEFAULT_STD, max_pixel_value=512.0, p=1.0),\n",
    "    ToTensorV2()]\n",
    ")\n",
    "\n",
    "test_transform = albu.Compose([\n",
    "    albu.Resize(CFG['IMG_SIZE'], CFG['IMG_SIZE']),\n",
    "#     albu.Normalize(mean=IMAGENET_DEFAULT_MEAN, std=IMAGENET_DEFAULT_STD, max_pixel_value=512.0, p=1.0),\n",
    "    ToTensorV2()]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048cafbe",
   "metadata": {},
   "source": [
    "### 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7993bc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_loader, vali_loader, scheduler, device):\n",
    "    model.to(device)\n",
    "\n",
    "    # Loss Function\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    best_score = 0\n",
    "    \n",
    "    for epoch in range(1,CFG[\"EPOCHS\"]+1):\n",
    "        train_pred=[]\n",
    "        train_y=[]\n",
    "        model.train()\n",
    "#         train_loss = 0\n",
    "        for img, label in tqdm(iter(train_loader)):\n",
    "            \n",
    "            img, label = img.float().to(device), label.float().to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Data -> Model -> Output\n",
    "            logit = model(img)\n",
    "            label = label.to(torch.int64)\n",
    "            loss = criterion(logit, label)\n",
    "\n",
    "            # backpropagation\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "#             train_loss += loss.item()/len(train_loader)\n",
    "            train_pred += logit.argmax(1).detach().cpu().numpy().tolist()\n",
    "            train_y += label.detach().cpu().numpy().tolist()\n",
    "            \n",
    "        # Evaluation Validation set\n",
    "        vali_score = validation(model, vali_loader, device)\n",
    "        \n",
    "        # vali_score가 더 이상 커지지 않으면\n",
    "        if scheduler is not None:\n",
    "            scheduler.step(vali_score)\n",
    "        \n",
    "        print(f'Epoch [{epoch}] Train Score : [{score_function(train_y, train_pred):.5f}] Validation Score : [{vali_score:.5f}]\\n')\n",
    "        \n",
    "        # Model Saved\n",
    "        if best_score < vali_score:\n",
    "            best_score = vali_score\n",
    "            torch.save(model.state_dict(), '../model/best_model.pth')\n",
    "            print('Model Saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a9d155",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, vali_loader, device):\n",
    "    model.eval() # Evaluation\n",
    "    logit_list = []\n",
    "    label_list = []\n",
    "    with torch.no_grad():\n",
    "        for img, label in tqdm(iter(vali_loader)):\n",
    "            img, label = img.float().to(device), label.float().to(device)\n",
    "            label = label.to(torch.int64)\n",
    "\n",
    "            logit_list.extend(model(img).argmax(1).detach().cpu().numpy().tolist())\n",
    "            label_list.extend(label.detach().cpu().numpy().tolist())\n",
    "\n",
    "    vali_f1_score = score_function(label_list, logit_list)\n",
    "    return vali_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e6bacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset = CustomDataset(test_img_path, None, train_mode=False, transforms=test_transform)\n",
    "# test_loader = DataLoader(test_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=0)\n",
    "\n",
    "def predict(model, test_loader, device):\n",
    "    model.eval()\n",
    "    model_pred = []\n",
    "    with torch.no_grad():\n",
    "        for img in tqdm(iter(test_loader)):\n",
    "            \n",
    "            img = img.float().to(device)\n",
    "\n",
    "            pred_logit = model(img).detach().cpu()\n",
    "            model_pred.extend(pred_logit.tolist())\n",
    "    return model_pred\n",
    "\n",
    "def score_function(real, pred):\n",
    "    score = f1_score(real, pred, average=\"macro\")\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedc706b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rows_train = len(all_img_path) # 주어진 train data의 row 수\n",
    "# rows_test = len(test_img_path) # 주어진 test data의 row 수\n",
    "# num_trial = 100 # 파라미터 튜닝을 몇 번 진행하는지의 수\n",
    "# splits_hp = 5 # 파라미터 튜닝을 진행할 때의 kfold 수\n",
    "# splits_tr = 5 # 모델 트레이닝을 진행할 때의 kfold 수\n",
    "# basic_seed = 42 # default seed\n",
    "# num_seed_tr = 10 # 트레이닝 seed 개수\n",
    "# sel_seed = 3 # 선택할 seed 개수\n",
    "# num_classes = 88\n",
    "\n",
    "# pred_dict = {}\n",
    "# pred_test_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f946c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_img_path = np.array(anomaly_dict['wood']['path'])\n",
    "local_label_raw = np.array(anomaly_dict['wood']['label']).astype(\"int32\")\n",
    "local_test_path = np.array(anomaly_test_dict['wood']['path'])\n",
    "\n",
    "test_dataset = CustomDataset(local_test_path.tolist(), None, train_mode=False, transforms=test_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da4c87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_unique = sorted(np.unique(local_label_raw))\n",
    "local_unique = {key:value for key,value in zip(local_unique, range(len(local_unique)))}\n",
    "local_label = np.array([local_unique[k] for k in local_label_raw])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc3450e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'IMG_SIZE':512,\n",
    "    'EPOCHS':30,\n",
    "    'LEARNING_RATE':5e-2,\n",
    "    'BATCH_SIZE':1,\n",
    "    'SEED':42\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1839d4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna import Trial\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.visualization import plot_contour, plot_optimization_history\n",
    "from optuna.visualization import plot_parallel_coordinate, plot_slice, plot_param_importances\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd77855",
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_load(path):\n",
    "    img = cv2.imread(path)[:,:,::-1]\n",
    "    img = cv2.resize(img, (64, 64)).flatten()\n",
    "    return img\n",
    "\n",
    "# train_imgs = [img_load(m) for m in tqdm(train_png)]\n",
    "# test_imgs = [img_load(n) for n in tqdm(test_png)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fef352",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_img = np.array([img_load(m) for m in tqdm(local_img_path)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431a7faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a611230",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_objective(trial: Trial) -> float:\n",
    "    params_lgb = {\n",
    "        \"random_state\": basic_seed,\n",
    "        \"verbosity\": -1,\n",
    "        \"n_estimators\": 10000,\n",
    "        \"objective\": \"multiclass\",\n",
    "        \"metric\": \"multi_logloss\",\n",
    "        'learning_rate': trial.suggest_uniform(\"learning_rate\", 0.001, 0.01),\n",
    "        \"reg_alpha\": trial.suggest_uniform(\"reg_alpha\", 0.0, 1),\n",
    "        \"reg_lambda\": trial.suggest_uniform(\"reg_lambda\", 0.0, 1),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 5, 10),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 200, 1200),\n",
    "        \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0), # feature_fraction\n",
    "        \"subsample\": trial.suggest_uniform(\"subsample\", 0.0, 1.0),\n",
    "        \"subsample_freq\": trial.suggest_int(\"subsample_freq\", 1, 10),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 1, 10),\n",
    "        \"max_bin\": trial.suggest_int(\"max_bin\", 150, 400),\n",
    "    }\n",
    "    \n",
    "    kfold = StratifiedKFold(n_splits=splits_hp, random_state=basic_seed, shuffle = True) # Cross-validation cv=5\n",
    "    cv = np.zeros((rows_train, num_classes))\n",
    "\n",
    "    for n, (train_idx, val_idx) in enumerate(kfold.split(local_img, local_label)):\n",
    "\n",
    "        x_train, x_val = local_img[train_idx], local_img[val_idx]\n",
    "        y_train, y_val = local_label[train_idx], local_label[val_idx]\n",
    "\n",
    "        lgbmodel = LGBMClassifier(**params_lgb)\n",
    "                                                                                        # 진행상황 보고싶을때 -1을 100으로\n",
    "        lgbmodel.fit(x_train, y_train, eval_set=[(x_val, y_val)], early_stopping_rounds=100, verbose=-1, eval_metric=custom_metric) \n",
    "        cv[val_idx, :] = lgbmodel.predict_proba(x_val)\n",
    "        \n",
    "#         print('fold', n+1, 'f1_score:', score_function(y_val, cv[val_idx, :].argmax(1)))\n",
    "        \n",
    "#     print('f1_score:', score_function(local_label, np.argmax(cv, axis=1)))\n",
    "    return score_function(local_label, np.argmax(cv, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ea4f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trial = 100\n",
    "splits_hp = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d9970d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_metric(truth, predictions):  \n",
    "    pred_labels = predictions.reshape(len(np.unique(truth)),-1).argmax(axis=0)\n",
    "    f1 = f1_score(truth, pred_labels, average='macro')\n",
    "    return ('macroF1', f1, True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044f232b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = TPESampler(seed=basic_seed)\n",
    "lgb_study = optuna.create_study(study_name=\"lgb_parameter_opt\", direction=\"maximize\", sampler=sampler)\n",
    "lgb_study.optimize(lgb_objective, n_trials=num_trial)\n",
    "\n",
    "lgb_best_hyperparams = lgb_study.best_trial.params\n",
    "lgb_base_hyperparams = {'objective':'multiclass', 'n_estimators':10000,\n",
    "                        'lambda_l1':lgb_best_hyperparams['reg_alpha'],\n",
    "                        'lambda_l2':lgb_best_hyperparams['reg_lambda'],\n",
    "                        'reg_alpha':None, 'reg_lambda':None\n",
    "                       }\n",
    "lgb_best_hyperparams.update(lgb_base_hyperparams)\n",
    "print(\"The best hyperparameters are:\\n\", lgb_best_hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e971296",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c3748a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e60125",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49e8486",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0662c7c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebeb5a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefa63a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00253373",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b684f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556db972",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c41125",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=splits_tr, random_state=basic_seed, shuffle=True) # CV 늘려가면서 하기\n",
    "cv = np.zeros((rows_train, num_classes))\n",
    "pred_test = np.zeros((rows_test, num_classes))\n",
    "for n, (train_idx, val_idx) in enumerate(kfold.split(local_img_path, local_label)):\n",
    "    \n",
    "    train_img_path, vali_img_path = local_img_path[train_idx], local_img_path[val_idx]\n",
    "    train_label, vali_label = local_label[train_idx], local_label[val_idx]\n",
    "    \n",
    "    # Get Dataloader\n",
    "    train_dataset = CustomDataset(train_img_path.tolist(), train_label.tolist(), train_mode=True, transforms=train_transform)\n",
    "    train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=True, num_workers=0)\n",
    "\n",
    "    vali_dataset = CustomDataset(vali_img_path.tolist(), vali_label.tolist(), train_mode=True, transforms=valid_transform)\n",
    "    vali_loader = DataLoader(vali_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=0)\n",
    "    \n",
    "    model = Network().to(device)\n",
    "    optimizer = torch.optim.SGD(params = model.parameters(), lr = CFG[\"LEARNING_RATE\"])\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, mode='max', patience=5, factor=0.2)\n",
    "    \n",
    "    train(model, optimizer, train_loader, vali_loader, scheduler, device)\n",
    "    \n",
    "    checkpoint = torch.load('../model/best_model.pth')\n",
    "    model = Network().to(device)\n",
    "    model.load_state_dict(checkpoint)\n",
    "    \n",
    "    vali_dataset = CustomDataset(vali_img_path.tolist(), vali_label.tolist(), train_mode=False, transforms=test_transform)\n",
    "    vali_loader = DataLoader(vali_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=0)\n",
    "    \n",
    "    cv[val_idx, :] = predict(model, vali_loader, device)\n",
    "    pred_test += np.array(predict(model, test_loader, device)) / splits_tr\n",
    "    print(f\"Fold {n+1} Score: {score_function(vali_label, cv[val_idx].argmax(axis=1))}\")\n",
    "    \n",
    "pred_dict['eff_b0'+str(seed)] = cv\n",
    "pred_test_dict['eff_b0'+str(seed)] = pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e973e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dict = {}\n",
    "pred_test_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9ea28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dict['eff_b0'+str(42)] = cv\n",
    "pred_test_dict['eff_b0'+str(42)] = pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3434683b",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=splits_tr, random_state=basic_seed, shuffle=True) # CV 늘려가면서 하기\n",
    "cv = np.zeros((rows_train, num_classes))\n",
    "pred_test = np.zeros((rows_test, num_classes))\n",
    "for n, (train_idx, val_idx) in enumerate(kfold.split(all_img_path, all_label)):\n",
    "    \n",
    "    train_img_path, vali_img_path = all_img_path[train_idx], all_img_path[val_idx]\n",
    "    train_label, vali_label = all_label[train_idx], all_label[val_idx]\n",
    "    \n",
    "    # Get Dataloader\n",
    "    train_dataset = CustomDataset(train_img_path.tolist(), train_label.tolist(), train_mode=True, transforms=train_transform)\n",
    "    train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=True, num_workers=0)\n",
    "\n",
    "    vali_dataset = CustomDataset(vali_img_path.tolist(), vali_label.tolist(), train_mode=True, transforms=valid_transform)\n",
    "    vali_loader = DataLoader(vali_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=0)\n",
    "    \n",
    "    model = Network().to(device)\n",
    "    optimizer = torch.optim.SGD(params = model.parameters(), lr = CFG[\"LEARNING_RATE\"])\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, mode='max', patience=3, factor=0.2)\n",
    "    \n",
    "    train(model, optimizer, train_loader, vali_loader, scheduler, device)\n",
    "    \n",
    "    checkpoint = torch.load('../model/best_model.pth')\n",
    "    model = Network().to(device)\n",
    "    model.load_state_dict(checkpoint)\n",
    "    \n",
    "    vali_dataset = CustomDataset(vali_img_path.tolist(), vali_label.tolist(), train_mode=False, transforms=test_transform)\n",
    "    vali_loader = DataLoader(vali_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=0)\n",
    "    \n",
    "    cv[val_idx, :] = predict(model, vali_loader, device)\n",
    "    pred_test += np.array(predict(model, test_loader, device)) / splits_tr\n",
    "    print(f\"Fold {n+1} Score: {score_function(vali_label, cv[val_idx].argmax(axis=1))}\")\n",
    "    \n",
    "pred_dict['eff_b0'+str(seed)] = cv\n",
    "pred_test_dict['eff_b0'+str(seed)] = pred_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443bced0",
   "metadata": {},
   "source": [
    "### 추론"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac561815",
   "metadata": {},
   "source": [
    "### 제출물 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b0ce22",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_decoder = {val:key for key, val in label_unique.items()}\n",
    "pred_final = [label_decoder[result] for result in pred_test.argmax(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0587dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "submission = pd.read_csv('../data/sample_submission.csv')\n",
    "submission[\"label\"] = pred_final\n",
    "submission_time = datetime.today().strftime('%Y-%m-%d-%M-%S')\n",
    "submission.to_csv(f'../submission/{submission_time}.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e73a637",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
