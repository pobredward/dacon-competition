{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "charming-investigator",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "LlcNsGEk7L5r",
   "metadata": {
    "id": "LlcNsGEk7L5r"
   },
   "outputs": [],
   "source": [
    "name = \"effb7ns_cv10_lr0005_batch32\"\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from tqdm.auto import tqdm\n",
    "import cv2\n",
    "import pickle\n",
    "\n",
    "import os\n",
    "import timm\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "FWntO1VD7L5u",
   "metadata": {
    "id": "FWntO1VD7L5u"
   },
   "outputs": [],
   "source": [
    "train_png = sorted(glob('../data/train/*.png'))\n",
    "test_png = sorted(glob('../data/test/*.png'))\n",
    "\n",
    "train_y = pd.read_csv(\"../data/train_df.csv\")\n",
    "\n",
    "train_labels = train_y[\"label\"]\n",
    "\n",
    "label_unique = sorted(np.unique(train_labels))\n",
    "label_unique = {key:value for key,value in zip(label_unique, range(len(label_unique)))}\n",
    "\n",
    "train_labels = [label_unique[k] for k in train_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "brazilian-samoa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_load(path):\n",
    "    img = cv2.imread(path)[:,:,::-1]\n",
    "    img = cv2.resize(img, (384, 384),interpolation = cv2.INTER_AREA)\n",
    "    return img\n",
    "\n",
    "# train_imgs = [img_load(m) for m in tqdm(train_png)]\n",
    "# test_imgs = [img_load(n) for n in tqdm(test_png)]\n",
    "\n",
    "# np.save('../data/train_imgs_384', np.array(train_imgs))\n",
    "# np.save('../data/test_imgs_384', np.array(test_imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "L6qBdX7nCp8L",
   "metadata": {
    "id": "L6qBdX7nCp8L"
   },
   "outputs": [],
   "source": [
    "train_imgs = np.load('../data/train_imgs_384.npy')\n",
    "test_imgs = np.load('../data/test_imgs_384.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "sscGLiJKPy6H",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sscGLiJKPy6H",
    "outputId": "976516c0-507d-458f-f0c4-6695751605d6"
   },
   "outputs": [],
   "source": [
    "# meanRGB = [np.mean(x, axis=(0,1)) for x in train_imgs]\n",
    "# stdRGB = [np.std(x, axis=(0,1)) for x in train_imgs]\n",
    "\n",
    "# meanR = np.mean([m[0] for m in meanRGB])/255\n",
    "# meanG = np.mean([m[1] for m in meanRGB])/255\n",
    "# meanB = np.mean([m[2] for m in meanRGB])/255\n",
    "\n",
    "# stdR = np.mean([s[0] for s in stdRGB])/255\n",
    "# stdG = np.mean([s[1] for s in stdRGB])/255\n",
    "# stdB = np.mean([s[2] for s in stdRGB])/255\n",
    "\n",
    "# print(\"train 평균\",meanR, meanG, meanB)\n",
    "# print(\"train 표준편차\",stdR, stdG, stdB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "JwVIQCrUSCFE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JwVIQCrUSCFE",
    "outputId": "293981ef-7f6a-4602-d208-5fd8473d5261"
   },
   "outputs": [],
   "source": [
    "# meanRGB = [np.mean(x, axis=(0,1)) for x in test_imgs]\n",
    "# stdRGB = [np.std(x, axis=(0,1)) for x in test_imgs]\n",
    "\n",
    "# meanR = np.mean([m[0] for m in meanRGB])/255\n",
    "# meanG = np.mean([m[1] for m in meanRGB])/255\n",
    "# meanB = np.mean([m[2] for m in meanRGB])/255\n",
    "\n",
    "# stdR = np.mean([s[0] for s in stdRGB])/255\n",
    "# stdG = np.mean([s[1] for s in stdRGB])/255\n",
    "# stdB = np.mean([s[2] for s in stdRGB])/255\n",
    "\n",
    "# print(\"test 평균\",meanR, meanG, meanB)\n",
    "# print(\"test 표준편차\",stdR, stdG, stdB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "VFXzojoo7L5y",
   "metadata": {
    "id": "VFXzojoo7L5y"
   },
   "outputs": [],
   "source": [
    "class Custom_dataset(Dataset):\n",
    "    def __init__(self, img_paths, labels, mode='train'):\n",
    "        self.img_paths = img_paths\n",
    "        self.labels = labels\n",
    "        self.mode=mode\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.img_paths[idx]\n",
    "        if self.mode == 'train':\n",
    "            train_transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean = [0.433038, 0.403458, 0.394151],\n",
    "                                     std = [0.181572, 0.174035, 0.163234]),\n",
    "                transforms.RandomAffine((-45, 45)),\n",
    "            ])\n",
    "            img = train_transform(img)\n",
    "        if self.mode == 'test':\n",
    "            test_transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean = [0.418256, 0.393101, 0.386632],\n",
    "                                     std = [0.195055, 0.190053, 0.185323])\n",
    "            ])\n",
    "            img = test_transform(img)\n",
    "\n",
    "        \n",
    "        label = self.labels[idx]\n",
    "        return img, label\n",
    "    \n",
    "class Network(nn.Module):\n",
    "    def __init__(self,mode = 'train'):\n",
    "        super(Network, self).__init__()\n",
    "        self.mode = mode\n",
    "        if self.mode == 'train':\n",
    "            self.model = timm.create_model('tf_efficientnet_b7_ns', pretrained=True, num_classes=88, drop_path_rate = 0.2)\n",
    "        if self.mode == 'test':\n",
    "            self.model = timm.create_model('tf_efficientnet_b7_ns', pretrained=True, num_classes=88, drop_path_rate = 0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38qk8sGbYiO_",
   "metadata": {
    "id": "38qk8sGbYiO_"
   },
   "outputs": [],
   "source": [
    "def score_function(real, pred):\n",
    "    score = f1_score(real, pred, average=\"macro\")\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "EnOG2n30-Dz5",
   "metadata": {
    "id": "EnOG2n30-Dz5"
   },
   "outputs": [],
   "source": [
    "def main(seed = 2022):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "main(2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "anonymous-houston",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train_dict = {}\n",
    "pred_test_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "lkNCkyG9RPzX",
   "metadata": {
    "id": "lkNCkyG9RPzX",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold1 epoch0 score: 0.34490\n",
      "fold1 epoch1 score: 0.44805\n",
      "fold1 epoch2 score: 0.43382\n",
      "fold1 epoch3 score: 0.51706\n",
      "fold1 epoch4 score: 0.59745\n",
      "fold1 epoch5 score: 0.63102\n",
      "fold1 epoch6 score: 0.62167\n",
      "fold1 epoch7 score: 0.65484\n",
      "fold1 epoch8 score: 0.69254\n",
      "fold1 epoch9 score: 0.67280\n",
      "fold1 epoch10 score: 0.70401\n",
      "fold1 epoch11 score: 0.69625\n",
      "fold1 epoch12 score: 0.68147\n",
      "fold1 epoch13 score: 0.78360\n",
      "fold1 epoch14 score: 0.76547\n",
      "fold1 epoch15 score: 0.77306\n",
      "fold1 epoch16 score: 0.75278\n",
      "fold1 epoch17 score: 0.76940\n",
      "fold1 epoch18 score: 0.75314\n",
      "fold1 epoch19 score: 0.75290\n",
      "fold1 epoch20 score: 0.76391\n",
      "fold1 epoch21 score: 0.74935\n",
      "fold1 epoch22 score: 0.79931\n",
      "fold1 epoch23 score: 0.71781\n",
      "fold1 epoch24 score: 0.80429\n",
      "fold1 epoch25 score: 0.77726\n",
      "fold1 epoch26 score: 0.76385\n",
      "fold1 epoch27 score: 0.74637\n",
      "fold1 epoch28 score: 0.79753\n",
      "fold1 epoch29 score: 0.77862\n",
      "fold1 epoch30 score: 0.69669\n",
      "fold1 epoch31 score: 0.73488\n",
      "fold1 epoch32 score: 0.72312\n",
      "fold1 epoch33 score: 0.76223\n",
      "fold1 epoch34 score: 0.76194\n",
      "fold1 epoch35 score: 0.77480\n",
      "fold1 epoch36 score: 0.79974\n",
      "fold1 epoch37 score: 0.75492\n",
      "fold1 epoch38 score: 0.78248\n",
      "fold1 epoch39 score: 0.76829\n",
      "fold1 epoch40 score: 0.81432\n",
      "fold1 epoch41 score: 0.77880\n",
      "fold1 epoch42 score: 0.80188\n",
      "fold1 epoch43 score: 0.80013\n",
      "fold1 epoch44 score: 0.74252\n",
      "fold1 epoch45 score: 0.77007\n",
      "fold1 epoch46 score: 0.77338\n",
      "fold1 epoch47 score: 0.81775\n",
      "fold1 epoch48 score: 0.80672\n",
      "fold1 epoch49 score: 0.75888\n",
      "fold1 epoch50 score: 0.82484\n",
      "fold1 epoch51 score: 0.85989\n",
      "fold1 epoch52 score: 0.83703\n",
      "fold1 epoch53 score: 0.84244\n",
      "fold1 epoch54 score: 0.82859\n",
      "fold1 epoch55 score: 0.89567\n",
      "fold1 epoch56 score: 0.84213\n",
      "fold1 epoch57 score: 0.81943\n",
      "fold1 epoch58 score: 0.78150\n",
      "fold1 epoch59 score: 0.84036\n",
      "fold1 epoch60 score: 0.83305\n",
      "fold1 epoch61 score: 0.82704\n",
      "fold1 epoch62 score: 0.77147\n",
      "fold1 epoch63 score: 0.75237\n",
      "fold1 epoch64 score: 0.77643\n",
      "fold1 epoch65 score: 0.83929\n",
      "fold1 epoch66 score: 0.83971\n",
      "fold1 epoch67 score: 0.77910\n",
      "fold1 epoch68 score: 0.78768\n",
      "fold1 epoch69 score: 0.70877\n",
      "epoch : 70/70    time : 119s/0s\n",
      "TRAIN    loss : 0.04007    f1 : 0.96258\n",
      "Val    loss : 0.25201    f1 : 0.70877\n",
      "fold2 epoch0 score: 0.29955\n",
      "fold2 epoch1 score: 0.45726\n",
      "fold2 epoch2 score: 0.66323\n",
      "fold2 epoch3 score: 0.66982\n",
      "fold2 epoch4 score: 0.61229\n",
      "fold2 epoch5 score: 0.66728\n",
      "fold2 epoch6 score: 0.66209\n",
      "fold2 epoch7 score: 0.67781\n",
      "fold2 epoch8 score: 0.69721\n",
      "fold2 epoch9 score: 0.77900\n",
      "fold2 epoch10 score: 0.81761\n",
      "fold2 epoch11 score: 0.70937\n",
      "fold2 epoch12 score: 0.68123\n",
      "fold2 epoch13 score: 0.72947\n",
      "fold2 epoch14 score: 0.80497\n",
      "fold2 epoch15 score: 0.78805\n",
      "fold2 epoch16 score: 0.84968\n",
      "fold2 epoch17 score: 0.73230\n",
      "fold2 epoch18 score: 0.85243\n",
      "fold2 epoch19 score: 0.86075\n",
      "fold2 epoch20 score: 0.77745\n",
      "fold2 epoch21 score: 0.78942\n",
      "fold2 epoch22 score: 0.76987\n",
      "fold2 epoch23 score: 0.83020\n",
      "fold2 epoch24 score: 0.75195\n",
      "fold2 epoch25 score: 0.77978\n",
      "fold2 epoch26 score: 0.81386\n",
      "fold2 epoch27 score: 0.84061\n",
      "fold2 epoch28 score: 0.81254\n",
      "fold2 epoch29 score: 0.84596\n",
      "fold2 epoch30 score: 0.85814\n",
      "fold2 epoch31 score: 0.83242\n",
      "fold2 epoch32 score: 0.80058\n",
      "fold2 epoch33 score: 0.81054\n",
      "fold2 epoch34 score: 0.76416\n",
      "fold2 epoch35 score: 0.79656\n",
      "fold2 epoch36 score: 0.78391\n",
      "fold2 epoch37 score: 0.81142\n",
      "fold2 epoch38 score: 0.82069\n",
      "fold2 epoch39 score: 0.78139\n",
      "epoch : 40/70    time : 119s/3581s\n",
      "TRAIN    loss : 0.08156    f1 : 0.92173\n",
      "Val    loss : 0.16082    f1 : 0.78139\n",
      "epoch : 40/70    time : 119s/3581s\n",
      "TRAIN    loss : 0.08156    f1 : 0.92173\n",
      "Val    loss : 0.16082    f1 : 0.78139\n",
      "fold3 epoch0 score: 0.30690\n",
      "fold3 epoch1 score: 0.55414\n",
      "fold3 epoch2 score: 0.51127\n",
      "fold3 epoch3 score: 0.62851\n",
      "fold3 epoch4 score: 0.67151\n",
      "fold3 epoch5 score: 0.69166\n",
      "fold3 epoch6 score: 0.79346\n",
      "fold3 epoch7 score: 0.68305\n",
      "fold3 epoch8 score: 0.70195\n",
      "fold3 epoch9 score: 0.71930\n",
      "fold3 epoch10 score: 0.79048\n",
      "fold3 epoch11 score: 0.79202\n",
      "fold3 epoch12 score: 0.82748\n",
      "fold3 epoch13 score: 0.84249\n",
      "fold3 epoch14 score: 0.77158\n",
      "fold3 epoch15 score: 0.84141\n",
      "fold3 epoch16 score: 0.84458\n",
      "fold3 epoch17 score: 0.77359\n",
      "fold3 epoch18 score: 0.76386\n",
      "fold3 epoch19 score: 0.73243\n",
      "fold3 epoch20 score: 0.84870\n",
      "fold3 epoch21 score: 0.84038\n",
      "fold3 epoch22 score: 0.86602\n",
      "fold3 epoch23 score: 0.76967\n",
      "fold3 epoch24 score: 0.72996\n",
      "fold3 epoch25 score: 0.81435\n",
      "fold3 epoch26 score: 0.81993\n",
      "fold3 epoch27 score: 0.79887\n",
      "fold3 epoch28 score: 0.82277\n",
      "fold3 epoch29 score: 0.82224\n",
      "fold3 epoch30 score: 0.85662\n",
      "fold3 epoch31 score: 0.89327\n",
      "fold3 epoch32 score: 0.77448\n",
      "fold3 epoch33 score: 0.81413\n",
      "fold3 epoch34 score: 0.79875\n",
      "fold3 epoch35 score: 0.83485\n",
      "fold3 epoch36 score: 0.79621\n",
      "fold3 epoch37 score: 0.85090\n",
      "fold3 epoch38 score: 0.79771\n",
      "fold3 epoch39 score: 0.82645\n",
      "fold3 epoch40 score: 0.82529\n",
      "fold3 epoch41 score: 0.87869\n",
      "fold3 epoch42 score: 0.84366\n",
      "fold3 epoch43 score: 0.80758\n",
      "fold3 epoch44 score: 0.83723\n",
      "fold3 epoch45 score: 0.85319\n",
      "fold3 epoch46 score: 0.80333\n",
      "fold3 epoch47 score: 0.88306\n",
      "fold3 epoch48 score: 0.87955\n",
      "fold3 epoch49 score: 0.82342\n",
      "fold3 epoch50 score: 0.83029\n",
      "fold3 epoch51 score: 0.80892\n",
      "epoch : 52/70    time : 102s/1831s\n",
      "TRAIN    loss : 0.03732    f1 : 0.96174\n",
      "Val    loss : 0.18058    f1 : 0.80892\n",
      "epoch : 52/70    time : 102s/1831s\n",
      "TRAIN    loss : 0.03732    f1 : 0.96174\n",
      "Val    loss : 0.18058    f1 : 0.80892\n",
      "fold4 epoch0 score: 0.37627\n",
      "fold4 epoch1 score: 0.55369\n",
      "fold4 epoch2 score: 0.56465\n",
      "fold4 epoch3 score: 0.73995\n",
      "fold4 epoch4 score: 0.61459\n",
      "fold4 epoch5 score: 0.61565\n",
      "fold4 epoch6 score: 0.74169\n",
      "fold4 epoch7 score: 0.68509\n",
      "fold4 epoch8 score: 0.71757\n",
      "fold4 epoch9 score: 0.72790\n",
      "fold4 epoch10 score: 0.72156\n",
      "fold4 epoch11 score: 0.67620\n",
      "fold4 epoch12 score: 0.77335\n",
      "fold4 epoch13 score: 0.73391\n",
      "fold4 epoch14 score: 0.74179\n",
      "fold4 epoch15 score: 0.80366\n",
      "fold4 epoch16 score: 0.82159\n",
      "fold4 epoch17 score: 0.80673\n",
      "fold4 epoch18 score: 0.72755\n",
      "fold4 epoch19 score: 0.69756\n",
      "fold4 epoch20 score: 0.81373\n",
      "fold4 epoch21 score: 0.79217\n",
      "fold4 epoch22 score: 0.68783\n",
      "fold4 epoch23 score: 0.77600\n",
      "fold4 epoch24 score: 0.75340\n",
      "fold4 epoch25 score: 0.78132\n",
      "fold4 epoch26 score: 0.74462\n",
      "fold4 epoch27 score: 0.76769\n",
      "fold4 epoch28 score: 0.78687\n",
      "fold4 epoch29 score: 0.81843\n",
      "fold4 epoch30 score: 0.81603\n",
      "fold4 epoch31 score: 0.78684\n",
      "fold4 epoch32 score: 0.76709\n",
      "fold4 epoch33 score: 0.74932\n",
      "fold4 epoch34 score: 0.80287\n",
      "fold4 epoch35 score: 0.80560\n",
      "fold4 epoch36 score: 0.75300\n",
      "epoch : 37/70    time : 102s/3367s\n",
      "TRAIN    loss : 0.05045    f1 : 0.96838\n",
      "Val    loss : 0.26557    f1 : 0.75300\n",
      "epoch : 37/70    time : 102s/3367s\n",
      "TRAIN    loss : 0.05045    f1 : 0.96838\n",
      "Val    loss : 0.26557    f1 : 0.75300\n",
      "fold5 epoch0 score: 0.36216\n",
      "fold5 epoch1 score: 0.43877\n",
      "fold5 epoch2 score: 0.54546\n",
      "fold5 epoch3 score: 0.58100\n",
      "fold5 epoch4 score: 0.57655\n",
      "fold5 epoch5 score: 0.64991\n",
      "fold5 epoch6 score: 0.58734\n",
      "fold5 epoch7 score: 0.59203\n",
      "fold5 epoch8 score: 0.60006\n",
      "fold5 epoch9 score: 0.62023\n",
      "fold5 epoch10 score: 0.60805\n",
      "fold5 epoch11 score: 0.70990\n",
      "fold5 epoch12 score: 0.68626\n",
      "fold5 epoch13 score: 0.64270\n",
      "fold5 epoch14 score: 0.73380\n",
      "fold5 epoch15 score: 0.74386\n",
      "fold5 epoch16 score: 0.73762\n",
      "fold5 epoch17 score: 0.70396\n",
      "fold5 epoch18 score: 0.65653\n",
      "fold5 epoch19 score: 0.73115\n",
      "fold5 epoch20 score: 0.60883\n",
      "fold5 epoch21 score: 0.64189\n",
      "fold5 epoch22 score: 0.67908\n",
      "fold5 epoch23 score: 0.70495\n",
      "fold5 epoch24 score: 0.61563\n",
      "fold5 epoch25 score: 0.59196\n",
      "fold5 epoch26 score: 0.70458\n",
      "fold5 epoch27 score: 0.71499\n",
      "fold5 epoch28 score: 0.66833\n",
      "fold5 epoch29 score: 0.72005\n",
      "fold5 epoch30 score: 0.75232\n",
      "fold5 epoch31 score: 0.73670\n",
      "fold5 epoch32 score: 0.67967\n",
      "fold5 epoch33 score: 0.62025\n",
      "fold5 epoch34 score: 0.61690\n",
      "fold5 epoch35 score: 0.65039\n",
      "fold5 epoch36 score: 0.67547\n",
      "fold5 epoch37 score: 0.72766\n",
      "fold5 epoch38 score: 0.70109\n",
      "fold5 epoch39 score: 0.65721\n",
      "fold5 epoch40 score: 0.64827\n",
      "fold5 epoch41 score: 0.61578\n",
      "fold5 epoch42 score: 0.69942\n",
      "fold5 epoch43 score: 0.56803\n",
      "fold5 epoch44 score: 0.66308\n",
      "fold5 epoch45 score: 0.69311\n",
      "fold5 epoch46 score: 0.76276\n",
      "fold5 epoch47 score: 0.69890\n",
      "fold5 epoch48 score: 0.70897\n",
      "fold5 epoch49 score: 0.68210\n",
      "fold5 epoch50 score: 0.78508\n",
      "fold5 epoch51 score: 0.67527\n",
      "fold5 epoch52 score: 0.67348\n",
      "fold5 epoch53 score: 0.76160\n",
      "fold5 epoch54 score: 0.67357\n",
      "fold5 epoch55 score: 0.72700\n",
      "fold5 epoch56 score: 0.69995\n",
      "fold5 epoch57 score: 0.65472\n",
      "fold5 epoch58 score: 0.65425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold5 epoch59 score: 0.76842\n",
      "fold5 epoch60 score: 0.70977\n",
      "fold5 epoch61 score: 0.70888\n",
      "fold5 epoch62 score: 0.72578\n",
      "fold5 epoch63 score: 0.70477\n",
      "fold5 epoch64 score: 0.73618\n",
      "fold5 epoch65 score: 0.68514\n",
      "fold5 epoch66 score: 0.74452\n",
      "fold5 epoch67 score: 0.71254\n",
      "fold5 epoch68 score: 0.72646\n",
      "fold5 epoch69 score: 0.67078\n",
      "epoch : 70/70    time : 135s/0s\n",
      "TRAIN    loss : 0.02993    f1 : 0.96264\n",
      "Val    loss : 0.20221    f1 : 0.67078\n",
      "fold6 epoch0 score: 0.35989\n",
      "fold6 epoch1 score: 0.39025\n",
      "fold6 epoch2 score: 0.54426\n",
      "fold6 epoch3 score: 0.53521\n",
      "fold6 epoch4 score: 0.57917\n",
      "fold6 epoch5 score: 0.62272\n",
      "fold6 epoch6 score: 0.68217\n",
      "fold6 epoch7 score: 0.67902\n",
      "fold6 epoch8 score: 0.65093\n",
      "fold6 epoch9 score: 0.71573\n",
      "fold6 epoch10 score: 0.62367\n",
      "fold6 epoch11 score: 0.63344\n",
      "fold6 epoch12 score: 0.59173\n",
      "fold6 epoch13 score: 0.70989\n",
      "fold6 epoch14 score: 0.74745\n",
      "fold6 epoch15 score: 0.68351\n",
      "fold6 epoch16 score: 0.70901\n",
      "fold6 epoch17 score: 0.69654\n",
      "fold6 epoch18 score: 0.63439\n",
      "fold6 epoch19 score: 0.66967\n",
      "fold6 epoch20 score: 0.67288\n",
      "fold6 epoch21 score: 0.77093\n",
      "fold6 epoch22 score: 0.70819\n",
      "fold6 epoch23 score: 0.70613\n",
      "fold6 epoch24 score: 0.70794\n",
      "fold6 epoch25 score: 0.70733\n",
      "fold6 epoch26 score: 0.77366\n",
      "fold6 epoch27 score: 0.69365\n",
      "fold6 epoch28 score: 0.71294\n",
      "fold6 epoch29 score: 0.67725\n",
      "fold6 epoch30 score: 0.74144\n",
      "fold6 epoch31 score: 0.74428\n",
      "fold6 epoch32 score: 0.76241\n",
      "fold6 epoch33 score: 0.74088\n",
      "fold6 epoch34 score: 0.75513\n",
      "fold6 epoch35 score: 0.68802\n",
      "fold6 epoch36 score: 0.68987\n",
      "fold6 epoch37 score: 0.69335\n",
      "fold6 epoch38 score: 0.59925\n",
      "fold6 epoch39 score: 0.62025\n",
      "fold6 epoch40 score: 0.74513\n",
      "fold6 epoch41 score: 0.72333\n",
      "fold6 epoch42 score: 0.73359\n",
      "fold6 epoch43 score: 0.70451\n",
      "fold6 epoch44 score: 0.69152\n",
      "fold6 epoch45 score: 0.69360\n",
      "fold6 epoch46 score: 0.68384\n",
      "epoch : 47/70    time : 133s/3051s\n",
      "TRAIN    loss : 0.04238    f1 : 0.95527\n",
      "Val    loss : 0.29654    f1 : 0.68384\n",
      "epoch : 47/70    time : 133s/3051s\n",
      "TRAIN    loss : 0.04238    f1 : 0.95527\n",
      "Val    loss : 0.29654    f1 : 0.68384\n",
      "fold7 epoch0 score: 0.35823\n",
      "fold7 epoch1 score: 0.44274\n",
      "fold7 epoch2 score: 0.44485\n",
      "fold7 epoch3 score: 0.56978\n",
      "fold7 epoch4 score: 0.66944\n",
      "fold7 epoch5 score: 0.61821\n",
      "fold7 epoch6 score: 0.68071\n",
      "fold7 epoch7 score: 0.67376\n",
      "fold7 epoch8 score: 0.66692\n",
      "fold7 epoch9 score: 0.68372\n",
      "fold7 epoch10 score: 0.75043\n",
      "fold7 epoch11 score: 0.71683\n",
      "fold7 epoch12 score: 0.71972\n",
      "fold7 epoch13 score: 0.75644\n",
      "fold7 epoch14 score: 0.73615\n",
      "fold7 epoch15 score: 0.75105\n",
      "fold7 epoch16 score: 0.78376\n",
      "fold7 epoch17 score: 0.67498\n",
      "fold7 epoch18 score: 0.80026\n",
      "fold7 epoch19 score: 0.71811\n",
      "fold7 epoch20 score: 0.75928\n",
      "fold7 epoch21 score: 0.81503\n",
      "fold7 epoch22 score: 0.67680\n",
      "fold7 epoch23 score: 0.78925\n",
      "fold7 epoch24 score: 0.78881\n",
      "fold7 epoch25 score: 0.77062\n",
      "fold7 epoch26 score: 0.78486\n",
      "fold7 epoch27 score: 0.76943\n",
      "fold7 epoch28 score: 0.73063\n",
      "fold7 epoch29 score: 0.79543\n",
      "fold7 epoch30 score: 0.73158\n",
      "fold7 epoch31 score: 0.66900\n",
      "fold7 epoch32 score: 0.69033\n",
      "fold7 epoch33 score: 0.76135\n",
      "fold7 epoch34 score: 0.68244\n",
      "fold7 epoch35 score: 0.71051\n",
      "fold7 epoch36 score: 0.61268\n",
      "fold7 epoch37 score: 0.65800\n",
      "fold7 epoch38 score: 0.73014\n",
      "fold7 epoch39 score: 0.71021\n",
      "fold7 epoch40 score: 0.71625\n",
      "fold7 epoch41 score: 0.79039\n",
      "epoch : 42/70    time : 132s/3708s\n",
      "TRAIN    loss : 0.03590    f1 : 0.96039\n",
      "Val    loss : 0.19899    f1 : 0.79039\n",
      "epoch : 42/70    time : 132s/3708s\n",
      "TRAIN    loss : 0.03590    f1 : 0.96039\n",
      "Val    loss : 0.19899    f1 : 0.79039\n",
      "fold8 epoch0 score: 0.35110\n",
      "fold8 epoch1 score: 0.51551\n",
      "fold8 epoch2 score: 0.52314\n",
      "fold8 epoch3 score: 0.51831\n",
      "fold8 epoch4 score: 0.60464\n",
      "fold8 epoch5 score: 0.63402\n",
      "fold8 epoch6 score: 0.67107\n",
      "fold8 epoch7 score: 0.63865\n",
      "fold8 epoch8 score: 0.68194\n",
      "fold8 epoch9 score: 0.70713\n",
      "fold8 epoch10 score: 0.73390\n",
      "fold8 epoch11 score: 0.71998\n",
      "fold8 epoch12 score: 0.72767\n",
      "fold8 epoch13 score: 0.69867\n",
      "fold8 epoch14 score: 0.76915\n",
      "fold8 epoch15 score: 0.73222\n",
      "fold8 epoch16 score: 0.72948\n",
      "fold8 epoch17 score: 0.78476\n",
      "fold8 epoch18 score: 0.77328\n",
      "fold8 epoch19 score: 0.76741\n",
      "fold8 epoch20 score: 0.67147\n",
      "fold8 epoch21 score: 0.76074\n",
      "fold8 epoch22 score: 0.74335\n",
      "fold8 epoch23 score: 0.72564\n",
      "fold8 epoch24 score: 0.72483\n",
      "fold8 epoch25 score: 0.81711\n",
      "fold8 epoch26 score: 0.77130\n",
      "fold8 epoch27 score: 0.70127\n",
      "fold8 epoch28 score: 0.76652\n",
      "fold8 epoch29 score: 0.72410\n",
      "fold8 epoch30 score: 0.75341\n",
      "fold8 epoch31 score: 0.68794\n",
      "fold8 epoch32 score: 0.77088\n",
      "fold8 epoch33 score: 0.75877\n",
      "fold8 epoch34 score: 0.75259\n",
      "fold8 epoch35 score: 0.71675\n",
      "fold8 epoch36 score: 0.78751\n",
      "fold8 epoch37 score: 0.76356\n",
      "fold8 epoch38 score: 0.76151\n",
      "fold8 epoch39 score: 0.75138\n",
      "fold8 epoch40 score: 0.70551\n",
      "fold8 epoch41 score: 0.74525\n",
      "fold8 epoch42 score: 0.81370\n",
      "fold8 epoch43 score: 0.74565\n",
      "fold8 epoch44 score: 0.72149\n",
      "fold8 epoch45 score: 0.79819\n",
      "epoch : 46/70    time : 133s/3189s\n",
      "TRAIN    loss : 0.03303    f1 : 0.96656\n",
      "Val    loss : 0.17077    f1 : 0.79819\n",
      "epoch : 46/70    time : 133s/3189s\n",
      "TRAIN    loss : 0.03303    f1 : 0.96656\n",
      "Val    loss : 0.17077    f1 : 0.79819\n",
      "fold9 epoch0 score: 0.32816\n",
      "fold9 epoch1 score: 0.42683\n",
      "fold9 epoch2 score: 0.47973\n",
      "fold9 epoch3 score: 0.50721\n",
      "fold9 epoch4 score: 0.66765\n",
      "fold9 epoch5 score: 0.69614\n",
      "fold9 epoch6 score: 0.61870\n",
      "fold9 epoch7 score: 0.59264\n",
      "fold9 epoch8 score: 0.63485\n",
      "fold9 epoch9 score: 0.63511\n",
      "fold9 epoch10 score: 0.64753\n",
      "fold9 epoch11 score: 0.65447\n",
      "fold9 epoch12 score: 0.69465\n",
      "fold9 epoch13 score: 0.67353\n",
      "fold9 epoch14 score: 0.75655\n",
      "fold9 epoch15 score: 0.70359\n",
      "fold9 epoch16 score: 0.70732\n",
      "fold9 epoch17 score: 0.66438\n",
      "fold9 epoch18 score: 0.74284\n",
      "fold9 epoch19 score: 0.69890\n",
      "fold9 epoch20 score: 0.68041\n",
      "fold9 epoch21 score: 0.73111\n",
      "fold9 epoch22 score: 0.79035\n",
      "fold9 epoch23 score: 0.75928\n",
      "fold9 epoch24 score: 0.70932\n",
      "fold9 epoch25 score: 0.71842\n",
      "fold9 epoch26 score: 0.66250\n",
      "fold9 epoch27 score: 0.72738\n",
      "fold9 epoch28 score: 0.69748\n",
      "fold9 epoch29 score: 0.72684\n",
      "fold9 epoch30 score: 0.71882\n",
      "fold9 epoch31 score: 0.66222\n",
      "fold9 epoch32 score: 0.69748\n",
      "fold9 epoch33 score: 0.66214\n",
      "fold9 epoch34 score: 0.74396\n",
      "fold9 epoch35 score: 0.76053\n",
      "fold9 epoch36 score: 0.71824\n",
      "fold9 epoch37 score: 0.69172\n",
      "fold9 epoch38 score: 0.79015\n",
      "fold9 epoch39 score: 0.73062\n",
      "fold9 epoch40 score: 0.72603\n",
      "fold9 epoch41 score: 0.66114\n",
      "fold9 epoch42 score: 0.68840\n",
      "epoch : 43/70    time : 132s/3551s\n",
      "TRAIN    loss : 0.05025    f1 : 0.95832\n",
      "Val    loss : 0.25655    f1 : 0.68840\n",
      "epoch : 43/70    time : 132s/3551s\n",
      "TRAIN    loss : 0.05025    f1 : 0.95832\n",
      "Val    loss : 0.25655    f1 : 0.68840\n",
      "fold10 epoch0 score: 0.27339\n",
      "fold10 epoch1 score: 0.49318\n",
      "fold10 epoch2 score: 0.53532\n",
      "fold10 epoch3 score: 0.47048\n",
      "fold10 epoch4 score: 0.63087\n",
      "fold10 epoch5 score: 0.64557\n",
      "fold10 epoch6 score: 0.71961\n",
      "fold10 epoch7 score: 0.72027\n",
      "fold10 epoch8 score: 0.72864\n",
      "fold10 epoch9 score: 0.73010\n",
      "fold10 epoch10 score: 0.65285\n",
      "fold10 epoch11 score: 0.72560\n",
      "fold10 epoch12 score: 0.80435\n",
      "fold10 epoch13 score: 0.76054\n",
      "fold10 epoch14 score: 0.76535\n",
      "fold10 epoch15 score: 0.81143\n",
      "fold10 epoch16 score: 0.69227\n",
      "fold10 epoch17 score: 0.72193\n",
      "fold10 epoch18 score: 0.81314\n",
      "fold10 epoch19 score: 0.79130\n",
      "fold10 epoch20 score: 0.77582\n",
      "fold10 epoch21 score: 0.80833\n",
      "fold10 epoch22 score: 0.79772\n",
      "fold10 epoch23 score: 0.77502\n",
      "fold10 epoch24 score: 0.74451\n",
      "fold10 epoch25 score: 0.72758\n",
      "fold10 epoch26 score: 0.73379\n",
      "fold10 epoch27 score: 0.76108\n",
      "fold10 epoch28 score: 0.64505\n",
      "fold10 epoch29 score: 0.72247\n",
      "fold10 epoch30 score: 0.78486\n",
      "fold10 epoch31 score: 0.75963\n",
      "fold10 epoch32 score: 0.74768\n",
      "fold10 epoch33 score: 0.73380\n",
      "fold10 epoch34 score: 0.75414\n",
      "fold10 epoch35 score: 0.75854\n",
      "fold10 epoch36 score: 0.71448\n",
      "fold10 epoch37 score: 0.84395\n",
      "fold10 epoch38 score: 0.77247\n",
      "fold10 epoch39 score: 0.75108\n",
      "fold10 epoch40 score: 0.75353\n",
      "fold10 epoch41 score: 0.87408\n",
      "fold10 epoch42 score: 0.84269\n",
      "fold10 epoch43 score: 0.81608\n",
      "fold10 epoch44 score: 0.89789\n",
      "fold10 epoch45 score: 0.76180\n",
      "fold10 epoch46 score: 0.81153\n",
      "fold10 epoch47 score: 0.74682\n",
      "fold10 epoch48 score: 0.77426\n",
      "fold10 epoch49 score: 0.71661\n",
      "fold10 epoch50 score: 0.78570\n",
      "fold10 epoch51 score: 0.75417\n",
      "fold10 epoch52 score: 0.77444\n",
      "fold10 epoch53 score: 0.74572\n",
      "fold10 epoch54 score: 0.80847\n",
      "fold10 epoch55 score: 0.78420\n",
      "fold10 epoch56 score: 0.82378\n",
      "fold10 epoch57 score: 0.82795\n",
      "fold10 epoch58 score: 0.72970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold10 epoch59 score: 0.80558\n",
      "fold10 epoch60 score: 0.81466\n",
      "fold10 epoch61 score: 0.79698\n",
      "fold10 epoch62 score: 0.75340\n",
      "fold10 epoch63 score: 0.75548\n",
      "fold10 epoch64 score: 0.73454\n",
      "epoch : 65/70    time : 134s/669s\n",
      "TRAIN    loss : 0.03739    f1 : 0.96733\n",
      "Val    loss : 0.20810    f1 : 0.73454\n",
      "epoch : 65/70    time : 134s/669s\n",
      "TRAIN    loss : 0.03739    f1 : 0.96733\n",
      "Val    loss : 0.20810    f1 : 0.73454\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "cv = StratifiedKFold(n_splits = 10, random_state = 2022, shuffle=True)\n",
    "batch_size = 32\n",
    "epochs = 70\n",
    "pred_ensemble = []\n",
    "\n",
    "\n",
    "for idx, (train_idx, val_idx) in enumerate(cv.split(train_imgs, np.array(train_labels))):\n",
    "#     if ((idx+1)<7):\n",
    "#         continue\n",
    "#     print(\"----------fold_{} start!----------\".format(idx))\n",
    "    t_imgs, val_imgs = train_imgs[train_idx],  train_imgs[val_idx]\n",
    "    t_labels, val_labels = np.array(train_labels)[train_idx], np.array(train_labels)[val_idx]\n",
    "\n",
    "    # Train\n",
    "    train_dataset = Custom_dataset(np.array(t_imgs), np.array(t_labels), mode='train')\n",
    "    train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "    # Val\n",
    "    val_dataset = Custom_dataset(np.array(val_imgs), np.array(val_labels), mode='test')\n",
    "    val_loader = DataLoader(val_dataset, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    best=0\n",
    "\n",
    "    model = Network().to(device)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay = 2e-2)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    scaler = torch.cuda.amp.GradScaler()  \n",
    "\n",
    "    best_f1 = 0\n",
    "    early_stopping = 0\n",
    "    for epoch in range(epochs):\n",
    "        start=time.time()\n",
    "        train_loss = 0\n",
    "        train_pred=[]\n",
    "        train_y=[]\n",
    "        model.train()\n",
    "        for batch in (train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            x = torch.tensor(batch[0], dtype=torch.float32, device=device)\n",
    "            y = torch.tensor(batch[1], dtype=torch.long, device=device)\n",
    "            with torch.cuda.amp.autocast():\n",
    "                pred = model(x)\n",
    "            loss = criterion(pred, y)\n",
    "\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            train_loss += loss.item()/len(train_loader)\n",
    "            train_pred += pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "            train_y += y.detach().cpu().numpy().tolist()\n",
    "        train_f1 = score_function(train_y, train_pred)\n",
    "        state_dict= model.state_dict()\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss = 0 \n",
    "            val_pred = []\n",
    "            val_y = []\n",
    "\n",
    "\n",
    "            for batch in (val_loader):\n",
    "                x_val = torch.tensor(batch[0], dtype = torch.float32, device = device)\n",
    "                y_val = torch.tensor(batch[1], dtype=torch.long, device=device)\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    pred_val = model(x_val)\n",
    "                loss_val = criterion(pred_val, y_val)\n",
    "\n",
    "                val_loss += loss_val.item()/len(val_loader)\n",
    "                val_pred += pred_val.argmax(1).detach().cpu().numpy().tolist()\n",
    "                val_y += y_val.detach().cpu().numpy().tolist()\n",
    "            val_f1 = score_function(val_y, val_pred)\n",
    "            print(f'fold{idx+1} epoch{epoch} score: {val_f1:.5f}')\n",
    "\n",
    "            if val_f1 > best_f1:\n",
    "                best_epoch = epoch\n",
    "                best_loss = val_loss\n",
    "                best_f1 = val_f1\n",
    "                early_stopping = 0\n",
    "\n",
    "                torch.save({'epoch':epoch,\n",
    "                            'state_dict':state_dict,\n",
    "                            'optimizer': optimizer.state_dict(),\n",
    "                            'scaler': scaler.state_dict(),\n",
    "                     }, f'../model/{name}_best_model_{idx+1}.pth')\n",
    "#                 print('-----------------SAVE:{} epoch----------------'.format(best_epoch+1))\n",
    "            else:\n",
    "                early_stopping += 1\n",
    "\n",
    "                # Early Stopping\n",
    "        if early_stopping == 20:\n",
    "            TIME = time.time() - start\n",
    "            print(f'epoch : {epoch+1}/{epochs}    time : {TIME:.0f}s/{TIME*(epochs-epoch-1):.0f}s')\n",
    "            print(f'TRAIN    loss : {train_loss:.5f}    f1 : {train_f1:.5f}')\n",
    "            print(f'Val    loss : {val_loss:.5f}    f1 : {val_f1:.5f}')\n",
    "            break\n",
    "\n",
    "    TIME = time.time() - start\n",
    "    print(f'epoch : {epoch+1}/{epochs}    time : {TIME:.0f}s/{TIME*(epochs-epoch-1):.0f}s')\n",
    "    print(f'TRAIN    loss : {train_loss:.5f}    f1 : {train_f1:.5f}')\n",
    "    print(f'Val    loss : {val_loss:.5f}    f1 : {val_f1:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "analyzed-diversity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------fold_1 predict start!----------\n",
      "----------fold_2 predict start!----------\n",
      "----------fold_3 predict start!----------\n",
      "----------fold_4 predict start!----------\n",
      "----------fold_5 predict start!----------\n",
      "----------fold_6 predict start!----------\n",
      "----------fold_7 predict start!----------\n",
      "----------fold_8 predict start!----------\n",
      "----------fold_9 predict start!----------\n",
      "----------fold_10 predict start!----------\n"
     ]
    }
   ],
   "source": [
    "pred_train = np.zeros((len(train_imgs), 88))\n",
    "pred_test = np.zeros((len(test_imgs), 88))\n",
    "\n",
    "test_dataset = Custom_dataset(np.array(test_imgs), np.array([\"tmp\"]*len(test_imgs)), mode='test')\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "for idx, (train_idx, val_idx) in enumerate(cv.split(train_imgs, np.array(train_labels))):\n",
    "    print(\"----------fold_{} predict start!----------\".format(idx+1))\n",
    "    \n",
    "    t_imgs, val_imgs = train_imgs[train_idx],  train_imgs[val_idx]\n",
    "    t_labels, val_labels = np.array(train_labels)[train_idx], np.array(train_labels)[val_idx]\n",
    "\n",
    "    # Val\n",
    "    val_dataset = Custom_dataset(np.array(val_imgs), np.array(val_labels), mode='test')\n",
    "    val_loader = DataLoader(val_dataset, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    model_test = Network(mode = 'test').to(device)\n",
    "    model_test.load_state_dict(torch.load((f'../model/{name}_best_model_{idx+1}.pth'))['state_dict'])\n",
    "    model_test.eval()\n",
    "    \n",
    "    pred_train_list = []\n",
    "    with torch.no_grad():\n",
    "        for batch in (val_loader):\n",
    "            x = torch.tensor(batch[0], dtype = torch.float32, device = device)\n",
    "            with torch.cuda.amp.autocast():\n",
    "                pred_train_local = model_test(x)\n",
    "                pred_train_list.extend(pred_train_local.detach().cpu().numpy())\n",
    "                \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    model_test = Network(mode = 'test').to(device)\n",
    "    model_test.load_state_dict(torch.load((f'../model/{name}_best_model_{idx+1}.pth'))['state_dict'])\n",
    "    model_test.eval()\n",
    "            \n",
    "    pred_test_list = []\n",
    "    with torch.no_grad():\n",
    "        for batch in (test_loader):\n",
    "            x = torch.tensor(batch[0], dtype = torch.float32, device = device)\n",
    "            with torch.cuda.amp.autocast():\n",
    "                pred_test_local = model_test(x)\n",
    "                pred_test_list.extend(pred_test_local.detach().cpu().numpy())\n",
    "                \n",
    "    pred_train[val_idx, :] = pred_train_list\n",
    "    pred_test += np.array(pred_test_list) / 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "listed-antique",
   "metadata": {},
   "source": [
    "## 학습 결과 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "stuck-butterfly",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train_dict[f'{name}_seed{str(2022)}'] = pred_train\n",
    "pred_test_dict[f'{name}_seed{str(2022)}'] = pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "electrical-mexico",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_dict(model, pred_dict, pred_test_dict):\n",
    "    pred_dict_local = {}\n",
    "    for key, value in pred_dict.items():\n",
    "        if model in key:\n",
    "            pred_dict_local[key]=value\n",
    "\n",
    "    pred_test_dict_local = {}\n",
    "    for key, value in pred_test_dict.items():\n",
    "        if model in key:\n",
    "            pred_test_dict_local[key]=value\n",
    "\n",
    "    pred_dict_new_local = dict(sorted(\n",
    "        pred_dict_local.items(), \n",
    "        key=lambda x:score_function((train_labels), np.argmax(list(x[1]), axis=1)), reverse=False)[:5])\n",
    "    pred_test_dict_new_local = {}\n",
    "    for key, value in pred_dict_new_local.items():\n",
    "        pred_test_dict_new_local[key]=pred_test_dict_local[key]\n",
    "        \n",
    "    return pred_dict_new_local, pred_test_dict_new_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fiscal-chess",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dict(model, pred_dict, pred_test_dict):\n",
    "    with open('../pickle/pred_train_dict_'+model+'.pickle', 'wb') as fw:\n",
    "        pickle.dump(pred_dict, fw)\n",
    "    with open('../pickle/pred_test_dict_'+model+'.pickle', 'wb') as fw:\n",
    "        pickle.dump(pred_test_dict, fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "legal-college",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train_dict_global, pred_test_dict_global = sort_dict(name, pred_train_dict, pred_test_dict)\n",
    "save_dict(name, pred_train_dict_global, pred_test_dict_global)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "[BASELINE]_EfficientNet_b3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
