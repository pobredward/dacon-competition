{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JjP3so34EqC_",
    "outputId": "f179d412-e202-482b-c882-d84faabe1387"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /content/drive/MyDrive/crop-disease/train.zip\n",
      "replace train/10027/10027.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n",
      "mkdir: cannot create directory ‘model’: File exists\n"
     ]
    }
   ],
   "source": [
    "!unzip /content/drive/MyDrive/crop-disease/train.zip # 자신의 train.zip \n",
    "!mkdir model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f6dPi7hc_QRH",
    "outputId": "47361f3c-8cd8-4dd8-ff36-8c53aaba5617"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: timm in /usr/local/lib/python3.7/dist-packages (0.4.12)\n",
      "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.10.0+cu111)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.11.1+cu111)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (3.10.0.2)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.19.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install timm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vfd2Rsxkqi5j"
   },
   "source": [
    "# 라이브러리 로드 및 필요 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "4UE1tEdf-tKW"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import timm\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "# score 계산\n",
    "def accuracy_function(real, pred):                   # https://dacon.io/competitions/official/235870/codeshare/4146\n",
    "    score = f1_score(real, pred, average='macro')\n",
    "    return score\n",
    "\n",
    "# torch model 저장\n",
    "def model_save(model, score,  path):\n",
    "    os.makedirs('model', exist_ok=True)\n",
    "    torch.save({\n",
    "        'model': model.state_dict(),\n",
    "        'score': score\n",
    "    }, path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sZiEU5Iao7N0"
   },
   "source": [
    "# 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_png = sorted(glob('../data/train/*.png'))\n",
    "test_png = sorted(glob('../data/test/*.png'))\n",
    "\n",
    "train_y = pd.read_csv(\"../data/train_df.csv\")\n",
    "\n",
    "train_labels = train_y[\"label\"]\n",
    "\n",
    "label_unique = sorted(np.unique(train_labels))\n",
    "label_unique = {key:value for key,value in zip(label_unique, range(len(label_unique)))}\n",
    "\n",
    "train_labels = [label_unique[k] for k in train_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_load(path):\n",
    "    img = cv2.imread(path)[:,:,::-1]\n",
    "    img = cv2.resize(img, (256, 256))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 4277/4277 [01:30<00:00, 47.49it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 2154/2154 [00:43<00:00, 49.00it/s]\n"
     ]
    }
   ],
   "source": [
    "train_imgs = [img_load(m) for m in tqdm(train_png)]\n",
    "test_imgs = [img_load(n) for n in tqdm(test_png)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "828m0RgV-8f3",
    "outputId": "5e40f2a0-4654-4505-e99c-5dd77890f491"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5767/5767 [00:38<00:00, 151.46it/s]\n"
     ]
    }
   ],
   "source": [
    "# # 주어진 훈련 데이터 경로\n",
    "# train_csv = sorted(glob('train/*/*.csv'))\n",
    "# train_jpg = sorted(glob('train/*/*.jpg'))\n",
    "# train_json = sorted(glob('train/*/*.json'))\n",
    "\n",
    "\n",
    "# crops = []\n",
    "# diseases = []\n",
    "# risks = []\n",
    "# labels = []\n",
    "\n",
    "# # 훈련데이터 로드\n",
    "# for i in range(len(train_json)):\n",
    "#     with open(train_json[i], 'r') as f:\n",
    "#         sample = json.load(f)\n",
    "#         crop = sample['annotations']['crop']\n",
    "#         disease = sample['annotations']['disease']\n",
    "#         risk = sample['annotations']['risk']\n",
    "#         label=f\"{crop}_{disease}_{risk}\"\n",
    "    \n",
    "#         crops.append(crop)\n",
    "#         diseases.append(disease)\n",
    "#         risks.append(risk)\n",
    "#         labels.append(label)\n",
    "\n",
    "# label_unique = sorted(np.unique(labels))\n",
    "# label_unique = {key:value for key,value in zip(label_unique, range(len(label_unique)))}\n",
    "\n",
    "# labels = [label_unique[k] for k in labels]\n",
    "\n",
    "\n",
    "# # 이미지 로드 함수 / 로드 후 (512, 384)로 사이즈 변환 ==> (원본 사이즈에서 width 384인 샘플이 많아서 (512, 384) 사이즈로 변환)\n",
    "# def img_load(path):\n",
    "#     img = cv2.imread(path)[:,:,::-1]\n",
    "#     img = cv2.resize(img, (384, 512))\n",
    "#     return img\n",
    "\n",
    "# # 이미지 로드\n",
    "# imgs = [img_load(k) for k in tqdm(train_jpg)]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J556wfcbo9ib"
   },
   "source": [
    "# 데이터로더와 모델 정의\n",
    "- 모델에 입력되는 이미지에 다양성을 추가하기 위해 vertical, horizontal flip을 랜덤하게 적용. ( 훈련데이터만 )\n",
    "- Efficientent-b0 (pretrained) 모델 사용.\n",
    "- 실제로는 crop_disease_risk가 다양한 조합으로 나올 수 있으나 훈련데이터에 존재하는 label들의 고유값은 총 25개였기 때문에 출력값을 25로 설정. (test dataset에 존재하는 label은 train dataset에도 존재 https://dacon.io/competitions/official/235870/talkboard/405713?page=1&dtype=recent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "hdI5YM9coxL4"
   },
   "outputs": [],
   "source": [
    "class Custom_dataset(Dataset):\n",
    "    def __init__(self, img_paths, labels, mode='train'):\n",
    "        self.img_paths = img_paths\n",
    "        self.labels = labels\n",
    "        self.mode = mode\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.img_paths[idx]\n",
    "        if self.mode=='train':\n",
    "            augmentation = random.randint(0,2)\n",
    "            if augmentation==1:\n",
    "                img = img[::-1].copy()\n",
    "            elif augmentation==2:\n",
    "                img = img[:,::-1].copy()\n",
    "        img = transforms.ToTensor()(img)\n",
    "        if self.mode=='test':\n",
    "            return img\n",
    "        \n",
    "        label = self.labels[idx]\n",
    "        return img,label\n",
    "    \n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.model = timm.create_model('efficientnet_b0', pretrained=True, num_classes=25)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6K2rkTudo_5I"
   },
   "source": [
    "# 데이터 분리 및 로더 정의\n",
    "- 검증 데이터는 간단히 KFold (k=5) 방식을 사용.\n",
    "- 배치 사이즈는 16을 사용. colab(일반버전) 에서 batch size 32일 때 메모리 오류가 납니다.\n",
    "- 에폭은 30으로 설정."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-19T03:01:31.480044Z",
     "start_time": "2022-01-19T03:01:31.397227Z"
    },
    "id": "UwgCA0mU_LMs"
   },
   "outputs": [],
   "source": [
    "# KFold\n",
    "folds = []\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "for train_idx, valid_idx in kf.split(train_imgs):\n",
    "    folds.append((train_idx, valid_idx))\n",
    "fold=0\n",
    "train_idx, valid_idx = folds[fold]\n",
    "\n",
    "batch_size = 16\n",
    "epochs = 30\n",
    "\n",
    "\n",
    "# Train\n",
    "train_dataset = Custom_dataset(np.array(train_imgs)[train_idx], np.array(train_labels)[train_idx], mode='train')\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size, pin_memory=True, num_workers=8)\n",
    "\n",
    "# Validation \n",
    "valid_dataset = Custom_dataset(np.array(train_imgs)[valid_idx], np.array(train_labels)[valid_idx], mode='valid')\n",
    "valid_loader = DataLoader(valid_dataset, shuffle=False, batch_size=batch_size, pin_memory=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OzD1viK6pE5S"
   },
   "source": [
    "# 훈련\n",
    "- optimizer는 Adam을 사용.\n",
    "- Mixed Precision Training을 사용하기위헤 AMP를 사용.\n",
    "- validation score 를 모니터하면서 점수가 개선될 때 마다 모델을 저장.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running\n"
     ]
    }
   ],
   "source": [
    "model = Network().to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scaler = torch.cuda.amp.GradScaler() \n",
    "\n",
    "print(\"Running\")\n",
    "\n",
    "best=0\n",
    "for epoch in range(epochs):\n",
    "    start=time.time()\n",
    "    train_loss = 0\n",
    "    train_pred=[]\n",
    "    train_y=[]\n",
    "    model.train()\n",
    "    for batch in (train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        print(\"Running\")\n",
    "        x = torch.tensor(batch[0], dtype=torch.float32, device=device)\n",
    "        y = torch.tensor(batch[1], dtype=torch.long, device=device)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            pred = model(x)\n",
    "        loss = criterion(pred, y)\n",
    "\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        train_loss += loss.item()/len(train_loader)\n",
    "        train_pred += pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "        train_y += y.detach().cpu().numpy().tolist()\n",
    "        \n",
    "    \n",
    "    train_f1 = accuracy_function(train_y, train_pred)\n",
    "    \n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "    valid_pred=[]\n",
    "    valid_y=[]\n",
    "    with torch.no_grad():\n",
    "        for batch in (valid_loader):\n",
    "            x = torch.tensor(batch[0], dtype=torch.float32, device=device)\n",
    "            y = torch.tensor(batch[1], dtype=torch.long, device=device)\n",
    "            with torch.cuda.amp.autocast():\n",
    "                pred = model(x)\n",
    "            loss = criterion(pred, y)\n",
    "            valid_loss += loss.item()/len(valid_loader)\n",
    "            valid_pred += pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "            valid_y += y.detach().cpu().numpy().tolist()\n",
    "        valid_f1 = accuracy_function(valid_y, valid_pred)\n",
    "    if valid_f1>=best:\n",
    "        best=valid_f1\n",
    "        model_save(model, valid_f1, f'model/eff-b0.pth')\n",
    "    TIME = time.time() - start\n",
    "    print(f'epoch : {epoch+1}/{epochs}    time : {TIME:.0f}s/{TIME*(epochs-epoch-1):.0f}s')\n",
    "    print(f'TRAIN    loss : {train_loss:.5f}    f1 : {train_f1:.5f}')\n",
    "    print(f'VALID    loss : {valid_loss:.5f}    f1 : {valid_f1:.5f}    best : {best:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B-04AwZTGCYn",
    "outputId": "02ea7f64-7c36-4d7e-8b16-414ad5118db7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/30    time : 110s/3178s\n",
      "TRAIN    loss : 0.60060    f1 : 0.61207\n",
      "VALID    loss : 0.35065    f1 : 0.67450    best : 0.67450\n",
      "epoch : 2/30    time : 108s/3034s\n",
      "TRAIN    loss : 0.23640    f1 : 0.81202\n",
      "VALID    loss : 0.23117    f1 : 0.79577    best : 0.79577\n",
      "epoch : 3/30    time : 108s/2922s\n",
      "TRAIN    loss : 0.18012    f1 : 0.86794\n",
      "VALID    loss : 0.26513    f1 : 0.82589    best : 0.82589\n",
      "epoch : 4/30    time : 108s/2811s\n",
      "TRAIN    loss : 0.17742    f1 : 0.86356\n",
      "VALID    loss : 0.21942    f1 : 0.85821    best : 0.85821\n",
      "epoch : 5/30    time : 108s/2703s\n",
      "TRAIN    loss : 0.14122    f1 : 0.89331\n",
      "VALID    loss : 0.23205    f1 : 0.87375    best : 0.87375\n",
      "epoch : 6/30    time : 108s/2591s\n",
      "TRAIN    loss : 0.11268    f1 : 0.92715\n",
      "VALID    loss : 0.19384    f1 : 0.85435    best : 0.87375\n",
      "epoch : 7/30    time : 108s/2479s\n",
      "TRAIN    loss : 0.07634    f1 : 0.93744\n",
      "VALID    loss : 0.16295    f1 : 0.88713    best : 0.88713\n",
      "epoch : 8/30    time : 108s/2367s\n",
      "TRAIN    loss : 0.08807    f1 : 0.94531\n",
      "VALID    loss : 0.22397    f1 : 0.86927    best : 0.88713\n",
      "epoch : 9/30    time : 108s/2259s\n",
      "TRAIN    loss : 0.13083    f1 : 0.92853\n",
      "VALID    loss : 0.24639    f1 : 0.86928    best : 0.88713\n",
      "epoch : 10/30    time : 107s/2150s\n",
      "TRAIN    loss : 0.08493    f1 : 0.94342\n",
      "VALID    loss : 0.21936    f1 : 0.83223    best : 0.88713\n",
      "epoch : 11/30    time : 107s/2042s\n",
      "TRAIN    loss : 0.07391    f1 : 0.94359\n",
      "VALID    loss : 0.18249    f1 : 0.87658    best : 0.88713\n",
      "epoch : 12/30    time : 107s/1928s\n",
      "TRAIN    loss : 0.05788    f1 : 0.96463\n",
      "VALID    loss : 0.23330    f1 : 0.89763    best : 0.89763\n",
      "epoch : 13/30    time : 107s/1816s\n",
      "TRAIN    loss : 0.10895    f1 : 0.93124\n",
      "VALID    loss : 0.29103    f1 : 0.80979    best : 0.89763\n",
      "epoch : 14/30    time : 107s/1708s\n",
      "TRAIN    loss : 0.07745    f1 : 0.95793\n",
      "VALID    loss : 0.25696    f1 : 0.84678    best : 0.89763\n",
      "epoch : 15/30    time : 107s/1602s\n",
      "TRAIN    loss : 0.04079    f1 : 0.96450\n",
      "VALID    loss : 0.16048    f1 : 0.89218    best : 0.89763\n",
      "epoch : 16/30    time : 107s/1493s\n",
      "TRAIN    loss : 0.05830    f1 : 0.95848\n",
      "VALID    loss : 0.23535    f1 : 0.83953    best : 0.89763\n",
      "epoch : 17/30    time : 107s/1388s\n",
      "TRAIN    loss : 0.06432    f1 : 0.94868\n",
      "VALID    loss : 0.24742    f1 : 0.89394    best : 0.89763\n",
      "epoch : 18/30    time : 107s/1281s\n",
      "TRAIN    loss : 0.04174    f1 : 0.97447\n",
      "VALID    loss : 0.21586    f1 : 0.87589    best : 0.89763\n",
      "epoch : 19/30    time : 107s/1175s\n",
      "TRAIN    loss : 0.10495    f1 : 0.93604\n",
      "VALID    loss : 0.20870    f1 : 0.87664    best : 0.89763\n",
      "epoch : 20/30    time : 107s/1067s\n",
      "TRAIN    loss : 0.08869    f1 : 0.94992\n",
      "VALID    loss : 0.23725    f1 : 0.86358    best : 0.89763\n",
      "epoch : 21/30    time : 107s/962s\n",
      "TRAIN    loss : 0.04215    f1 : 0.97561\n",
      "VALID    loss : 0.18654    f1 : 0.90243    best : 0.90243\n",
      "epoch : 22/30    time : 107s/857s\n",
      "TRAIN    loss : 0.02931    f1 : 0.98059\n",
      "VALID    loss : 0.16464    f1 : 0.90295    best : 0.90295\n",
      "epoch : 23/30    time : 107s/747s\n",
      "TRAIN    loss : 0.05912    f1 : 0.95276\n",
      "VALID    loss : 0.19892    f1 : 0.88483    best : 0.90295\n",
      "epoch : 24/30    time : 107s/641s\n",
      "TRAIN    loss : 0.03764    f1 : 0.97982\n",
      "VALID    loss : 0.23354    f1 : 0.87932    best : 0.90295\n",
      "epoch : 25/30    time : 107s/534s\n",
      "TRAIN    loss : 0.03473    f1 : 0.98382\n",
      "VALID    loss : 0.20876    f1 : 0.89367    best : 0.90295\n",
      "epoch : 26/30    time : 107s/427s\n",
      "TRAIN    loss : 0.06999    f1 : 0.94953\n",
      "VALID    loss : 0.19092    f1 : 0.90795    best : 0.90795\n",
      "epoch : 27/30    time : 107s/320s\n",
      "TRAIN    loss : 0.06314    f1 : 0.96831\n",
      "VALID    loss : 0.27779    f1 : 0.81920    best : 0.90795\n",
      "epoch : 28/30    time : 107s/213s\n",
      "TRAIN    loss : 0.04352    f1 : 0.96884\n",
      "VALID    loss : 0.29061    f1 : 0.86722    best : 0.90795\n",
      "epoch : 29/30    time : 107s/107s\n",
      "TRAIN    loss : 0.03488    f1 : 0.98115\n",
      "VALID    loss : 0.21246    f1 : 0.89236    best : 0.90795\n",
      "epoch : 30/30    time : 107s/0s\n",
      "TRAIN    loss : 0.03938    f1 : 0.98071\n",
      "VALID    loss : 0.23226    f1 : 0.87517    best : 0.90795\n"
     ]
    }
   ],
   "source": [
    "model = Network().to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scaler = torch.cuda.amp.GradScaler() \n",
    "\n",
    "\n",
    "\n",
    "best=0\n",
    "for epoch in range(epochs):\n",
    "    start=time.time()\n",
    "    train_loss = 0\n",
    "    train_pred=[]\n",
    "    train_y=[]\n",
    "    model.train()\n",
    "    for batch in (train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        x = torch.tensor(batch[0], dtype=torch.float32, device=device)\n",
    "        y = torch.tensor(batch[1], dtype=torch.long, device=device)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            pred = model(x)\n",
    "        loss = criterion(pred, y)\n",
    "\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        train_loss += loss.item()/len(train_loader)\n",
    "        train_pred += pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "        train_y += y.detach().cpu().numpy().tolist()\n",
    "        \n",
    "    \n",
    "    train_f1 = accuracy_function(train_y, train_pred)\n",
    "    \n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "    valid_pred=[]\n",
    "    valid_y=[]\n",
    "    with torch.no_grad():\n",
    "        for batch in (valid_loader):\n",
    "            x = torch.tensor(batch[0], dtype=torch.float32, device=device)\n",
    "            y = torch.tensor(batch[1], dtype=torch.long, device=device)\n",
    "            with torch.cuda.amp.autocast():\n",
    "                pred = model(x)\n",
    "            loss = criterion(pred, y)\n",
    "            valid_loss += loss.item()/len(valid_loader)\n",
    "            valid_pred += pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "            valid_y += y.detach().cpu().numpy().tolist()\n",
    "        valid_f1 = accuracy_function(valid_y, valid_pred)\n",
    "    if valid_f1>=best:\n",
    "        best=valid_f1\n",
    "        model_save(model, valid_f1, f'model/eff-b0.pth')\n",
    "    TIME = time.time() - start\n",
    "    print(f'epoch : {epoch+1}/{epochs}    time : {TIME:.0f}s/{TIME*(epochs-epoch-1):.0f}s')\n",
    "    print(f'TRAIN    loss : {train_loss:.5f}    f1 : {train_f1:.5f}')\n",
    "    print(f'VALID    loss : {valid_loss:.5f}    f1 : {valid_f1:.5f}    best : {best:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MzDFwsyHJsuH",
    "outputId": "7ebb1bd0-c502-4e95-952b-1bab700f2468"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jan 13 08:38:37 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   60C    P0    30W /  70W |   4908MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6rLFKtWajW02"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p1vp0coLMisQ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "JM-crop_disease.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
