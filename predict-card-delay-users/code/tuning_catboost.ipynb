{
 "cells": [
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "aquatic-arthritis",
=======
   "id": "f344c8d7",
>>>>>>> 5c54fecbfda9056c77f6dca7fee0b3b1b07ab836
   "metadata": {},
   "source": [
    "# Just to Get Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
<<<<<<< HEAD
   "id": "acoustic-continent",
=======
   "id": "9c7d11d9",
>>>>>>> 5c54fecbfda9056c77f6dca7fee0b3b1b07ab836
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Memory optimization from  6.86MB to  1.92MB (72.1% reduction)\n",
      "Memory optimization from  2.59MB to  0.72MB (72.1% reduction)\n"
=======
      "Memory optimization from  7.67MB to  1.92MB (75.0% reduction)\n",
      "Memory optimization from  2.90MB to  0.72MB (75.0% reduction)\n"
>>>>>>> 5c54fecbfda9056c77f6dca7fee0b3b1b07ab836
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "import joblib\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from itertools import combinations\n",
    "from eli5.permutation_importance import get_score_importances\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "from sklearn import cluster\n",
    "\n",
    "import optuna\n",
    "from optuna import Trial\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.visualization import plot_contour, plot_optimization_history\n",
    "from optuna.visualization import plot_parallel_coordinate, plot_slice, plot_param_importances\n",
    "from hyperopt.pyll.base import scope\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "from catboost import Pool, CatBoostClassifier\n",
    "from kaggler.model import AutoLGB\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, GridSearchCV, StratifiedShuffleSplit, train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, log_loss\n",
    "import random\n",
    "\n",
    "train = pd.read_csv('data/train.csv').drop(['index', 'FLAG_MOBIL'], axis=1).fillna('NAN')\n",
    "test = pd.read_csv('data/test.csv').drop(['index', 'FLAG_MOBIL'], axis=1).fillna('NAN')\n",
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "\n",
    "# train데이터와 test데이터 변수를 함께 조정하기 위해 병합\n",
    "merge_data = pd.concat([train, test], axis = 0)\n",
    "\n",
    "# DAYS_BIRTH\n",
    "merge_data['DAYS_BIRTH_month']=np.floor((-merge_data['DAYS_BIRTH'])/30)-(\n",
    "    (np.floor((-merge_data['DAYS_BIRTH'])/30)/12).astype(int)*12)\n",
    "merge_data['DAYS_BIRTH_week']=np.floor((-merge_data['DAYS_BIRTH'])/7)-(\n",
    "    (np.floor((-merge_data['DAYS_BIRTH'])/7)/4).astype(int)*4)\n",
    "\n",
    "# DAYS_EMPLOYED\n",
    "merge_data['DAYS_EMPLOYED_month']=np.floor((-merge_data['DAYS_EMPLOYED'])/30)-(\n",
    "    (np.floor((-merge_data['DAYS_EMPLOYED'])/30)/12).astype(int)*12)\n",
    "merge_data['DAYS_EMPLOYED_week']=np.floor((-merge_data['DAYS_EMPLOYED'])/7)-(\n",
    "    (np.floor((-merge_data['DAYS_EMPLOYED'])/7)/4).astype(int)*4)\n",
    "\n",
    "# before_EMPLOYED\n",
    "merge_data['before_EMPLOYED']=merge_data['DAYS_BIRTH']-merge_data['DAYS_EMPLOYED']\n",
    "merge_data['before_EMPLOYED_month']=np.floor((-merge_data['before_EMPLOYED'])/30)-(\n",
    "    (np.floor((-merge_data['before_EMPLOYED'])/30)/12).astype(int)*12)\n",
    "merge_data['before_EMPLOYED_week']=np.floor((-merge_data['before_EMPLOYED'])/7)-(\n",
    "    (np.floor((-merge_data['before_EMPLOYED'])/7)/4).astype(int)*4)\n",
    "\n",
    "# DAYS_BIRTH / Income\n",
    "merge_data['DAYS_BIRTH_month/income_total'] = merge_data['DAYS_BIRTH_month'] / merge_data['income_total']\n",
    "merge_data['DAYS_BIRTH_week/income_total'] = merge_data['DAYS_BIRTH_week'] / merge_data['income_total']\n",
    "\n",
    "# DAYS_EMPLOYED / Income\n",
    "merge_data['DAYS_EMPLOYED_month/income_total'] = merge_data['DAYS_EMPLOYED_month'] / merge_data['income_total']\n",
    "merge_data['DAYS_EMPLOYED_week/income_total'] = merge_data['DAYS_EMPLOYED_week'] / merge_data['income_total']\n",
    "\n",
    "# before_EMPLOYED / Income\n",
    "merge_data['before_EMPLOYED/income_total'] = merge_data['before_EMPLOYED'] / merge_data['income_total']\n",
    "merge_data['before_EMPLOYED_month/income_total'] = merge_data['before_EMPLOYED_month'] / merge_data['income_total']\n",
    "merge_data['before_EMPLOYED_week/income_total'] = merge_data['before_EMPLOYED_week'] / merge_data['income_total']\n",
    "\n",
    "# Income / Family\n",
    "merge_data['income_total/family_size'] = merge_data['income_total'] / merge_data['family_size']\n",
    "\n",
    "merge_data['child_num/income_total'] = merge_data['child_num'] / merge_data['income_total']\n",
    "merge_data['family_size/income_total'] = merge_data['family_size'] / merge_data['income_total']\n",
    "merge_data['DAYS_BIRTH/income_total'] = merge_data['DAYS_BIRTH'] / merge_data['income_total']\n",
    "merge_data['DAYS_EMPLOYED/income_total'] = merge_data['DAYS_EMPLOYED'] / merge_data['income_total']\n",
    "merge_data['DAYS_EMPLOYED/DAYS_BIRTH'] =  merge_data['DAYS_EMPLOYED'] / merge_data['DAYS_BIRTH']\n",
    "\n",
    "# Income skewed-data\n",
    "merge_data['income_total'] = np.log1p(merge_data['income_total'])\n",
    "# merge_data['log_income_total'] = np.log(merge_data['income_total'])\n",
    "# merge_data['sqrt_income_total'] = np.sqrt(merge_data['income_total'])\n",
    "# merge_data['boxcox_income_total'] = stats.boxcox(merge_data['income_total'])[0]\n",
    "\n",
    "merge_data = merge_data.fillna(-999)\n",
    "train = merge_data[merge_data['credit'] != -999]\n",
    "test = merge_data[merge_data['credit'] == -999]\n",
    "test.drop('credit', axis = 1, inplace = True)\n",
    "\n",
    "train_cols = list(train.columns); train_cols.remove('credit'); train_cols.append('credit')\n",
    "train = train[train_cols]\n",
    "\n",
    "train_x = train.drop(['credit'], axis=1) # 데이터 나누기\n",
    "train_y = train['credit']\n",
    "test_x = test.copy()\n",
    "\n",
    "enc = LabelEncoder()\n",
    "for col in train_x.columns:\n",
    "    if (train_x[col].dtypes=='O'):\n",
    "        train_x[col] = enc.fit_transform(train_x[col])\n",
    "        test_x[col] = enc.fit_transform(test_x[col])\n",
    "\n",
    "def reduce_mem_usage(data):\n",
    "    numerics = ['int8', 'int16', 'int32', 'int64', 'float32', 'float64']\n",
    "    start_memory = data.memory_usage().sum() / 1024**2    \n",
    "    for col in data.columns:\n",
    "        col_type = data[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = data[col].min()\n",
    "            c_max = data[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    data[col] = data[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    data[col] = data[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    data[col] = data[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    data[col] = data[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    data[col] = data[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    data[col] = data[col].astype(np.float32)\n",
    "                else:\n",
    "                    data[col] = data[col].astype(np.float64)    \n",
    "    end_memory = data.memory_usage().sum() / 1024**2\n",
    "    print('Memory optimization from {:5.2f}MB to {:5.2f}MB ({:.1f}% reduction)'\n",
    "          .format(start_memory, end_memory, 100 * (start_memory - end_memory) / start_memory))\n",
    "    return data\n",
    "train_x = reduce_mem_usage(train_x)\n",
    "test_x = reduce_mem_usage(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
<<<<<<< HEAD
   "id": "brutal-asian",
=======
   "id": "637fe6c1",
>>>>>>> 5c54fecbfda9056c77f6dca7fee0b3b1b07ab836
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_objective(trial: Trial) -> float:\n",
    "    cat_params = {\n",
    "        'thread_count': None,\n",
    "        'allow_writing_files': False,\n",
    "        'loss_function': 'MultiClass',\n",
    "        'bootstrap_type': 'Bernoulli', # Baysian은 커널 오류\n",
    "        'n_estimators':  50000,\n",
    "        #'learning_rate': 0.01,\n",
    "        #'bootstrap_type': trial.suggest_categorical('bootstrap_type', ['Bernoulli']), # Poisson은 gpu만\n",
    "        'l2_leaf_reg': trial.suggest_loguniform(\"l2_leaf_reg\", 10, 1000),\n",
    "        #'random_strength': trial.suggest_loguniform(\"random_strength\", 1e-2, 100),\n",
    "        'max_bin': trial.suggest_int('max_bin', 150, 500), # border_counts\n",
    "        'colsample_bylevel': trial.suggest_uniform('colsample_bylevel', 0.01, 0.6), # rsm # gpu not support\n",
    "        'learning_rate':trial.suggest_uniform(\"learning_rate\", 0.01, 0.04),\n",
    "        'leaf_estimation_iterations': trial.suggest_int('leaf_estimation_iterations', 1, 10),\n",
    "        'depth': trial.suggest_int('depth', 10, 15),\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 1, 50), # min_child_samples\n",
    "        \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0)\n",
    "        #\"bagging_temperature\": trial.suggest_loguniform(\"bagging_temperature\", 1e-2, 100)\n",
    "     }\n",
    "#     if cat_params[\"bootstrap_type\"] == \"Bayesian\":\n",
    "#         cat_params[\"bagging_temperature\"] = trial.suggest_loguniform('bagging_temperature', 1e-2, 100)\n",
    "#     else:\n",
    "#         cat_params[\"subsample\"] = trial.suggest_uniform(\"subsample\", 0.1, 1.0)\n",
<<<<<<< HEAD
    "   # print(cat_params)\n",
=======
    "    #print(cat_params)\n",
>>>>>>> 5c54fecbfda9056c77f6dca7fee0b3b1b07ab836
    "        \n",
    "    \n",
    "    \n",
    "    # CV=10으로 튜닝\n",
    "    \n",
    "    seed = 91373\n",
    "    kfold = StratifiedKFold(n_splits=5, random_state = seed, shuffle = True)\n",
    "    cv = np.zeros((train_x.shape[0], 3))\n",
    "\n",
    "    for n, (train_idx, val_idx) in enumerate(kfold.split(train_x, train_y)):\n",
    "\n",
    "        x_train, x_val = train_x.iloc[train_idx], train_x.iloc[val_idx]\n",
    "        y_train, y_val = train_y.iloc[train_idx], train_y.iloc[val_idx]\n",
    "        \n",
    "        catmodel = CatBoostClassifier(**cat_params)                              # 진행상황 보고싶을때 False를 1000으로\n",
    "        catmodel.fit(x_train, y_train,\n",
    "                     eval_set=[(x_val,y_val)], early_stopping_rounds=30, verbose=False)\n",
    "\n",
    "        cv[val_idx, :] = catmodel.predict_proba(x_val)\n",
    "        #print(f'fold{n+1} multi_logloss: {log_loss(y_val, cv[val_idx, :])}') # Fold마다 점수 체크하려면 주석 해제\n",
    "    #print('multi_logloss:', log_loss(train_y, cv))\n",
    "\n",
    "    \n",
    "    return log_loss(train_y, cv)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "id": "separate-momentum",
=======
   "execution_count": 3,
   "id": "aae8028c",
>>>>>>> 5c54fecbfda9056c77f6dca7fee0b3b1b07ab836
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "\u001b[32m[I 2021-05-22 21:17:58,659]\u001b[0m A new study created in memory with name: cat_parameter_opt\u001b[0m\n",
      "\u001b[32m[I 2021-05-22 21:27:22,255]\u001b[0m Trial 0 finished with value: 0.7073896897339982 and parameters: {'l2_leaf_reg': 56.11516415334507, 'max_bin': 483, 'colsample_bylevel': 0.441876425668729, 'learning_rate': 0.03197316968394073, 'leaf_estimation_iterations': 2, 'depth': 8, 'min_data_in_leaf': 3, 'subsample': 0.9330880728874675}. Best is trial 0 with value: 0.7073896897339982.\u001b[0m\n",
      "\u001b[32m[I 2021-05-22 21:31:44,586]\u001b[0m Trial 1 finished with value: 0.7697924235789463 and parameters: {'l2_leaf_reg': 159.30522616241012, 'max_bin': 398, 'colsample_bylevel': 0.02214485163452344, 'learning_rate': 0.03939819704323989, 'leaf_estimation_iterations': 9, 'depth': 9, 'min_data_in_leaf': 10, 'subsample': 0.5917022549267169}. Best is trial 0 with value: 0.7073896897339982.\u001b[0m\n",
      "\u001b[32m[I 2021-05-22 21:36:21,065]\u001b[0m Trial 2 finished with value: 0.7011765096457029 and parameters: {'l2_leaf_reg': 40.59611610484304, 'max_bin': 334, 'colsample_bylevel': 0.2648475609988483, 'learning_rate': 0.025824582803960838, 'leaf_estimation_iterations': 7, 'depth': 8, 'min_data_in_leaf': 15, 'subsample': 0.6831809216468459}. Best is trial 2 with value: 0.7011765096457029.\u001b[0m\n",
      "\u001b[32m[I 2021-05-22 21:41:22,753]\u001b[0m Trial 3 finished with value: 0.7011003389853353 and parameters: {'l2_leaf_reg': 81.68455894760157, 'max_bin': 425, 'colsample_bylevel': 0.12780753147343224, 'learning_rate': 0.030284688768272235, 'leaf_estimation_iterations': 6, 'depth': 8, 'min_data_in_leaf': 31, 'subsample': 0.5852620618436457}. Best is trial 3 with value: 0.7011003389853353.\u001b[0m\n",
      "\u001b[32m[I 2021-05-22 21:45:12,153]\u001b[0m Trial 4 finished with value: 0.7024101261744465 and parameters: {'l2_leaf_reg': 13.492834268013251, 'max_bin': 483, 'colsample_bylevel': 0.57972289951399, 'learning_rate': 0.03616794696232922, 'leaf_estimation_iterations': 4, 'depth': 8, 'min_data_in_leaf': 35, 'subsample': 0.7200762468698007}. Best is trial 3 with value: 0.7011003389853353.\u001b[0m\n",
      "\u001b[32m[I 2021-05-22 21:47:47,356]\u001b[0m Trial 5 finished with value: 0.7211841863790602 and parameters: {'l2_leaf_reg': 17.541893487450796, 'max_bin': 323, 'colsample_bylevel': 0.03028922745797885, 'learning_rate': 0.038186408041575644, 'leaf_estimation_iterations': 3, 'depth': 11, 'min_data_in_leaf': 16, 'subsample': 0.7600340105889054}. Best is trial 3 with value: 0.7011003389853353.\u001b[0m\n",
      "\u001b[32m[I 2021-05-22 22:23:43,081]\u001b[0m Trial 6 finished with value: 0.6989548844084593 and parameters: {'l2_leaf_reg': 123.9996783684609, 'max_bin': 214, 'colsample_bylevel': 0.5820549303810896, 'learning_rate': 0.035502656467222296, 'leaf_estimation_iterations': 10, 'depth': 12, 'min_data_in_leaf': 30, 'subsample': 0.9609371175115584}. Best is trial 6 with value: 0.6989548844084593.\u001b[0m\n",
      "\u001b[32m[I 2021-05-22 22:27:48,493]\u001b[0m Trial 7 finished with value: 0.7091578203891753 and parameters: {'l2_leaf_reg': 15.030900645056818, 'max_bin': 218, 'colsample_bylevel': 0.036684100457217456, 'learning_rate': 0.02650660661526529, 'leaf_estimation_iterations': 4, 'depth': 9, 'min_data_in_leaf': 42, 'subsample': 0.6783766633467947}. Best is trial 6 with value: 0.6989548844084593.\u001b[0m\n",
      "\u001b[32m[I 2021-05-22 22:52:06,093]\u001b[0m Trial 8 finished with value: 0.6930262601738287 and parameters: {'l2_leaf_reg': 36.464395589807204, 'max_bin': 340, 'colsample_bylevel': 0.09314529273510995, 'learning_rate': 0.03604393961508079, 'leaf_estimation_iterations': 1, 'depth': 12, 'min_data_in_leaf': 39, 'subsample': 0.5993578407670862}. Best is trial 8 with value: 0.6930262601738287.\u001b[0m\n",
      "\u001b[32m[I 2021-05-22 22:56:05,417]\u001b[0m Trial 9 finished with value: 0.7018909548628359 and parameters: {'l2_leaf_reg': 10.257563974185649, 'max_bin': 436, 'colsample_bylevel': 0.42704583287009407, 'learning_rate': 0.03458014336081974, 'leaf_estimation_iterations': 8, 'depth': 8, 'min_data_in_leaf': 18, 'subsample': 0.5579345297625649}. Best is trial 8 with value: 0.6930262601738287.\u001b[0m\n"
=======
      "\u001b[32m[I 2021-05-23 02:27:27,338]\u001b[0m A new study created in memory with name: cat_parameter_opt\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-dab2274c3236>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTPESampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcat_study\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cat_parameter_opt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"minimize\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcat_study\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcat_objective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcat_best_hyperparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcat_study\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/optuna/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    398\u001b[0m             )\n\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    401\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/optuna/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     67\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/optuna/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/optuna/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-f8d5e6967953>\u001b[0m in \u001b[0;36mcat_objective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mcatmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCatBoostClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mcat_params\u001b[0m\u001b[0;34m)\u001b[0m                              \u001b[0;31m# 진행상황 보고싶을때 False를 1000으로\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         catmodel.fit(x_train, y_train,\n\u001b[0m\u001b[1;32m     42\u001b[0m                      eval_set=[(x_val,y_val)], early_stopping_rounds=30, verbose=False)\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/catboost/core.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\u001b[0m\n\u001b[1;32m   4537\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_is_classification_objective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss_function'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4539\u001b[0;31m         self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n\u001b[0m\u001b[1;32m   4540\u001b[0m                   \u001b[0meval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_description\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_period\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4541\u001b[0m                   silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mlog_fixup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_get_train_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m             self._train(\n\u001b[0m\u001b[1;32m   1919\u001b[0m                 \u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1920\u001b[0m                 \u001b[0mtrain_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"eval_sets\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m_train\u001b[0;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[1;32m   1364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1366\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minit_model\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1367\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_trained_model_attributes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
>>>>>>> 5c54fecbfda9056c77f6dca7fee0b3b1b07ab836
     ]
    }
   ],
   "source": [
    "sampler = TPESampler(seed=42)\n",
    "cat_study = optuna.create_study(study_name=\"cat_parameter_opt\", direction=\"minimize\", sampler=sampler)\n",
    "cat_study.optimize(cat_objective, n_trials=50)\n",
    "\n",
    "cat_best_hyperparams = cat_study.best_trial.params\n",
    "cat_base_hyperparams = {'loss_function': 'MultiClass', 'n_estimators': 50000, 'thread_count': None, \n",
    "                        'allow_writing_files': False, 'bootstrap_type': 'Bernoulli'}\n",
    "cat_best_hyperparams.update(cat_base_hyperparams)\n",
    "print(\"The best hyperparameters are:\\n\", cat_best_hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "forty-sight",
=======
   "id": "3cefe0ec",
>>>>>>> 5c54fecbfda9056c77f6dca7fee0b3b1b07ab836
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 나오자마자 복붙해서 카톡방에 올려서 따로 저장해두기!! (파라미터값, logg값 둘 다)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "executive-highway",
=======
   "id": "b06c51d7",
>>>>>>> 5c54fecbfda9056c77f6dca7fee0b3b1b07ab836
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_optimization_history(cat_study) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "divided-humor",
=======
   "id": "c82219db",
>>>>>>> 5c54fecbfda9056c77f6dca7fee0b3b1b07ab836
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_param_importances(cat_study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "significant-chain",
=======
   "id": "4e97795d",
>>>>>>> 5c54fecbfda9056c77f6dca7fee0b3b1b07ab836
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_slice(cat_study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "norman-coast",
=======
   "id": "49a61436",
>>>>>>> 5c54fecbfda9056c77f6dca7fee0b3b1b07ab836
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위 그래프들은 지우지 말고 그대로 커밋해주기 (결과 보고 범위 다시 지정해야함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "unnecessary-phenomenon",
=======
   "id": "eb8c26f3",
>>>>>>> 5c54fecbfda9056c77f6dca7fee0b3b1b07ab836
   "metadata": {},
   "outputs": [],
   "source": [
    "#  {'bootstrap_type': 'Bernoulli', 'l2_leaf_reg': 95.93542290320686, 'random_strength': 20.17940526189691, \n",
    "#   'max_bin': 185, 'colsample_bylevel': 0.08309149072060056, 'learning_rate': 0.0643798350832877, 'leaf_estimation_iterations': 8, \n",
    "#   'depth': 10, 'min_data_in_leaf': 26, 'subsample': 0.7746017801223928, 'loss_function': 'MultiClass', 'n_estimators': 50000, \n",
    "#   'thread_count': None}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.7.9"
=======
   "version": "3.8.8"
>>>>>>> 5c54fecbfda9056c77f6dca7fee0b3b1b07ab836
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
