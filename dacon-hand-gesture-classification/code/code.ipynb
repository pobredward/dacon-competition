{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad96fe0d",
   "metadata": {},
   "source": [
    "# 1. Import, Setting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df43961f",
   "metadata": {},
   "source": [
    "## (1) Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47b037c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Library\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# HP Tuning\n",
    "import optuna\n",
    "from optuna import Trial\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.visualization import plot_contour, plot_optimization_history\n",
    "from optuna.visualization import plot_parallel_coordinate, plot_slice, plot_param_importances\n",
    "\n",
    "# Modeling\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from lightgbm import LGBMClassifier\n",
    "import xgboost as xgb\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Dropout, Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b862fd",
   "metadata": {},
   "source": [
    "## (2) Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0698e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../data/train.csv\")\n",
    "test = pd.read_csv(\"../data/test.csv\")\n",
    "submission = pd.read_csv(\"../data/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217d55a3",
   "metadata": {},
   "source": [
    "## (3) Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed851249",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dict = {}\n",
    "pred_test_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c52031f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_train = 2335 # 주어진 train data의 row 수\n",
    "rows_test = 9555 # 주어진 test data의 row 수\n",
    "classes = 4 # 주어진 데이터의 class 수\n",
    "num_trial = 20 # 파라미터 튜닝을 몇 번 진행하는지의 수\n",
    "splits_hp = 5 # 파라미터 튜닝을 진행할 때의 kfold 수\n",
    "splits_tr = 15 # 모델 트레이닝을 진행할 때의 kfold 수\n",
    "basic_seed = 42 # default seed\n",
    "num_seed = 10 # 트레이닝 seed 개수\n",
    "sel_seed = 3 # 선택할 seed 개수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a987fc9b",
   "metadata": {},
   "source": [
    "## (4) Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3651ede2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dir(dir):\n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)\n",
    "        print(\"Created Directory :\", dir)\n",
    "    else:\n",
    "        print(\"Directory already existed :\", dir)\n",
    "create_dir(\"../pkl\")\n",
    "create_dir(\"../model\")\n",
    "create_dir(\"../submission\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777eb93e",
   "metadata": {},
   "source": [
    "# 2. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cf3f16",
   "metadata": {},
   "source": [
    "## (1) LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a16342",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train.iloc[:, 1:-1]\n",
    "train_y = train.iloc[:, -1:]\n",
    "test_x = test.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdfd598",
   "metadata": {},
   "source": [
    "### a. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5201043b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_objective(trial: Trial) -> float:\n",
    "    params_lgb = {\n",
    "        \"random_state\": basic_seed,\n",
    "        \"verbosity\": -1,\n",
    "        \"n_estimators\": 10000,\n",
    "        \"objective\": \"multiclass\",\n",
    "        \"metric\": \"multi_logloss\",\n",
    "        'learning_rate': trial.suggest_uniform(\"learning_rate\", 0.005, 0.05),\n",
    "        \"reg_alpha\": trial.suggest_uniform(\"reg_alpha\", 0.0, 1),\n",
    "        \"reg_lambda\": trial.suggest_uniform(\"reg_lambda\", 0.0, 1),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 5, 8),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 200, 1200),\n",
    "        \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0), # feature_fraction\n",
    "        \"subsample\": trial.suggest_uniform(\"subsample\", 0.0, 1.0),\n",
    "        \"subsample_freq\": trial.suggest_int(\"subsample_freq\", 1, 10),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 1, 10),\n",
    "        \"max_bin\": trial.suggest_int(\"max_bin\", 150, 400),\n",
    "    }\n",
    "    \n",
    "    kfold = StratifiedKFold(n_splits=splits_hp, random_state=basic_seed, shuffle = True) # Cross-validation cv=5\n",
    "    cv = np.zeros((rows_train, classes))\n",
    "\n",
    "    for n, (train_idx, val_idx) in enumerate(kfold.split(train_x, train_y)):\n",
    "\n",
    "        x_train, x_val = train_x.iloc[train_idx], train_x.iloc[val_idx]\n",
    "        y_train, y_val = train_y.iloc[train_idx].values.ravel(), train_y.iloc[val_idx].values.ravel()\n",
    "\n",
    "        lgbmodel = LGBMClassifier(**params_lgb)\n",
    "                                                                                        # 진행상황 보고싶을때 -1을 100으로\n",
    "        lgbmodel.fit(x_train, y_train, eval_set=[(x_val, y_val)], early_stopping_rounds=30, verbose=-1) \n",
    "        cv[val_idx, :] = lgbmodel.predict_proba(x_val)\n",
    "        \n",
    "    print('accuracy_score:', accuracy_score(train_y, np.argmax(cv, axis=1)))\n",
    "    return accuracy_score(train_y, np.argmax(cv, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee2df56",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sampler = TPESampler(seed=basic_seed)\n",
    "lgb_study = optuna.create_study(study_name=\"lgb_parameter_opt\", direction=\"maximize\", sampler=sampler)\n",
    "lgb_study.optimize(lgb_objective, n_trials=num_trial)\n",
    "\n",
    "lgb_best_hyperparams = lgb_study.best_trial.params\n",
    "lgb_base_hyperparams = {'objective':'multiclass', 'n_estimators':10000,\n",
    "                        'lambda_l1':lgb_best_hyperparams['reg_alpha'],\n",
    "                        'lambda_l2':lgb_best_hyperparams['reg_lambda'],\n",
    "                        'reg_alpha':None, 'reg_lambda':None\n",
    "                       }\n",
    "lgb_best_hyperparams.update(lgb_base_hyperparams)\n",
    "print(\"The best hyperparameters are:\\n\", lgb_best_hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afba36af",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.matplotlib.plot_param_importances(lgb_study);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb0feb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.matplotlib.plot_slice(lgb_study);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8e032b",
   "metadata": {},
   "source": [
    "### b. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3c223d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lucky_seeds = np.random.randint(0, 1000, num_seed)\n",
    "\n",
    "for i, seed in enumerate(lucky_seeds):\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=splits, random_state=basic_seed, shuffle=True) # CV 늘려가면서 하기\n",
    "    cv = np.zeros((rows_train, classes))\n",
    "    pred_test = np.zeros((rows_test, classes), dtype=float)\n",
    "\n",
    "    for n, (train_idx, val_idx) in enumerate(kfold.split(train_x, train_y)):\n",
    "        \n",
    "        x_train, x_val = train_x.iloc[train_idx], train_x.iloc[val_idx]\n",
    "        y_train, y_val = train_y.iloc[train_idx].values.ravel(), train_y.iloc[val_idx].values.ravel()\n",
    "\n",
    "        lgbmodel = LGBMClassifier(**lgb_best_hyperparams)\n",
    "        lgbmodel.fit(x_train, y_train, eval_set=[(x_val, y_val)], early_stopping_rounds=30, verbose=None)\n",
    "        \n",
    "        cv[val_idx,:] = lgbmodel.predict_proba(x_val)\n",
    "        pred_test += lgbmodel.predict_proba(test_x) / splits\n",
    "        \n",
    "    pred_dict['lgb'+str(seed)] = cv\n",
    "    pred_test_dict['lgb'+str(seed)] = pred_test\n",
    "    print(f'seed {seed}', 'accuracy_score :', accuracy_score(train_y, np.argmax(cv, axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee92c24",
   "metadata": {},
   "source": [
    "## (2) XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da74c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train.iloc[:, 1:-1]\n",
    "train_y = train.iloc[:, -1:]\n",
    "test_x = test.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7590f386",
   "metadata": {},
   "source": [
    "### a. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f52b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_objective(trial: Trial) -> float:\n",
    "    params_xgb = {\n",
    "        \"random_state\": basic_seed,\n",
    "        \"verbose\": None,\n",
    "        \"num_class\": classes,\n",
    "        \"objective\": \"multi:softprob\",\n",
    "        \"eval_metric\": \"mlogloss\",\n",
    "        \"learning_rate\": trial.suggest_uniform(\"learning_rate\", 0.005, 0.05),\n",
    "        \"reg_alpha\": trial.suggest_uniform(\"reg_alpha\", 0.0, 0.1), # default=0\n",
    "        \"reg_lambda\": trial.suggest_uniform(\"reg_lambda\", 0.0, 0.1), # default=1\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 8, 15),\n",
    "        \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0), # default=0\n",
    "        \"colsample_bylevel\": trial.suggest_uniform(\"colsample_bylevel\", 0.5, 1.0),\n",
    "        \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0), # default=1,\n",
    "        \"min_child_weight\": trial.suggest_uniform(\"min_child_weight\", 1, 5), # default=1\n",
    "        \"max_bin\": trial.suggest_int(\"max_bin\", 200, 500),\n",
    "    }\n",
    "    \n",
    "    kfold = StratifiedKFold(n_splits=splits_hp, random_state=basic_seed, shuffle=True) # Cross-validation cv=5\n",
    "    cv = np.zeros((rows_test, classes))\n",
    "\n",
    "    for n, (train_idx, val_idx) in enumerate(kfold.split(train_x, train_y)):\n",
    "\n",
    "        x_train, x_val = train_x.iloc[train_idx], train_x.iloc[val_idx]\n",
    "        y_train, y_val = train_y.iloc[train_idx], train_y.iloc[val_idx]\n",
    "        \n",
    "        dtrain = xgb.DMatrix(x_train, label=y_train)\n",
    "        dvalid = xgb.DMatrix(x_val, label=y_val)\n",
    "        watchlist = [(dtrain, 'train'), (dvalid, 'valid')]\n",
    "                                                                                            # 진행상황 보고싶을때 None을 100으로\n",
    "        xgbmodel = xgb.train(params_xgb, dtrain, 100000, watchlist, early_stopping_rounds=30, verbose_eval=None)\n",
    "        cv[val_idx, :] = xgbmodel.predict(dvalid)\n",
    "        \n",
    "    print('accuracy_score:', accuracy_score(train_y, np.argmax(cv, axis=1)))\n",
    "    \n",
    "    return accuracy_score(train_y, np.argmax(cv, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d42b20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = TPESampler(seed=basic_seed)\n",
    "xgb_study = optuna.create_study(study_name=\"xgb_parameter_opt\", direction=\"maximize\", sampler=sampler)\n",
    "xgb_study.optimize(xgb_objective, n_trials=num_trial)\n",
    "\n",
    "xgb_best_hyperparams = xgb_study.best_trial.params\n",
    "xgb_base_hyperparams = {'objective':'multi:softprob', \"num_class\": classes, \"eval_metric\": \"mlogloss\", \"random_state\": basic_seed}\n",
    "xgb_best_hyperparams.update(xgb_base_hyperparams)\n",
    "print(\"The best hyperparameters are:\\n\", xgb_best_hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c20d2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.matplotlib.plot_param_importances(xgb_study);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8321476",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.matplotlib.plot_slice(xgb_study);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f9ee75",
   "metadata": {},
   "outputs": [],
   "source": [
    "lucky_seeds = np.random.randint(0, 100, num_seed)\n",
    "xgtest = xgb.DMatrix(test_x)\n",
    "for i, seed in enumerate(lucky_seeds):\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=splits_tr, random_state=basic_seed, shuffle = True) # CV 늘려가면서 하기\n",
    "    cv=np.zeros((rows_train, classes))\n",
    "    pred_test = np.zeros((rows_test, classes), dtype=float)\n",
    "\n",
    "    for n, (train_idx, val_idx) in enumerate(kfold.split(train_x, train_y)):\n",
    "        \n",
    "        x_train, x_val = train_x.iloc[train_idx], train_x.iloc[val_idx]\n",
    "        y_train, y_val = train_y.iloc[train_idx].values.ravel(), train_y.iloc[val_idx].values.ravel()\n",
    "        \n",
    "        dtrain = xgb.DMatrix(x_train, label=y_train)\n",
    "        dvalid = xgb.DMatrix(x_val, label=y_val)\n",
    "        watchlist = [(dtrain, 'train'), (dvalid, 'valid')]\n",
    "        \n",
    "                                                                                            # 진행상황 보고싶을때 None을 100으로\n",
    "        xgbmodel = xgb.train(xgb_best_hyperparams, dtrain, 100000, watchlist, early_stopping_rounds=30, verbose_eval=None)\n",
    "\n",
    "        cv[val_idx, :] = xgbmodel.predict(dvalid)\n",
    "        pred_test += xgbmodel.predict(xgtest) / splits_tr # CV 바꾸면 이 숫자도 똑같이 바꿔야함\n",
    "        \n",
    "    pred_dict['xgb'+str(seed)] = cv\n",
    "    pred_test_dict['xgb'+str(seed)] = pred_test\n",
    "    print(f'seed {seed}', 'accuracy_score :', accuracy_score(train_y, np.argmax(cv, axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa995e20",
   "metadata": {},
   "source": [
    "## 3-3. CNN Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f029a8",
   "metadata": {},
   "source": [
    "### (1) HP Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84e97fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train.iloc[:, 1:-1]\n",
    "test_x = test.iloc[:, 1:]\n",
    "\n",
    "train_x = np.array(train_x).reshape(-1, 8, 4, 1)\n",
    "test_x = np.array(test_x).reshape(-1, 8, 4, 1)\n",
    "\n",
    "ohe = OneHotEncoder(sparse = False)\n",
    "train_y = ohe.fit_transform(train[['target']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133cf35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(num_layer, mid_units, num_filters):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=num_filters[0], kernel_size=(2, 2),\n",
    "                 activation=\"elu\",\n",
    "                 input_shape=(8, 4, 1)))\n",
    "    model.add(BatchNormalization())\n",
    "    #model.add(Dropout(dropout_rate[0]))\n",
    "    for i in range(1,num_layer):\n",
    "        model.add(Conv2D(filters=num_filters[i], kernel_size=(2, 2), padding=\"same\", activation=\"elu\"))\n",
    "        model.add(BatchNormalization())\n",
    "        #model.add(Dropout(dropout_rate[i+1]))\n",
    "            \n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dense(mid_units, activation='relu'))\n",
    "    #model.add(Dropout(dropout_rate[-1]))\n",
    "    model.add(Dense(classes, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2b2cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_objective(trial: Trial) -> float:\n",
    "    \n",
    "    #clear_session\n",
    "    keras.backend.clear_session()\n",
    "    \n",
    "    #number of the convolution layer\n",
    "    num_layer = trial.suggest_int(\"num_layer\", 2, 3)\n",
    "    \n",
    "    #number of the unit\n",
    "    mid_units = int(trial.suggest_discrete_uniform(\"mid_units\", 30, 150, 10))\n",
    "    \n",
    "    #number of the each convolution layer filter\n",
    "    num_filters = [int(trial.suggest_discrete_uniform(\"num_filter_\"+str(i), 16, 256, 16)) for i in range(num_layer)]\n",
    "\n",
    "    #Dropout\n",
    "    #dropout_rate = trial.suggest_uniform('dropout_rate', 0.0, 0.5)\n",
    "    #dropout_rate = [int(trial.suggest_uniform(\"dropout_rate\"+str(ii), 0.0, 0.5)) for ii in range(num_layer+1)]\n",
    "    \n",
    "    kfold = StratifiedKFold(n_splits=splits_hp, random_state = basic_seed, shuffle = True) # Cross-validation cv=5\n",
    "    es = EarlyStopping(monitor=\"val_acc\", patience=5, mode=\"max\", verbose=0)\n",
    "    cv = np.zeros((rows_train, classes))\n",
    "\n",
    "    for n, (train_idx, val_idx) in enumerate(kfold.split(train_x, train.target)):\n",
    "\n",
    "        x_train, y_train = train_x[train_idx], train_y[train_idx]\n",
    "        x_val, y_val = train_x[val_idx], train_y[val_idx]\n",
    "        \n",
    "        mc = ModelCheckpoint(f\"../model_{n+1}.h5\", save_best_only=True, monitor=\"val_acc\", mode=\"max\", verbose=0)\n",
    "        \n",
    "        model = create_model(num_layer, mid_units, num_filters)\n",
    "        \n",
    "        # Adam optimizer learning rate\n",
    "        optimizer = Adam(learning_rate=trial.suggest_uniform(\"learning_rate\", 0.0005, 0.005))\n",
    "        model.compile(optimizer=optimizer,\n",
    "                      loss=\"categorical_crossentropy\",\n",
    "                      metrics=[\"acc\"])\n",
    "        model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=100, batch_size=32, \n",
    "                  callbacks=[es,mc], verbose=None)\n",
    "        \n",
    "        best = load_model(f\"../model_{n+1}.h5\")\n",
    "        cv[val_idx, :] = best.predict(x_val)\n",
    "        \n",
    "    print('accuracy_score:', accuracy_score(np.argmax(train_y, axis=1), np.argmax(cv, axis=1)))\n",
    "    \n",
    "    return accuracy_score(np.argmax(train_y, axis=1), np.argmax(cv, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fab4e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = TPESampler(seed=basic_seed)\n",
    "cnn_study = optuna.create_study(study_name=\"cnn_parameter_opt\", direction=\"maximize\", sampler=sampler)\n",
    "cnn_study.optimize(cnn_objective, n_trials=num_trial)\n",
    "cnn_best_hyperparams = cnn_study.best_trial.params\n",
    "print(\"The best hyperparameters are:\\n\", cnn_best_hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786d3ac8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "optuna.visualization.matplotlib.plot_param_importances(cnn_study);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f606157",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "optuna.visualization.matplotlib.plot_slice(cnn_study);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47158a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lucky_seeds = np.random.randint(0, 100, num_seed)\n",
    "\n",
    "for i, seed in enumerate(lucky_seeds):\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=splits_tr, random_state=basic_seed, shuffle = True) # CV 늘려가면서 하기\n",
    "    cv=np.zeros((rows_train, classes))\n",
    "    pred_test = np.zeros((rows_test, classes), dtype=float)\n",
    "    es = EarlyStopping(monitor=\"val_acc\", patience=5, mode=\"max\", verbose=0)\n",
    "    \n",
    "    for n, (train_idx, val_idx) in enumerate(kfold.split(train_x, train.target)):\n",
    "        \n",
    "        x_train, y_train = train_x[train_idx], train_y[train_idx]\n",
    "        x_val, y_val = train_x[val_idx], train_y[val_idx]\n",
    "        \n",
    "        cnn = create_model(cnn_study.best_params['num_layer'], cnn_study.best_params['mid_units'], \n",
    "                  [cnn_study.best_params[f'num_filter_{i}'] for i in range(cnn_study.best_params['num_layer'])])\n",
    "\n",
    "        # ModelCheckpoint Fold마다 갱신\n",
    "        mc = ModelCheckpoint(f\"../model_{i+1}.h5\", save_best_only=True, monitor=\"val_acc\", mode=\"max\", verbose=0)\n",
    "\n",
    "        # 모델 Complie\n",
    "        optimizer = Adam(learning_rate=cnn_study.best_params['learning_rate'])\n",
    "        cnn.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"acc\"])\n",
    "        cnn.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=100, batch_size=32, \n",
    "                callbacks=[es,mc], verbose=0)\n",
    "\n",
    "        # 최고 성능 기록 모델\n",
    "        best = load_model(f\"../model_{i+1}.h5\")\n",
    "        cv[val_idx,:] = best.predict(x_val)\n",
    "        pred_test += best.predict(test_x) / splits_tr\n",
    "        \n",
    "    pred_dict['cnn'+str(seed)] = cv\n",
    "    pred_test_dict['cnn'+str(seed)] = pred_test\n",
    "    print(f'seed {seed}', 'accuracy_score :', accuracy_score(np.argmax(train_y, axis=1), np.argmax(cv, axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85006be",
   "metadata": {},
   "source": [
    "## 4. Stacking (XGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29034517",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_dict(model, pred_dict, pred_test_dict):\n",
    "    pred_dict_local = {}\n",
    "    for key, value in pred_dict.items():\n",
    "        if model in key:\n",
    "            pred_dict_local[key]=value\n",
    "\n",
    "    pred_test_dict_local = {}\n",
    "    for key, value in pred_test_dict.items():\n",
    "        if model in key:\n",
    "            pred_test_dict_local[key]=value\n",
    "\n",
    "    pred_dict_new_local = dict(sorted(\n",
    "        pred_dict_local.items(), \n",
    "        key=lambda x:accuracy_score(np.argmax(train_y, axis=1), \n",
    "                                    np.argmax(list(x[1]), axis=1)), reverse=True)[:sel_seed])\n",
    "    pred_test_dict_new_local = {}\n",
    "    for key, value in pred_dict_new_local.items():\n",
    "        pred_test_dict_new_local[key]=pred_test_dict_local[key]\n",
    "        \n",
    "    return pred_dict_new_local, pred_test_dict_new_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddde195",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dict_lgb, pred_test_dict_lgb = sort_dict('lgb', pred_dict, pred_test_dict)\n",
    "pred_dict_xgb, pred_test_dict_xgb = sort_dict('xgb', pred_dict, pred_test_dict)\n",
    "pred_dict_cnn, pred_test_dict_cnn = sort_dict('cnn', pred_dict, pred_test_dict)\n",
    "pred_dict_rcnn, pred_test_dict_rcnn = sort_dict('rcnn', pred_dict, pred_test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44666d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dict(model, pred_dict, pred_test_dict):\n",
    "    with open('./pkl/pred_dict_'+model+'.pickle', 'wb') as fw:\n",
    "        pickle.dump(pred_dict, fw)\n",
    "    with open('./pkl/pred_test_dict_'+model+'.pickle', 'wb') as fw:\n",
    "        pickle.dump(pred_test_dict, fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3e6615",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dir(dir):\n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)\n",
    "        print(\"Created Directory :\", dir)\n",
    "    else:\n",
    "        print(\"Directory already existed :\", dir)\n",
    "create_dir(\"pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bf6d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dict('lgb', pred_dict_lgb, pred_test_dict_lgb)\n",
    "save_dict('xgb', pred_dict_xgb, pred_test_dict_xgb)\n",
    "save_dict('cnn', pred_dict_cnn, pred_test_dict_cnn)\n",
    "save_dict('rcnn', pred_dict_rcnn, pred_test_dict_rcnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bc5a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dict(model):\n",
    "    with open('./pkl/pred_dict_'+model+'.pickle', 'rb') as fw:\n",
    "        pred_dict_new_local = pickle.load(fw)\n",
    "    with open('./pkl/pred_test_dict_'+model+'.pickle', 'rb') as fw:\n",
    "        pred_test_dict_new_local = pickle.load(fw)    \n",
    "    return pred_dict_new_local, pred_test_dict_new_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371b9c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dict_lgb, pred_test_dict_lgb = load_dict('lgb')\n",
    "pred_dict_xgb, pred_test_dict_xgb = load_dict('xgb')\n",
    "pred_dict_cnn, pred_test_dict_cnn = load_dict('cnn')\n",
    "pred_dict_rcnn, pred_test_dict_rcnn = load_dict('rcnn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265928a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dict_total = {**pred_dict_lgb, **pred_dict_xgb, **pred_dict_cnn, **pred_dict_rcnn}\n",
    "pred_test_dict_total = {**pred_test_dict_lgb, **pred_test_dict_xgb, **pred_test_dict_cnn, **pred_test_dict_rcnn}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83968184",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train.iloc[:, -1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99202bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_objective(trial: Trial) -> float:\n",
    "    params_xgb = {\n",
    "        \"random_state\": basic_seed,\n",
    "        \"verbose\": None,\n",
    "        \"num_class\": classes,\n",
    "        \"objective\": \"multi:softprob\",\n",
    "        \"eval_metric\": \"mlogloss\",\n",
    "        \"learning_rate\": trial.suggest_uniform(\"learning_rate\", 0.0005, 0.05),\n",
    "        \"reg_alpha\": trial.suggest_uniform(\"reg_alpha\", 0.1, 1.0),\n",
    "        \"reg_lambda\": trial.suggest_uniform(\"reg_lambda\", 0.1, 1.0),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 6, 10),\n",
    "        \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.3, 1.0),\n",
    "        \"colsample_bylevel\": trial.suggest_uniform(\"colsample_bylevel\", 0.3, 1.0),\n",
    "        \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
    "        \"gamma\": trial.suggest_uniform(\"gamma\", 0.0, 0.5),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "        \"max_bin\": trial.suggest_int(\"max_bin\", 100, 400),\n",
    "    }\n",
    "    \n",
    "    kfold = StratifiedKFold(n_splits=splits_hp, random_state=basic_seed, shuffle=True)\n",
    "    cv = np.zeros((rows_train, classes))\n",
    "\n",
    "    for n, (train_idx, val_idx) in enumerate(kfold.split(train_x, train_y)):\n",
    "\n",
    "        x_train, x_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_train, y_val = train_y.iloc[train_idx], train_y.iloc[val_idx]\n",
    "        \n",
    "        dtrain = xgb.DMatrix(x_train, label=y_train)\n",
    "        dvalid = xgb.DMatrix(x_val, label=y_val)\n",
    "        watchlist = [(dtrain, 'train'), (dvalid, 'valid')]\n",
    "                                                                                            # 진행상황 보고싶을때 None을 100으로\n",
    "        stack_xgbmodel = xgb.train(params_xgb, dtrain, 100000, watchlist, early_stopping_rounds=30, verbose_eval=None)\n",
    "        cv[val_idx, :] = stack_xgbmodel.predict(dvalid)\n",
    "\n",
    "    print('accuracy_score:', accuracy_score(train_y, np.argmax(cv, axis=1)))\n",
    "\n",
    "    return accuracy_score(train_y, np.argmax(cv, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d6cfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(np.hstack([x for _, x in pred_dict_total.items()]))\n",
    "X_test = pd.DataFrame(np.hstack([x for _, x in pred_test_dict_total.items()]))\n",
    "\n",
    "sampler = TPESampler(seed=basic_seed)\n",
    "stack_study = optuna.create_study(study_name=\"stack_parameter_opt\", direction=\"maximize\", sampler=sampler)\n",
    "stack_study.optimize(stack_objective, n_trials=num_trial)\n",
    "\n",
    "stack_best_hyperparams = stack_study.best_trial.params\n",
    "stack_base_hyperparams = {'objective':'multi:softprob', \"num_class\": classes, \"eval_metric\": \"mlogloss\", \"random_state\": basic_seed}\n",
    "stack_best_hyperparams.update(stack_base_hyperparams)\n",
    "print(\"The best hyperparameters are:\\n\", stack_best_hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93c5f96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optuna.visualization.matplotlib.plot_param_importances(stack_study);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3ef357",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.matplotlib.plot_slice(stack_study);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c207c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.zeros((rows_train, classes), dtype=float)\n",
    "pred_test = np.zeros((rows_test, classes), dtype=float)\n",
    "kfold = StratifiedKFold(n_splits=splits_tr, random_state=basic_seed, shuffle = True)\n",
    "\n",
    "for n, (train_idx, val_idx) in enumerate(kfold.split(X_train, train_y)):\n",
    "    x_train, x_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "    y_train, y_val = train_y.iloc[train_idx], train_y.iloc[val_idx]\n",
    "\n",
    "    dtrain = xgb.DMatrix(x_train, label=y_train)\n",
    "    dvalid = xgb.DMatrix(x_val, label=y_val)\n",
    "    watchlist = [(dtrain, 'train'), (dvalid, 'valid')]\n",
    "                                                                                        # 진행상황 보고싶을때 None을 100으로\n",
    "    stack_xgbmodel = xgb.train(stack_best_hyperparams, dtrain, 100000, watchlist, early_stopping_rounds=30, verbose_eval=None)\n",
    "    \n",
    "    pred[val_idx, :] = stack_xgbmodel.predict(dvalid)\n",
    "    pred_test += stack_xgbmodel.predict(xgb.DMatrix(X_test)) / splits_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1c503d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'CV Log Loss: {log_loss(train_y, pred):.6f}')\n",
    "print(f'CV Accuracy Score: {accuracy_score(train_y, np.argmax(pred, axis=1)):.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93770c99",
   "metadata": {},
   "source": [
    "## 5. Blending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3899b04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_train = pred.copy()\n",
    "stack_test = pred_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a32d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import permutations\n",
    "candidate = [0,1,2,3,4,5,6,7,8,9,10]\n",
    "permute = permutations(candidate,5)\n",
    "score = {}\n",
    "for i in list(permute):\n",
    "    pred_final = (sum(pred_dict_lgb.values())/sel_seed * i[0] +\n",
    "              sum(pred_dict_xgb.values())/sel_seed * i[1] +\n",
    "              sum(pred_dict_cnn.values())/sel_seed * i[2] +\n",
    "              sum(pred_dict_rcnn.values())/sel_seed * i[3] +\n",
    "                               stack_train * i[4])\n",
    "    score[i] = accuracy_score(train_y, np.argmax(pred_final, axis=1))\n",
    "\n",
    "score = dict(sorted(score.items(), key=lambda x: x[1], reverse=True)[:5])\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6242600c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_final = (sum(pred_dict_lgb.values())/sel_seed * 0 +\n",
    "              sum(pred_dict_xgb.values())/sel_seed * 1 +\n",
    "              sum(pred_dict_cnn.values())/sel_seed * 3 +\n",
    "              sum(pred_dict_rcnn.values())/sel_seed * 2 +\n",
    "                               stack_train * 15)\n",
    "accuracy_score(train_y, np.argmax(pred_final, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0559b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test_final = (sum(pred_test_dict_lgb.values())/3 * 0 +\n",
    "                   sum(pred_test_dict_xgb.values())/3 * 1 +\n",
    "                    sum(pred_test_dict_cnn.values())/3 * 3 +\n",
    "                    sum(pred_dict_rcnn.values())/3 * 2 +\n",
    "                                          stack_test * 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99e7dc7",
   "metadata": {},
   "source": [
    "## 6. Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e409af",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_name = '20220318'\n",
    "submission_number = '3'\n",
    "submission['target'] = np.argmax(pred_test_final, axis=1)\n",
    "submission.to_csv(f'../submission/{submission_name}-{submission_number}.csv', index = False)\n",
    "submission.target.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
