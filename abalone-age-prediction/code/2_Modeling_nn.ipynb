{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e3babe3",
   "metadata": {},
   "source": [
    "# 1. Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3afc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Library\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Modeling\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf83377",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dir(dir):\n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)\n",
    "        print(\"Created Directory :\", dir)\n",
    "    else:\n",
    "        print(\"Directory already existed :\", dir)\n",
    "create_dir(\"../pickle\")\n",
    "create_dir(\"../model\")\n",
    "create_dir(\"../submission\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c700011b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../data/train.csv\")\n",
    "test = pd.read_csv(\"../data/test.csv\")\n",
    "submission = pd.read_csv(\"../data/sample_submission.csv\")\n",
    "\n",
    "train = train.drop([\"id\"], axis=1)\n",
    "test = test.drop([\"id\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b95a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_train = train.shape[0] # 주어진 train data의 row 수\n",
    "rows_test = test.shape[0] # 주어진 test data의 row 수\n",
    "num_trial = 100 # 파라미터 튜닝을 몇 번 진행하는지의 수\n",
    "splits_hp = 5 # 파라미터 튜닝을 진행할 때의 kfold 수\n",
    "splits_tr = 5 # 모델 트레이닝을 진행할 때의 kfold 수\n",
    "basic_seed = 42 # default seed\n",
    "num_seed_tr = 10 # 트레이닝 seed 개수\n",
    "sel_seed = 3 # 선택할 seed 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab1b054",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dict = {}\n",
    "pred_test_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efd3099",
   "metadata": {},
   "source": [
    "# 2. NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abad59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Weight Ratio'] = train['Shucked Weight'] / train['Whole Weight']\n",
    "test['Weight Ratio'] = test['Shucked Weight'] / test['Whole Weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de616bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Foreign Body'] = train['Whole Weight'] - (train['Shucked Weight'] + train['Viscra Weight'] + train['Shell Weight'])\n",
    "test['Foreign Body'] = test['Whole Weight'] - (test['Shucked Weight'] + test['Viscra Weight'] + test['Shell Weight'])\n",
    "train.loc[train[(train['Foreign Body']<0.0005)].index, \"Foreign Body\"] = 0.0005\n",
    "test.loc[test[(test['Foreign Body']<0.0005)].index, \"Foreign Body\"] = 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f116eefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ohe = train.copy()\n",
    "test_ohe = test.copy()\n",
    "\n",
    "train_ohe = pd.get_dummies(train_ohe)\n",
    "test_ohe = pd.get_dummies(test_ohe)\n",
    "\n",
    "train_x = train_ohe.drop(['Target'], axis=1)\n",
    "train_y = train_ohe['Target']\n",
    "test_x = test_ohe.copy()\n",
    "\n",
    "print('One-Hot Encoding Completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baff724a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = '../model/'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)\n",
    "\n",
    "modelpath = \"../model/{epoch:02d}-{val_loss:.4f}.hdf5\"\n",
    "\n",
    "cp = ModelCheckpoint(filepath=modelpath, monitor='val_mae', verbose=0, save_best_only=True, mode = 'min')\n",
    "es = EarlyStopping(monitor='val_mae', patience=50, mode='min')\n",
    "rlrp = ReduceLROnPlateau(monitor='val_mae', factor=0.2, patience=40, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79899077",
   "metadata": {},
   "outputs": [],
   "source": [
    "lucky_seeds = np.random.randint(0, 1000, num_seed_tr)\n",
    "\n",
    "for i, seed in enumerate(lucky_seeds):\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=splits_tr, random_state=seed, shuffle=True)\n",
    "    cv = np.zeros(rows_train)\n",
    "    pred_test = np.zeros(rows_test)\n",
    "\n",
    "    for n, (train_idx, val_idx) in enumerate(kfold.split(train_x, train_y)):\n",
    "        \n",
    "        x_train, x_val = train_x.iloc[train_idx], train_x.iloc[val_idx]\n",
    "        y_train, y_val = train_y.iloc[train_idx].values.ravel(), train_y.iloc[val_idx].values.ravel()\n",
    "        \n",
    "        nnmodel = Sequential()\n",
    "        nnmodel.add(Dense(16, input_dim=len(train_x.columns), activation='elu'))\n",
    "        nnmodel.add(Dense(32, activation='elu'))    \n",
    "        nnmodel.add(Dense(64, activation='elu'))\n",
    "        nnmodel.add(Dropout(0.5))  \n",
    "        nnmodel.add(Dense(32, activation='elu'))\n",
    "        nnmodel.add(Dense(16, activation='elu'))\n",
    "        nnmodel.add(Dense(1))\n",
    "\n",
    "        nnmodel.compile(loss='mean_absolute_error',\n",
    "              optimizer='Nadam', \n",
    "              metrics=['mae'])\n",
    "\n",
    "        nnmodel.fit(train_x, train_y, validation_data=(x_val, y_val), epochs=1000, batch_size=32, \n",
    "                    verbose=None, callbacks=[es, cp, rlrp])\n",
    "        \n",
    "        cv[val_idx] = nnmodel.predict(x_val).flatten()\n",
    "        pred_test += nnmodel.predict(test_x).flatten() / splits_tr\n",
    "        \n",
    "    pred_dict['nn'+str(seed)] = cv\n",
    "    pred_test_dict['nn'+str(seed)] = pred_test\n",
    "    print(f'seed {seed}', 'mean_absolute_error :', mean_absolute_error(train_y, cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e22259",
   "metadata": {},
   "source": [
    "# 3. Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018720e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_dict(model, pred_dict, pred_test_dict):\n",
    "    pred_dict_local = {}\n",
    "    for key, value in pred_dict.items():\n",
    "        if model in key:\n",
    "            pred_dict_local[key]=value\n",
    "\n",
    "    pred_test_dict_local = {}\n",
    "    for key, value in pred_test_dict.items():\n",
    "        if model in key:\n",
    "            pred_test_dict_local[key]=value\n",
    "\n",
    "    pred_dict_new_local = dict(sorted(\n",
    "        pred_dict_local.items(), \n",
    "        key=lambda x:mean_absolute_error((train_y), list(x[1])), reverse=False)[:sel_seed])\n",
    "    pred_test_dict_new_local = {}\n",
    "    for key, value in pred_dict_new_local.items():\n",
    "        pred_test_dict_new_local[key]=pred_test_dict_local[key]\n",
    "        \n",
    "    return pred_dict_new_local, pred_test_dict_new_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a1ca88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dict(model, pred_dict, pred_test_dict):\n",
    "    with open('../pickle/pred_dict_'+model+'.pickle', 'wb') as fw:\n",
    "        pickle.dump(pred_dict, fw)\n",
    "    with open('../pickle/pred_test_dict_'+model+'.pickle', 'wb') as fw:\n",
    "        pickle.dump(pred_test_dict, fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63edff23",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dict_nn, pred_test_dict_nn = sort_dict('nn', pred_dict, pred_test_dict)\n",
    "save_dict('nn', pred_dict_nn, pred_test_dict_nn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
